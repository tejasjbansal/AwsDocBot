{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe1b57f",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f43fd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "398c899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d344126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling_core.types.doc import ImageRefMode\n",
    "from docling.datamodel.settings import settings\n",
    "\n",
    "from docling.document_converter import (\n",
    "    DocumentConverter,\n",
    "    PdfFormatOption,\n",
    "    WordFormatOption,\n",
    ")\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "from docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode, EasyOcrOptions, TesseractOcrOptions, OcrMacOptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f35d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f524a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_chucks = []\n",
    "\n",
    "def chunking(result):\n",
    "    from docling_core.transforms.chunker.tokenizer.huggingface import HuggingFaceTokenizer\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "    from docling.chunking import HybridChunker\n",
    "\n",
    "    EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    tokenizer = HuggingFaceTokenizer(\n",
    "        tokenizer=AutoTokenizer.from_pretrained(EMBED_MODEL_ID),\n",
    "    )\n",
    "\n",
    "    chunker = HybridChunker(tokenizer=tokenizer,merge_peers=True)  # set tokenizer as needed\n",
    "    chunk_iter = chunker.chunk(result.document)\n",
    "\n",
    "    # Convert the iterator to a list to count the chunks\n",
    "    chunks = list(chunk_iter)\n",
    "    docs_chucks.append(chunks)\n",
    "    num_chunks = len(chunks)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"=== {i} ===\")\n",
    "        txt_tokens = tokenizer.count_tokens(chunk.text)\n",
    "        print(f\"chunk.text ({txt_tokens} tokens):\\n{chunk.text!r}\")\n",
    "\n",
    "        ser_txt = chunker.contextualize(chunk=chunk)\n",
    "        ser_tokens = tokenizer.count_tokens(ser_txt)\n",
    "        print(f\"chunker.contextualize(chunk) ({ser_tokens} tokens):\\n{ser_txt!r}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Print the number of chunks\n",
    "    print(f\"The document has been divided into {num_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35516dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiformatconversion():\n",
    "    input_paths = [\n",
    "        Path(\"ARD Docs/data/pdf/aws.pdf\"),\n",
    "        # Path(\"ARD Docs/md/\"),\n",
    "        # Path(\"ARD Docs/data/html/\"),\n",
    "        # Path(\"ARD Docs/data/docx/\"),\n",
    "        # Path(\"ARD Docs/data/pptx/\"),\n",
    "        # Path(\"ARD Docs/data/images/\"),\n",
    "        # Path(\"ARD Docs/data/asciidoc/\"),\n",
    "        # Path(\"ARD Docs/data/csv/\"),\n",
    "        # Path(\"ARD Docs/data/xlsx/\"),\n",
    "    ]\n",
    "\n",
    "    ## for defaults use:\n",
    "    # doc_converter = DocumentConverter()\n",
    "\n",
    "    ## to customize use:\n",
    "\n",
    "    IMAGE_RESOLUTION_SCALE = 2.0\n",
    "\n",
    "    # Define pipeline options for PDF processing\n",
    "    pipeline_options = PdfPipelineOptions(\n",
    "        do_table_structure=True,  \n",
    "        do_ocr=True,  # Enable OCR\n",
    "        ocr_options=TesseractOcrOptions(force_full_page_ocr=True, lang=[\"eng\"]),  \n",
    "        table_structure_options=dict(\n",
    "            do_cell_matching=False,  \n",
    "            mode=TableFormerMode.ACCURATE  \n",
    "        ),\n",
    "        generate_page_images=True,  \n",
    "        generate_picture_images=True, \n",
    "        images_scale=IMAGE_RESOLUTION_SCALE,\n",
    "    )\n",
    "\n",
    "    doc_converter = (\n",
    "        DocumentConverter(  # all of the below is optional, has internal defaults.\n",
    "            allowed_formats=[\n",
    "                InputFormat.PDF,\n",
    "                InputFormat.IMAGE,\n",
    "                InputFormat.DOCX,\n",
    "                InputFormat.HTML,\n",
    "                InputFormat.PPTX,\n",
    "                InputFormat.ASCIIDOC,\n",
    "                InputFormat.CSV,\n",
    "                InputFormat.MD,\n",
    "                InputFormat.XLSX,\n",
    "            ],  # whitelist formats, non-matching files are ignored.\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options),\n",
    "                InputFormat.DOCX: WordFormatOption(\n",
    "                    pipeline_cls=SimplePipeline  # , backend=MsWordDocumentBackend\n",
    "                ),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    # Enable the profiling to measure the time spent\n",
    "    settings.debug.profile_pipeline_timings = True\n",
    "\n",
    "    start_time = time.time()\n",
    "    conv_results = doc_converter.convert_all(input_paths)\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    _log.info(f\"Document converted in {end_time:.2f} seconds.\")\n",
    "\n",
    "    for res in conv_results:\n",
    "        out_path = Path(\"parsed-ard-docs\")\n",
    "        out_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "\n",
    "        print(\n",
    "            f\"Document {res.input.file.name} converted.\"\n",
    "            f\"\\nSaved markdown output to: {out_path!s}\"\n",
    "        )\n",
    "\n",
    "        chunking(res)\n",
    "\n",
    "        _log.debug(res.document._export_to_indented_text(max_text_len=16))\n",
    "\n",
    "        # Export Docling document format to markdowndoc:\n",
    "        with (out_path / f\"{res.input.file.stem}.md\").open(\"w\") as fp:\n",
    "            fp.write(res.document.export_to_markdown(image_mode=ImageRefMode.REFERENCED))\n",
    "            doc_filename = Path(f\"./parsed-ard-docs/{res.input.file.name}\").stem\n",
    "            md_filename = out_path / f\"{doc_filename}-with-images.md\"\n",
    "            res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "        # with (out_path / f\"{res.input.file.stem}.json\").open(\"w\") as fp:\n",
    "        #     fp.write(json.dumps(res.document.export_to_dict()))\n",
    "\n",
    "        # with (out_path / f\"{res.input.file.stem}.yaml\").open(\"w\") as fp:\n",
    "        #     fp.write(yaml.safe_dump(res.document.export_to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10564ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from typing import List\n",
    "\n",
    "db = lancedb.connect(\"lancedb/ard\")\n",
    "func = get_registry().get(\"sentence-transformers\").create(name=\"sentence-transformers/all-MiniLM-L6-v2\",device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d9868e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simplified metadata schema\n",
    "class ChunkMetadata(LanceModel):\n",
    "    \"\"\"\n",
    "    You must order the fields in alphabetical order.\n",
    "    This is a requirement of the Pydantic implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    filename: str | None\n",
    "    page_numbers: List[int] | None\n",
    "    title: str | None\n",
    "\n",
    "\n",
    "# Define the main Schema\n",
    "class Chunks(LanceModel):\n",
    "    text: str = func.SourceField()\n",
    "    vector: Vector(func.ndims()) = func.VectorField()  # type: ignore\n",
    "    metadata: ChunkMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9b589bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(table_name, chunks):\n",
    "    # Create table with processed chunks\n",
    "    processed_chunks = [\n",
    "    {\n",
    "        \"text\": chunk.text,\n",
    "        \"metadata\": {\n",
    "            \"filename\": chunk.meta.origin.filename,\n",
    "            \"page_numbers\": [\n",
    "                page_no\n",
    "                for page_no in sorted(\n",
    "                    set(\n",
    "                        prov.page_no\n",
    "                        for item in chunk.meta.doc_items\n",
    "                        for prov in item.prov\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "            or None,\n",
    "            \"title\": chunk.meta.headings[0] if chunk.meta.headings else None,\n",
    "        },\n",
    "    }\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "    # Create table - this will apply the embedding function automatically\n",
    "    table = db.create_table(table_name, schema=Chunks, mode=\"overwrite\")\n",
    "    \n",
    "    # Add data - the embedding function will be applied automatically\n",
    "    table.add(processed_chunks)\n",
    "    df = table.to_pandas()\n",
    "    df.to_csv(\"vectors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5475bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    multiformatconversion()\n",
    "    for chucks in docs_chucks:\n",
    "        embedding(\"awsdb\",chucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "120a455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document aws.pdf converted.\n",
      "Saved markdown output to: parsed-ard-docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4329 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 0 ===\n",
      "chunk.text (107 tokens):\n",
      "\"Copyright © 2025 Amazon Web Services, Inc. and/or its affiliates. All rights reserved.\\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not Amazon's, in any manner that is likely to cause contusion among customers, or in any manner that disparages or discredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may or may not be affiliated with, connected to, or sponsored by Amazon.\"\n",
      "chunker.contextualize(chunk) (117 tokens):\n",
      "\"Overview of Amazon Web Services: AWS Whitepaper\\nCopyright © 2025 Amazon Web Services, Inc. and/or its affiliates. All rights reserved.\\nAmazon's trademarks and trade dress may not be used in connection with any product or service that is not Amazon's, in any manner that is likely to cause contusion among customers, or in any manner that disparages or discredits Amazon. All other trademarks not owned by Amazon are the property of their respective owners, who may or may not be affiliated with, connected to, or sponsored by Amazon.\"\n",
      "\n",
      "=== 1 ===\n",
      "chunk.text (501 tokens):\n",
      "'Abstract and introduction ............................................................................................................... 1, 1 = . Introduction ..................................................................................................................................................., 1 = 1. What is cloud computing? .............................................................................................................., 1 = 2. Six advantages of cloud computing ..............................................................................................., 1 = 3. Types of cloud computing'\n",
      "chunker.contextualize(chunk) (511 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAbstract and introduction ............................................................................................................... 1, 1 = . Introduction ..................................................................................................................................................., 1 = 1. What is cloud computing? .............................................................................................................., 1 = 2. Six advantages of cloud computing ..............................................................................................., 1 = 3. Types of cloud computing'\n",
      "\n",
      "=== 2 ===\n",
      "chunk.text (422 tokens):\n",
      "'.............................................................................................................., 1 = 4. Deployment models ....................................................................................................................................., 1 = 4. Cloud .........................................................................................................................................................., 1 = 4. Private cloud (on-premises)'\n",
      "chunker.contextualize(chunk) (432 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.............................................................................................................., 1 = 4. Deployment models ....................................................................................................................................., 1 = 4. Cloud .........................................................................................................................................................., 1 = 4. Private cloud (on-premises)'\n",
      "\n",
      "=== 3 ===\n",
      "chunk.text (406 tokens):\n",
      "'.................................................................................................................., 1 = 4. Hybrid ........................................................................................................................................................, 1 = 4. Global infrastructure ......................................................................................................................., 1 = 5. Security and compliance'\n",
      "chunker.contextualize(chunk) (416 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.................................................................................................................., 1 = 4. Hybrid ........................................................................................................................................................, 1 = 4. Global infrastructure ......................................................................................................................., 1 = 5. Security and compliance'\n",
      "\n",
      "=== 4 ===\n",
      "chunk.text (437 tokens):\n",
      "'................................................................................................................., 1 = 6. Security ..........................................................................................................................................................., 1 = 6. Compliance ....................................................................................................................................................., 1 = 7. AWS services'\n",
      "chunker.contextualize(chunk) (447 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................., 1 = 6. Security ..........................................................................................................................................................., 1 = 6. Compliance ....................................................................................................................................................., 1 = 7. AWS services'\n",
      "\n",
      "=== 5 ===\n",
      "chunk.text (433 tokens):\n",
      "'...................................................................................................................................., 1 = 7. Analytics ........................................................................................................................................................., 1 = 9. Accessing AWS services ..............................................................................................................................., 1 = . Analytics'\n",
      "chunker.contextualize(chunk) (443 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n...................................................................................................................................., 1 = 7. Analytics ........................................................................................................................................................., 1 = 9. Accessing AWS services ..............................................................................................................................., 1 = . Analytics'\n",
      "\n",
      "=== 6 ===\n",
      "chunk.text (433 tokens):\n",
      "'........................................................................................................................................................., 1 = 9. Amazon Athena ....................................................................................................................................., 1 = 11. Amazon CloudSearch ..........................................................................................................................., 1 = 11. Amazon DataZone'\n",
      "chunker.contextualize(chunk) (443 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................................................................., 1 = 9. Amazon Athena ....................................................................................................................................., 1 = 11. Amazon CloudSearch ..........................................................................................................................., 1 = 11. Amazon DataZone'\n",
      "\n",
      "=== 7 ===\n",
      "chunk.text (420 tokens):\n",
      "'................................................................................................................................, 1 = 11. Amazon EMR .........................................................................................................................................., 1 = 12. Amazon FinSpace .................................................................................................................................., 1 = 12. Amazon Kinesis'\n",
      "chunker.contextualize(chunk) (430 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................, 1 = 11. Amazon EMR .........................................................................................................................................., 1 = 12. Amazon FinSpace .................................................................................................................................., 1 = 12. Amazon Kinesis'\n",
      "\n",
      "=== 8 ===\n",
      "chunk.text (487 tokens):\n",
      "'....................................................................................................................................., 1 = 12. Amazon Data Firehose ........................................................................................................................., 1 = 13. Amazon Managed Service for Apache Flink .................................................................................... 13, 1 = . Amazon Kinesis Data Streams ..........................................................................................................., 1 = 14. Amazon Kinesis Video Streams'\n",
      "chunker.contextualize(chunk) (497 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................................................., 1 = 12. Amazon Data Firehose ........................................................................................................................., 1 = 13. Amazon Managed Service for Apache Flink .................................................................................... 13, 1 = . Amazon Kinesis Data Streams ..........................................................................................................., 1 = 14. Amazon Kinesis Video Streams'\n",
      "\n",
      "=== 9 ===\n",
      "chunk.text (374 tokens):\n",
      "'.......................................................................................................... 14, 1 = . Amazon OpenSearch Service ............................................................................................................., 1 = 14. Amazon Redshift ..................................................................................................................................., 1 = 15. Amazon Redshift'\n",
      "chunker.contextualize(chunk) (384 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.......................................................................................................... 14, 1 = . Amazon OpenSearch Service ............................................................................................................., 1 = 14. Amazon Redshift ..................................................................................................................................., 1 = 15. Amazon Redshift'\n",
      "\n",
      "=== 10 ===\n",
      "chunk.text (406 tokens):\n",
      "'..................................................................................................................................., 1 = 15. Amazon Redshift Serverless ..............................................................................................................., 1 = 15. QuickSight .............................................................................................................................................., 1 = 16'\n",
      "chunker.contextualize(chunk) (416 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..................................................................................................................................., 1 = 15. Amazon Redshift Serverless ..............................................................................................................., 1 = 15. QuickSight .............................................................................................................................................., 1 = 16'\n",
      "\n",
      "=== 11 ===\n",
      "chunk.text (423 tokens):\n",
      "'AWS Data Pipeline ................................................................................................................................, 1 = 16. AWS Entity Resolution ........................................................................................................................., 1 = 17. AWS Glue ................................................................................................................................................, 1 = 17. AWS Lake Formation'\n",
      "chunker.contextualize(chunk) (433 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAWS Data Pipeline ................................................................................................................................, 1 = 16. AWS Entity Resolution ........................................................................................................................., 1 = 17. AWS Glue ................................................................................................................................................, 1 = 17. AWS Lake Formation'\n",
      "\n",
      "=== 12 ===\n",
      "chunk.text (465 tokens):\n",
      "'............................................................................................................................, 1 = 18. Amazon Managed Streaming for Apache Kafka (Amazon MSK) ................................................., 1 = 18. Application integration ............................................................................................................................., 1 = 19. AWS Step Functions ............................................................................................................................., 1 = 21. Amazon AppFlow'\n",
      "chunker.contextualize(chunk) (475 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................, 1 = 18. Amazon Managed Streaming for Apache Kafka (Amazon MSK) ................................................., 1 = 18. Application integration ............................................................................................................................., 1 = 19. AWS Step Functions ............................................................................................................................., 1 = 21. Amazon AppFlow'\n",
      "\n",
      "=== 13 ===\n",
      "chunk.text (470 tokens):\n",
      "'.................................................................................................................................., 1 = 21. AWS B2B Data Interchange ................................................................................................................, 1 = 21. Amazon EventBridge ............................................................................................................................, 1 = 22. Amazon Managed Workflows for Apache Airflow (MWAA) .......................................................... 22, 1 = . Amazon MQ'\n",
      "chunker.contextualize(chunk) (480 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.................................................................................................................................., 1 = 21. AWS B2B Data Interchange ................................................................................................................, 1 = 21. Amazon EventBridge ............................................................................................................................, 1 = 22. Amazon Managed Workflows for Apache Airflow (MWAA) .......................................................... 22, 1 = . Amazon MQ'\n",
      "\n",
      "=== 14 ===\n",
      "chunk.text (477 tokens):\n",
      "'..........................................................................................................................................., 1 = 22. Amazon Simple Notification Service ................................................................................................, 1 = 23. Amazon Simple Queue Service .........................................................................................................., 1 = 23. Amazon Simple Workflow Service ...................................................................................................., 1 = 23. Blockchain'\n",
      "chunker.contextualize(chunk) (487 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..........................................................................................................................................., 1 = 22. Amazon Simple Notification Service ................................................................................................, 1 = 23. Amazon Simple Queue Service .........................................................................................................., 1 = 23. Amazon Simple Workflow Service ...................................................................................................., 1 = 23. Blockchain'\n",
      "\n",
      "=== 15 ===\n",
      "chunk.text (431 tokens):\n",
      "'...................................................................................................................................................., 1 = 23. Business applications ................................................................................................................................., 1 = . Alexa for Business ................................................................................................................................., 1 = 25. AWS AppFabric'\n",
      "chunker.contextualize(chunk) (441 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n...................................................................................................................................................., 1 = 23. Business applications ................................................................................................................................., 1 = . Alexa for Business ................................................................................................................................., 1 = 25. AWS AppFabric'\n",
      "\n",
      "=== 16 ===\n",
      "chunk.text (417 tokens):\n",
      "'......................................................................................................................................, 1 = 25. Amazon Chime ......................................................................................................................................, 1 = . Amazon Chime SDK ............................................................................................................................., 1 = 26. Amazon Connect'\n",
      "chunker.contextualize(chunk) (427 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................................................, 1 = 25. Amazon Chime ......................................................................................................................................, 1 = . Amazon Chime SDK ............................................................................................................................., 1 = 26. Amazon Connect'\n",
      "\n",
      "=== 17 ===\n",
      "chunk.text (426 tokens):\n",
      "'..................................................................................................................................., 1 = 26. Amazon Pinpoint ................................................................................................................................... 26, 1 = . Amazon SES ..........................................................................................................................................., 1 = 27. Amazon WorkDocs'\n",
      "chunker.contextualize(chunk) (436 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..................................................................................................................................., 1 = 26. Amazon Pinpoint ................................................................................................................................... 26, 1 = . Amazon SES ..........................................................................................................................................., 1 = 27. Amazon WorkDocs'\n",
      "\n",
      "=== 18 ===\n",
      "chunk.text (401 tokens):\n",
      "'................................................................................................................................, 1 = 27. Amazon WorkMail ................................................................................................................................., 1 = 27. Cloud Financial Management .................................................................................................................., 1 = 28. , 1 = 29. AWS Billing Conductor'\n",
      "chunker.contextualize(chunk) (411 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................, 1 = 27. Amazon WorkMail ................................................................................................................................., 1 = 27. Cloud Financial Management .................................................................................................................., 1 = 28. , 1 = 29. AWS Billing Conductor'\n",
      "\n",
      "=== 19 ===\n",
      "chunk.text (421 tokens):\n",
      "'........................................................................................................................, 1 = 30. AWS Budgets ........................................................................................................................................., 1 = 30. AWS Budgets ........................................................................................................................................., 1 = 30. Reserved Instance (RI) reporting'\n",
      "chunker.contextualize(chunk) (431 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................................, 1 = 30. AWS Budgets ........................................................................................................................................., 1 = 30. AWS Budgets ........................................................................................................................................., 1 = 30. Reserved Instance (RI) reporting'\n",
      "\n",
      "=== 20 ===\n",
      "chunk.text (478 tokens):\n",
      "'......................................................................................................., 1 = 30. Reserved Instance (RI) reporting ......................................................................................................., 1 = 31. Savings Plans ........................................................................................................................................., 1 = 31. Compare AWS compute services ......................................................................................................., 1 = 33'\n",
      "chunker.contextualize(chunk) (488 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................., 1 = 30. Reserved Instance (RI) reporting ......................................................................................................., 1 = 31. Savings Plans ........................................................................................................................................., 1 = 31. Compare AWS compute services ......................................................................................................., 1 = 33'\n",
      "\n",
      "=== 21 ===\n",
      "chunk.text (396 tokens):\n",
      "'Amazon EC2 ..........................................................................................................................................., 1 = 35. Amazon EC2 Auto Scaling .................................................................................................................., 1 = 37. Amazon EC2 Image Builder ................................................................................................................, 1 = 38. Amazon Lightsail'\n",
      "chunker.contextualize(chunk) (406 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAmazon EC2 ..........................................................................................................................................., 1 = 35. Amazon EC2 Auto Scaling .................................................................................................................., 1 = 37. Amazon EC2 Image Builder ................................................................................................................, 1 = 38. Amazon Lightsail'\n",
      "\n",
      "=== 22 ===\n",
      "chunk.text (412 tokens):\n",
      "'................................................................................................................................... 38, 1 = . Amazon Linux 2023 ............................................................................................................................., 1 = 38. AWS App Runner .................................................................................................................................., 1 = 39. AWS Batch'\n",
      "chunker.contextualize(chunk) (422 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................... 38, 1 = . Amazon Linux 2023 ............................................................................................................................., 1 = 38. AWS App Runner .................................................................................................................................., 1 = 39. AWS Batch'\n",
      "\n",
      "=== 23 ===\n",
      "chunk.text (430 tokens):\n",
      "'.............................................................................................................................................., 1 = 39. AWS Elastic Beanstalk .......................................................................................................................... 39, 1 = . AWS Fargate ..........................................................................................................................................., 1 = 40. AWS Lambda'\n",
      "chunker.contextualize(chunk) (440 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.............................................................................................................................................., 1 = 39. AWS Elastic Beanstalk .......................................................................................................................... 39, 1 = . AWS Fargate ..........................................................................................................................................., 1 = 40. AWS Lambda'\n",
      "\n",
      "=== 24 ===\n",
      "chunk.text (393 tokens):\n",
      "'.........................................................................................................................................., 1 = 40. AWS Serverless Application Repository ..........................................................................................., 1 = 40. AWS Outposts ........................................................................................................................................, 1 = 41. AWS Wavelength'\n",
      "chunker.contextualize(chunk) (403 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.........................................................................................................................................., 1 = 40. AWS Serverless Application Repository ..........................................................................................., 1 = 40. AWS Outposts ........................................................................................................................................, 1 = 41. AWS Wavelength'\n",
      "\n",
      "=== 25 ===\n",
      "chunk.text (404 tokens):\n",
      "'..................................................................................................................................., 1 = 41. VMware Cloud on AWS ........................................................................................................................ 42, 1 = . Customer enablement ..............................................................................................................................., 1 = 43. Containers'\n",
      "chunker.contextualize(chunk) (414 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..................................................................................................................................., 1 = 41. VMware Cloud on AWS ........................................................................................................................ 42, 1 = . Customer enablement ..............................................................................................................................., 1 = 43. Containers'\n",
      "\n",
      "=== 26 ===\n",
      "chunk.text (488 tokens):\n",
      "'...................................................................................................................................................., 1 = 43. Amazon Elastic Container Registry ..................................................................................................., 1 = 44. Amazon Elastic Container Service ....................................................................................................., 1 = 45. Amazon Elastic Kubernetes Service .................................................................................................., 1 = 45. AWS App2Container'\n",
      "chunker.contextualize(chunk) (498 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n...................................................................................................................................................., 1 = 43. Amazon Elastic Container Registry ..................................................................................................., 1 = 44. Amazon Elastic Container Service ....................................................................................................., 1 = 45. Amazon Elastic Kubernetes Service .................................................................................................., 1 = 45. AWS App2Container'\n",
      "\n",
      "=== 27 ===\n",
      "chunk.text (400 tokens):\n",
      "'............................................................................................................................., 1 = 45. Red Hat OpenShift Service on AWS ................................................................................................., 1 = 46. Databases ....................................................................................................................................................., 1 = . Compare AWS database services'\n",
      "chunker.contextualize(chunk) (410 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................., 1 = 45. Red Hat OpenShift Service on AWS ................................................................................................., 1 = 46. Databases ....................................................................................................................................................., 1 = . Compare AWS database services'\n",
      "\n",
      "=== 28 ===\n",
      "chunk.text (386 tokens):\n",
      "'....................................................................................................... 48, 1 = . Amazon Aurora ......................................................................................................................................, 1 = 49. Amazon DynamoDB .............................................................................................................................. 50, 1 = . Amazon ElastiCache'\n",
      "chunker.contextualize(chunk) (396 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................... 48, 1 = . Amazon Aurora ......................................................................................................................................, 1 = 49. Amazon DynamoDB .............................................................................................................................. 50, 1 = . Amazon ElastiCache'\n",
      "\n",
      "=== 29 ===\n",
      "chunk.text (502 tokens):\n",
      "'............................................................................................................................., 1 = 51. Amazon Keyspaces (for Apache Cassandra) ...................................................................................., 1 = 51. Amazon MemoryDB .............................................................................................................................., 1 = 52. Amazon Neptune .................................................................................................................................., 1 = 52. Amazon Relational Database'\n",
      "chunker.contextualize(chunk) (512 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................., 1 = 51. Amazon Keyspaces (for Apache Cassandra) ...................................................................................., 1 = 51. Amazon MemoryDB .............................................................................................................................., 1 = 52. Amazon Neptune .................................................................................................................................., 1 = 52. Amazon Relational Database'\n",
      "\n",
      "=== 30 ===\n",
      "chunk.text (448 tokens):\n",
      "'Service ..............................................................................................., 1 = 53. Amazon RDS for Db2 ..........................................................................................................................., 1 = 53. Amazon RDS on VMware ...................................................................................................................., 1 = 53. Amazon Quantum Ledger Database (Amazon QLDB) ................................................................... 54, 1 = . Amazon Timestream'\n",
      "chunker.contextualize(chunk) (458 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nService ..............................................................................................., 1 = 53. Amazon RDS for Db2 ..........................................................................................................................., 1 = 53. Amazon RDS on VMware ...................................................................................................................., 1 = 53. Amazon Quantum Ledger Database (Amazon QLDB) ................................................................... 54, 1 = . Amazon Timestream'\n",
      "\n",
      "=== 31 ===\n",
      "chunk.text (312 tokens):\n",
      "'............................................................................................................................, 1 = 55. Amazon DocumentDB (with MongoDB compatibility) .................................................................., 1 = 55. Amazon Lightsail managed databases ............................................................................................., 1 = 38'\n",
      "chunker.contextualize(chunk) (322 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................, 1 = 55. Amazon DocumentDB (with MongoDB compatibility) .................................................................., 1 = 55. Amazon Lightsail managed databases ............................................................................................., 1 = 38'\n",
      "\n",
      "=== 32 ===\n",
      "chunk.text (415 tokens):\n",
      "'Developer tools ........................................................................................................................................... 56, 1 = . AWS Infrastructure Composer ............................................................................................................, 1 = 56. AWS Cloud9 ..........................................................................................................................................., 1 = 57. AWS CloudShell'\n",
      "chunker.contextualize(chunk) (425 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nDeveloper tools ........................................................................................................................................... 56, 1 = . AWS Infrastructure Composer ............................................................................................................, 1 = 56. AWS Cloud9 ..........................................................................................................................................., 1 = 57. AWS CloudShell'\n",
      "\n",
      "=== 33 ===\n",
      "chunk.text (428 tokens):\n",
      "'....................................................................................................................................., 1 = 57. AWS CodeArtifact ................................................................................................................................., 1 = 57. AWS CodeBuild ......................................................................................................................................, 1 = 57. Amazon CodeCatalyst'\n",
      "chunker.contextualize(chunk) (438 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................................................., 1 = 57. AWS CodeArtifact ................................................................................................................................., 1 = 57. AWS CodeBuild ......................................................................................................................................, 1 = 57. Amazon CodeCatalyst'\n",
      "\n",
      "=== 34 ===\n",
      "chunk.text (412 tokens):\n",
      "'.........................................................................................................................., 1 = 58. AWS CodeCommit ................................................................................................................................., 1 = 58. AWS CodeDeploy .................................................................................................................................., 1 = 58. AWS CodePipeline'\n",
      "chunker.contextualize(chunk) (422 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.........................................................................................................................., 1 = 58. AWS CodeCommit ................................................................................................................................., 1 = 58. AWS CodeDeploy .................................................................................................................................., 1 = 58. AWS CodePipeline'\n",
      "\n",
      "=== 35 ===\n",
      "chunk.text (399 tokens):\n",
      "'................................................................................................................................. 58, 1 = . Amazon Corretto ..................................................................................................................................., 1 = 59. AWS Fault Injection Service ................................................................................................................, 1 = 59. Amazon Q Developer'\n",
      "chunker.contextualize(chunk) (409 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................. 58, 1 = . Amazon Corretto ..................................................................................................................................., 1 = 59. AWS Fault Injection Service ................................................................................................................, 1 = 59. Amazon Q Developer'\n",
      "\n",
      "=== 36 ===\n",
      "chunk.text (424 tokens):\n",
      "'..........................................................................................................................., 1 = 59. AWS X-Ray .............................................................................................................................................., 1 = 60. End user computing .................................................................................................................................., 1 = 60. Frontend web and mobile services'\n",
      "chunker.contextualize(chunk) (434 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..........................................................................................................................., 1 = 59. AWS X-Ray .............................................................................................................................................., 1 = 60. End user computing .................................................................................................................................., 1 = 60. Frontend web and mobile services'\n",
      "\n",
      "=== 37 ===\n",
      "chunk.text (407 tokens):\n",
      "'........................................................................................................, 1 = 62. AWS Amplify .........................................................................................................................................., 1 = 63. AWS AppSync ........................................................................................................................................, 1 = 63. AWS Device Farm'\n",
      "chunker.contextualize(chunk) (417 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................, 1 = 62. AWS Amplify .........................................................................................................................................., 1 = 63. AWS AppSync ........................................................................................................................................, 1 = 63. AWS Device Farm'\n",
      "\n",
      "=== 38 ===\n",
      "chunk.text (416 tokens):\n",
      "'.................................................................................................................................., 1 = 63. Amazon Location Service ...................................................................................................................., 1 = 64. Game tech .................................................................................................................................................... 64, 1 = . IoT'\n",
      "chunker.contextualize(chunk) (426 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.................................................................................................................................., 1 = 63. Amazon Location Service ...................................................................................................................., 1 = 64. Game tech .................................................................................................................................................... 64, 1 = . IoT'\n",
      "\n",
      "=== 39 ===\n",
      "chunk.text (454 tokens):\n",
      "'.................................................................................................................................................................., 1 = 64. AWS IoT Analytics ................................................................................................................................., 1 = 66. AWS IoT Button ..................................................................................................................................... 67, 1 = . AWS IoT Core'\n",
      "chunker.contextualize(chunk) (464 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.................................................................................................................................................................., 1 = 64. AWS IoT Analytics ................................................................................................................................., 1 = 66. AWS IoT Button ..................................................................................................................................... 67, 1 = . AWS IoT Core'\n",
      "\n",
      "=== 40 ===\n",
      "chunk.text (392 tokens):\n",
      "'........................................................................................................................................., 1 = 67. AWS IoT Device Defender ..................................................................................................................., 1 = 67. AWS IoT Device Management ............................................................................................................, 1 = 68. AWS IoT Events'\n",
      "chunker.contextualize(chunk) (402 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................................................., 1 = 67. AWS IoT Device Defender ..................................................................................................................., 1 = 67. AWS IoT Device Management ............................................................................................................, 1 = 68. AWS IoT Events'\n",
      "\n",
      "=== 41 ===\n",
      "chunk.text (418 tokens):\n",
      "'....................................................................................................................................., 1 = 68. AWS IoT ExpressLink ............................................................................................................................, 1 = 69. AWS IoT FleetWise ................................................................................................................................ 69, 1 = . AWS IoT Greengrass'\n",
      "chunker.contextualize(chunk) (428 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................................................., 1 = 68. AWS IoT ExpressLink ............................................................................................................................, 1 = 69. AWS IoT FleetWise ................................................................................................................................ 69, 1 = . AWS IoT Greengrass'\n",
      "\n",
      "=== 42 ===\n",
      "chunk.text (410 tokens):\n",
      "'............................................................................................................................., 1 = 70. AWS IoT SiteWise .................................................................................................................................. 70, 1 = . AWS IoT TwinMaker ............................................................................................................................., 1 = 71. FreeRTOS'\n",
      "chunker.contextualize(chunk) (420 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................., 1 = 70. AWS IoT SiteWise .................................................................................................................................. 70, 1 = . AWS IoT TwinMaker ............................................................................................................................., 1 = 71. FreeRTOS'\n",
      "\n",
      "=== 43 ===\n",
      "chunk.text (460 tokens):\n",
      "'................................................................................................................................................, 1 = 71. ML and AI ...................................................................................................................................................., 1 = 72. ML and AI ...................................................................................................................................................., 1 = 72'\n",
      "chunker.contextualize(chunk) (470 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................................, 1 = 71. ML and AI ...................................................................................................................................................., 1 = 72. ML and AI ...................................................................................................................................................., 1 = 72'\n",
      "\n",
      "=== 44 ===\n",
      "chunk.text (405 tokens):\n",
      "'Amazon Augmented AI ........................................................................................................................ 74, 1 = . Amazon Bedrock ..................................................................................................................................., 1 = 74. Amazon CodeGuru ................................................................................................................................, 1 = 75. Amazon Comprehend'\n",
      "chunker.contextualize(chunk) (415 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAmazon Augmented AI ........................................................................................................................ 74, 1 = . Amazon Bedrock ..................................................................................................................................., 1 = 74. Amazon CodeGuru ................................................................................................................................, 1 = 75. Amazon Comprehend'\n",
      "\n",
      "=== 45 ===\n",
      "chunk.text (130 tokens):\n",
      "'.........................................................................................................................., 1 = 75. Amazon DevOps'\n",
      "chunker.contextualize(chunk) (140 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.........................................................................................................................., 1 = 75. Amazon DevOps'\n",
      "\n",
      "=== 46 ===\n",
      "chunk.text (395 tokens):\n",
      "'Guru .........................................................................................................................., 1 = 75. Amazon Forecast ..................................................................................................................................., 1 = 76. Amazon Fraud Detector ......................................................................................................................, 1 = 77. Amazon Comprehend Medical'\n",
      "chunker.contextualize(chunk) (405 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nGuru .........................................................................................................................., 1 = 75. Amazon Forecast ..................................................................................................................................., 1 = 76. Amazon Fraud Detector ......................................................................................................................, 1 = 77. Amazon Comprehend Medical'\n",
      "\n",
      "=== 47 ===\n",
      "chunk.text (403 tokens):\n",
      "'..........................................................................................................., 1 = 77. Amazon Kendra ....................................................................................................................................., 1 = 77. Amazon Lex ............................................................................................................................................, 1 = 78. Amazon Lookout for Equipment'\n",
      "chunker.contextualize(chunk) (413 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..........................................................................................................., 1 = 77. Amazon Kendra ....................................................................................................................................., 1 = 77. Amazon Lex ............................................................................................................................................, 1 = 78. Amazon Lookout for Equipment'\n",
      "\n",
      "=== 48 ===\n",
      "chunk.text (490 tokens):\n",
      "'......................................................................................................., 1 = 78. Amazon Lookout for Metrics .............................................................................................................., 1 = 79. Amazon Lookout for Vision ................................................................................................................, 1 = 79. Amazon Monitron ................................................................................................................................., 1 = 80. Amazon PartyRock'\n",
      "chunker.contextualize(chunk) (500 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................., 1 = 78. Amazon Lookout for Metrics .............................................................................................................., 1 = 79. Amazon Lookout for Vision ................................................................................................................, 1 = 79. Amazon Monitron ................................................................................................................................., 1 = 80. Amazon PartyRock'\n",
      "\n",
      "=== 49 ===\n",
      "chunk.text (412 tokens):\n",
      "'................................................................................................................................ 80, 1 = . Amazon Personalize ............................................................................................................................., 1 = 80. Amazon Polly ........................................................................................................................................., 1 = 81. Amazon Q'\n",
      "chunker.contextualize(chunk) (422 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................ 80, 1 = . Amazon Personalize ............................................................................................................................., 1 = 80. Amazon Polly ........................................................................................................................................., 1 = 81. Amazon Q'\n",
      "\n",
      "=== 50 ===\n",
      "chunk.text (416 tokens):\n",
      "'..............................................................................................................................................., 1 = 82. Amazon Rekognition ............................................................................................................................, 1 = 82. Amazon SageMaker AI ........................................................................................................................., 1 = 83. Amazon Textract'\n",
      "chunker.contextualize(chunk) (426 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..............................................................................................................................................., 1 = 82. Amazon Rekognition ............................................................................................................................, 1 = 82. Amazon SageMaker AI ........................................................................................................................., 1 = 83. Amazon Textract'\n",
      "\n",
      "=== 51 ===\n",
      "chunk.text (414 tokens):\n",
      "'..................................................................................................................................., 1 = 89. Amazon Transcribe ..............................................................................................................................., 1 = 90. Amazon Translate ................................................................................................................................., 1 = 91. AWS DeepComposer'\n",
      "chunker.contextualize(chunk) (424 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..................................................................................................................................., 1 = 89. Amazon Transcribe ..............................................................................................................................., 1 = 90. Amazon Translate ................................................................................................................................., 1 = 91. AWS DeepComposer'\n",
      "\n",
      "=== 52 ===\n",
      "chunk.text (418 tokens):\n",
      "'............................................................................................................................. 91, 1 = . AWS DeepRacer ....................................................................................................................................., 1 = 91. AWS HealthLake ...................................................................................................................................., 1 = 91. AWS HealthScribe'\n",
      "chunker.contextualize(chunk) (428 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................. 91, 1 = . AWS DeepRacer ....................................................................................................................................., 1 = 91. AWS HealthLake ...................................................................................................................................., 1 = 91. AWS HealthScribe'\n",
      "\n",
      "=== 53 ===\n",
      "chunk.text (401 tokens):\n",
      "'................................................................................................................................., 1 = 92. AWS Panorama ......................................................................................................................................, 1 = 92. Management and governance ................................................................................................................., 1 = 93. AWS Auto Scaling'\n",
      "chunker.contextualize(chunk) (411 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................., 1 = 92. AWS Panorama ......................................................................................................................................, 1 = 92. Management and governance ................................................................................................................., 1 = 93. AWS Auto Scaling'\n",
      "\n",
      "=== 54 ===\n",
      "chunk.text (369 tokens):\n",
      "'................................................................................................................................., 1 = 94. Amazon Q Developer in chat applications ......................................................................................, 1 = 94. AWS CloudFormation ..........................................................................................................................., 1 = 95. AWS CloudTrail'\n",
      "chunker.contextualize(chunk) (379 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................., 1 = 94. Amazon Q Developer in chat applications ......................................................................................, 1 = 94. AWS CloudFormation ..........................................................................................................................., 1 = 95. AWS CloudTrail'\n",
      "\n",
      "=== 55 ===\n",
      "chunk.text (403 tokens):\n",
      "'......................................................................................................................................, 1 = 95. Amazon CloudWatch ............................................................................................................................, 1 = 95. AWS Compute Optimizer ...................................................................................................................., 1 = 96. AWS Console Mobile Application'\n",
      "chunker.contextualize(chunk) (413 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................................................, 1 = 95. Amazon CloudWatch ............................................................................................................................, 1 = 95. AWS Compute Optimizer ...................................................................................................................., 1 = 96. AWS Console Mobile Application'\n",
      "\n",
      "=== 56 ===\n",
      "chunk.text (106 tokens):\n",
      "'......................................................................................................, 1 = 96'\n",
      "chunker.contextualize(chunk) (116 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................, 1 = 96'\n",
      "\n",
      "=== 57 ===\n",
      "chunk.text (417 tokens):\n",
      "'AWS Control Tower .............................................................................................................................., 1 = 96. AWS Config ............................................................................................................................................, 1 = 97. AWS Health Dashboard ......................................................................................................................., 1 = 97. AWS Launch Wizard'\n",
      "chunker.contextualize(chunk) (427 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAWS Control Tower .............................................................................................................................., 1 = 96. AWS Config ............................................................................................................................................, 1 = 97. AWS Health Dashboard ......................................................................................................................., 1 = 97. AWS Launch Wizard'\n",
      "\n",
      "=== 58 ===\n",
      "chunk.text (483 tokens):\n",
      "'............................................................................................................................., 1 = 98. AWS License Manager .........................................................................................................................., 1 = 98. Amazon Managed Grafana ................................................................................................................., 1 = 99. Amazon Managed Service for Prometheus ....................................................................................., 1 = 99. AWS Organizations'\n",
      "chunker.contextualize(chunk) (493 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................., 1 = 98. AWS License Manager .........................................................................................................................., 1 = 98. Amazon Managed Grafana ................................................................................................................., 1 = 99. Amazon Managed Service for Prometheus ....................................................................................., 1 = 99. AWS Organizations'\n",
      "\n",
      "=== 59 ===\n",
      "chunk.text (420 tokens):\n",
      "'..............................................................................................................................., 1 = 99. AWS OpsWorks ..................................................................................................................................., 1 = 100. AWS Proton .......................................................................................................................................... 100, 1 = . Service Catalog'\n",
      "chunker.contextualize(chunk) (430 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..............................................................................................................................., 1 = 99. AWS OpsWorks ..................................................................................................................................., 1 = 100. AWS Proton .......................................................................................................................................... 100, 1 = . Service Catalog'\n",
      "\n",
      "=== 60 ===\n",
      "chunk.text (400 tokens):\n",
      "'..................................................................................................................................., 1 = 100. AWS Systems Manager ......................................................................................................................, 1 = 100. AWS Trusted Advisor ........................................................................................................................., 1 = 103. AWS Well-Architected Tool'\n",
      "chunker.contextualize(chunk) (410 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..................................................................................................................................., 1 = 100. AWS Systems Manager ......................................................................................................................, 1 = 100. AWS Trusted Advisor ........................................................................................................................., 1 = 103. AWS Well-Architected Tool'\n",
      "\n",
      "=== 61 ===\n",
      "chunk.text (501 tokens):\n",
      "'.............................................................................................................., 1 = 103. Media .........................................................................................................................................................., 1 = 103. Amazon Elastic Transcoder ..............................................................................................................., 1 = 104. Amazon Interactive Video Service .................................................................................................., 1 ='\n",
      "chunker.contextualize(chunk) (511 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.............................................................................................................., 1 = 103. Media .........................................................................................................................................................., 1 = 103. Amazon Elastic Transcoder ..............................................................................................................., 1 = 104. Amazon Interactive Video Service .................................................................................................., 1 ='\n",
      "\n",
      "=== 62 ===\n",
      "chunk.text (461 tokens):\n",
      "'104. Amazon Nimble Studio ....................................................................................................................., 1 = 104. AWS Elemental Appliances and Software ....................................................................................., 1 = 104. AWS Elemental MediaConnect ........................................................................................................, 1 = 105. AWS Elemental MediaConvert ........................................................................................................., 1 = 105. AWS Elemental MediaLive'\n",
      "chunker.contextualize(chunk) (471 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n104. Amazon Nimble Studio ....................................................................................................................., 1 = 104. AWS Elemental Appliances and Software ....................................................................................., 1 = 104. AWS Elemental MediaConnect ........................................................................................................, 1 = 105. AWS Elemental MediaConvert ........................................................................................................., 1 = 105. AWS Elemental MediaLive'\n",
      "\n",
      "=== 63 ===\n",
      "chunk.text (476 tokens):\n",
      "'................................................................................................................, 1 = 106. AWS Elemental MediaPackage ........................................................................................................, 1 = 106. AWS Elemental MediaStore .............................................................................................................. 106, 1 = . AWS Elemental MediaTailor ............................................................................................................., 1 = 106. Migration and transfer'\n",
      "chunker.contextualize(chunk) (486 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................, 1 = 106. AWS Elemental MediaPackage ........................................................................................................, 1 = 106. AWS Elemental MediaStore .............................................................................................................. 106, 1 = . AWS Elemental MediaTailor ............................................................................................................., 1 = 106. Migration and transfer'\n",
      "\n",
      "=== 64 ===\n",
      "chunk.text (457 tokens):\n",
      "'............................................................................................................................ 107, 1 = . AWS Application Discovery Service ................................................................................................, 1 = 108. AWS Application Migration Service ................................................................................................, 1 = 108. AWS Database Migration Service ...................................................................................................., 1 = 108. AWS Mainframe Modernization Service'\n",
      "chunker.contextualize(chunk) (467 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n............................................................................................................................ 107, 1 = . AWS Application Discovery Service ................................................................................................, 1 = 108. AWS Application Migration Service ................................................................................................, 1 = 108. AWS Database Migration Service ...................................................................................................., 1 = 108. AWS Mainframe Modernization Service'\n",
      "\n",
      "=== 65 ===\n",
      "chunk.text (502 tokens):\n",
      "'......................................................................................... 109, 1 = . AWS Migration Hub ..........................................................................................................................., 1 = 109. AWS Snow Family ..............................................................................................................................., 1 = 110. AWS DataSync ....................................................................................................................................., 1'\n",
      "chunker.contextualize(chunk) (512 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................... 109, 1 = . AWS Migration Hub ..........................................................................................................................., 1 = 109. AWS Snow Family ..............................................................................................................................., 1 = 110. AWS DataSync ....................................................................................................................................., 1'\n",
      "\n",
      "=== 66 ===\n",
      "chunk.text (375 tokens):\n",
      "'= 111. AWS Transfer Family .........................................................................................................................., 1 = 112. Networking and content delivery ......................................................................................................... 112, 1 = . Amazon API Gateway ........................................................................................................................, 1 = 114'\n",
      "chunker.contextualize(chunk) (385 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n= 111. AWS Transfer Family .........................................................................................................................., 1 = 112. Networking and content delivery ......................................................................................................... 112, 1 = . Amazon API Gateway ........................................................................................................................, 1 = 114'\n",
      "\n",
      "=== 67 ===\n",
      "chunk.text (133 tokens):\n",
      "'Amazon CloudFront ..........................................................................................................................., 1 = 114. Amazon Route'\n",
      "chunker.contextualize(chunk) (143 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAmazon CloudFront ..........................................................................................................................., 1 = 114. Amazon Route'\n",
      "\n",
      "=== 68 ===\n",
      "chunk.text (413 tokens):\n",
      "'53 ..............................................................................................................................., 1 = 114. AWS Verified Access ..........................................................................................................................., 1 = 115. Amazon VPC ........................................................................................................................................, 1 = 115. Amazon VPC Lattice'\n",
      "chunker.contextualize(chunk) (423 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n53 ..............................................................................................................................., 1 = 114. AWS Verified Access ..........................................................................................................................., 1 = 115. Amazon VPC ........................................................................................................................................, 1 = 115. Amazon VPC Lattice'\n",
      "\n",
      "=== 69 ===\n",
      "chunk.text (412 tokens):\n",
      "'........................................................................................................................... 115, 1 = . AWS App Mesh ...................................................................................................................................., 1 = 116. AWS Cloud Map .................................................................................................................................., 1 = 116. AWS Direct Connect'\n",
      "chunker.contextualize(chunk) (422 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................................... 115, 1 = . AWS App Mesh ...................................................................................................................................., 1 = 116. AWS Cloud Map .................................................................................................................................., 1 = 116. AWS Direct Connect'\n",
      "\n",
      "=== 70 ===\n",
      "chunk.text (397 tokens):\n",
      "'..........................................................................................................................., 1 = 117. AWS Global Accelerator ...................................................................................................................., 1 = 117. AWS PrivateLink .................................................................................................................................., 1 = 118. AWS Private 5G'\n",
      "chunker.contextualize(chunk) (407 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..........................................................................................................................., 1 = 117. AWS Global Accelerator ...................................................................................................................., 1 = 117. AWS PrivateLink .................................................................................................................................., 1 = 118. AWS Private 5G'\n",
      "\n",
      "=== 71 ===\n",
      "chunk.text (420 tokens):\n",
      "'..................................................................................................................................., 1 = 118. AWS Transit Gateway ......................................................................................................................... 119, 1 = . AWS VPN .............................................................................................................................................., 1 = 119. Elastic Load Balancing'\n",
      "chunker.contextualize(chunk) (430 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..................................................................................................................................., 1 = 118. AWS Transit Gateway ......................................................................................................................... 119, 1 = . AWS VPN .............................................................................................................................................., 1 = 119. Elastic Load Balancing'\n",
      "\n",
      "=== 72 ===\n",
      "chunk.text (361 tokens):\n",
      "'......................................................................................................................., 1 = 120. Integrated Private Wireless on AWS ............................................................................................... 120, 1 = . Quantum technologies ..........................................................................................................................., 1 = 121. Robotics'\n",
      "chunker.contextualize(chunk) (371 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................................., 1 = 120. Integrated Private Wireless on AWS ............................................................................................... 120, 1 = . Quantum technologies ..........................................................................................................................., 1 = 121. Robotics'\n",
      "\n",
      "=== 73 ===\n",
      "chunk.text (429 tokens):\n",
      "'......................................................................................................................................................, 1 = 122. Satellite ......................................................................................................................................................, 1 = 123. Security, identity, and compliance ......................................................................................................., 1 = 124. Amazon Cognito'\n",
      "chunker.contextualize(chunk) (439 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................................................................, 1 = 122. Satellite ......................................................................................................................................................, 1 = 123. Security, identity, and compliance ......................................................................................................., 1 = 124. Amazon Cognito'\n",
      "\n",
      "=== 74 ===\n",
      "chunk.text (402 tokens):\n",
      "'................................................................................................................................., 1 = 125. Amazon Detective .............................................................................................................................., 1 = 126. Amazon GuardDuty ............................................................................................................................, 1 = 126. Amazon Inspector'\n",
      "chunker.contextualize(chunk) (412 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n................................................................................................................................., 1 = 125. Amazon Detective .............................................................................................................................., 1 = 126. Amazon GuardDuty ............................................................................................................................, 1 = 126. Amazon Inspector'\n",
      "\n",
      "=== 75 ===\n",
      "chunk.text (404 tokens):\n",
      "'..............................................................................................................................., 1 = 127. Amazon Macie ....................................................................................................................................., 1 = 128. Amazon Security Lake ......................................................................................................................., 1 = 128. Amazon Verified Permissions'\n",
      "chunker.contextualize(chunk) (414 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..............................................................................................................................., 1 = 127. Amazon Macie ....................................................................................................................................., 1 = 128. Amazon Security Lake ......................................................................................................................., 1 = 128. Amazon Verified Permissions'\n",
      "\n",
      "=== 76 ===\n",
      "chunk.text (392 tokens):\n",
      "'..........................................................................................................., 1 = 129. AWS Artifact ........................................................................................................................................, 1 = 129. AWS Audit Manager ..........................................................................................................................., 1 = 129. AWS Certificate Manager'\n",
      "chunker.contextualize(chunk) (402 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n..........................................................................................................., 1 = 129. AWS Artifact ........................................................................................................................................, 1 = 129. AWS Audit Manager ..........................................................................................................................., 1 = 129. AWS Certificate Manager'\n",
      "\n",
      "=== 77 ===\n",
      "chunk.text (393 tokens):\n",
      "'.................................................................................................................., 1 = 130. AWS CloudHSM ..................................................................................................................................., 1 = 131. AWS Directory Service ......................................................................................................................., 1 = 131. AWS Firewall Manager'\n",
      "chunker.contextualize(chunk) (403 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.................................................................................................................., 1 = 130. AWS CloudHSM ..................................................................................................................................., 1 = 131. AWS Directory Service ......................................................................................................................., 1 = 131. AWS Firewall Manager'\n",
      "\n",
      "=== 78 ===\n",
      "chunk.text (473 tokens):\n",
      "'....................................................................................................................... 131, 1 = . AWS Identity and Access Management .......................................................................................... 132, 1 = . AWS Key Management Service ........................................................................................................, 1 = 132. AWS Network Firewall ......................................................................................................................., 1 = 133. AWS Resource Access Manager'\n",
      "chunker.contextualize(chunk) (483 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................................... 131, 1 = . AWS Identity and Access Management .......................................................................................... 132, 1 = . AWS Key Management Service ........................................................................................................, 1 = 132. AWS Network Firewall ......................................................................................................................., 1 = 133. AWS Resource Access Manager'\n",
      "\n",
      "=== 79 ===\n",
      "chunk.text (108 tokens):\n",
      "'........................................................................................................ 133, 1 = '\n",
      "chunker.contextualize(chunk) (118 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................ 133, 1 = '\n",
      "\n",
      "=== 80 ===\n",
      "chunk.text (417 tokens):\n",
      "'AWS Secrets Manager ........................................................................................................................ 134, 1 = . AWS Security Hub .............................................................................................................................., 1 = 134. AWS Shield ..........................................................................................................................................., 1 = 135. AWS IAM Identity Center'\n",
      "chunker.contextualize(chunk) (427 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\nAWS Secrets Manager ........................................................................................................................ 134, 1 = . AWS Security Hub .............................................................................................................................., 1 = 134. AWS Shield ..........................................................................................................................................., 1 = 135. AWS IAM Identity Center'\n",
      "\n",
      "=== 81 ===\n",
      "chunk.text (408 tokens):\n",
      "'.................................................................................................................., 1 = 136. AWS WAF .............................................................................................................................................., 1 = 136. AWS WAF Captcha .............................................................................................................................. 136, 1 = . Storage'\n",
      "chunker.contextualize(chunk) (418 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n.................................................................................................................., 1 = 136. AWS WAF .............................................................................................................................................., 1 = 136. AWS WAF Captcha .............................................................................................................................. 136, 1 = . Storage'\n",
      "\n",
      "=== 82 ===\n",
      "chunk.text (425 tokens):\n",
      "'......................................................................................................................................................., 1 = 137. AWS Backup ........................................................................................................................................., 1 = 138. Amazon Elastic Block Store .............................................................................................................. 138, 1 = . AWS Elastic Disaster Recovery'\n",
      "chunker.contextualize(chunk) (435 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................................................................., 1 = 137. AWS Backup ........................................................................................................................................., 1 = 138. Amazon Elastic Block Store .............................................................................................................. 138, 1 = . AWS Elastic Disaster Recovery'\n",
      "\n",
      "=== 83 ===\n",
      "chunk.text (502 tokens):\n",
      "'........................................................................................................., 1 = 138. Amazon Elastic File System .............................................................................................................. 139, 1 = . Amazon File Cache ............................................................................................................................., 1 = 140. Amazon FSx for Lustre ......................................................................................................................, 1 = 140. Amazon FSx for NetApp ONTAP'\n",
      "chunker.contextualize(chunk) (512 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n........................................................................................................., 1 = 138. Amazon Elastic File System .............................................................................................................. 139, 1 = . Amazon File Cache ............................................................................................................................., 1 = 140. Amazon FSx for Lustre ......................................................................................................................, 1 = 140. Amazon FSx for NetApp ONTAP'\n",
      "\n",
      "=== 84 ===\n",
      "chunk.text (451 tokens):\n",
      "'....................................................................................................., 1 = 140. Amazon FSx for OpenZFS ................................................................................................................. 141, 1 = . Amazon FSx for Windows File Server ............................................................................................, 1 = 141. Amazon Simple Storage Service ....................................................................................................., 1 = 142. AWS Storage Gateway'\n",
      "chunker.contextualize(chunk) (461 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................., 1 = 140. Amazon FSx for OpenZFS ................................................................................................................. 141, 1 = . Amazon FSx for Windows File Server ............................................................................................, 1 = 141. Amazon Simple Storage Service ....................................................................................................., 1 = 142. AWS Storage Gateway'\n",
      "\n",
      "=== 85 ===\n",
      "chunk.text (402 tokens):\n",
      "'......................................................................................................................., 1 = 143. Next steps ...................................................................................................................................., 1 = 144. Conclusion ...................................................................................................................................., 1 = 144. Conclusion'\n",
      "chunker.contextualize(chunk) (412 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n......................................................................................................................., 1 = 143. Next steps ...................................................................................................................................., 1 = 144. Conclusion ...................................................................................................................................., 1 = 144. Conclusion'\n",
      "\n",
      "=== 86 ===\n",
      "chunk.text (404 tokens):\n",
      "'...................................................................................................................................., 1 = 146. Resources ...................................................................................................................................... 147, 1 = . Document history ........................................................................................................................, 1 = 148.'\n",
      "chunker.contextualize(chunk) (414 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n...................................................................................................................................., 1 = 146. Resources ...................................................................................................................................... 147, 1 = . Document history ........................................................................................................................, 1 = 148.'\n",
      "\n",
      "=== 87 ===\n",
      "chunk.text (305 tokens):\n",
      "'....................................................................................................................................................................., 1 = 153. AWS Glossary ..............................................................................................................................., 1 = 153'\n",
      "chunker.contextualize(chunk) (315 tokens):\n",
      "'Overview of Amazon Web Services: AWS Whitepaper\\n....................................................................................................................................................................., 1 = 153. AWS Glossary ..............................................................................................................................., 1 = 153'\n",
      "\n",
      "=== 88 ===\n",
      "chunk.text (171 tokens):\n",
      "'Publication date: August 27, 2024 (\\nAmazon Web Services offers a broad set of global cloud-based products including compute, storage, databases, analytics, networking, mobile, developer tools, management tools, loT, security, and enterprise applications: on-demand, available in seconds, with pay-as-you-go pricing. From data warenousing to deployment tools, directories to content delivery, over 200 AWS services are available.\\nNew services can be provisioned quickly, without the upfront fixed expense. This allows enterprises, Start-ups, small and medium-sized businesses, and customers in the public sector to access the Duilding blocks they need to respond quickly to changing business requirements. This whitepaper provides you with an overview of the benefits of the AWS Cloud and introduces you to the services that make up the platform.'\n",
      "chunker.contextualize(chunk) (176 tokens):\n",
      "'Overview of Amazon Web Services\\nPublication date: August 27, 2024 (\\nAmazon Web Services offers a broad set of global cloud-based products including compute, storage, databases, analytics, networking, mobile, developer tools, management tools, loT, security, and enterprise applications: on-demand, available in seconds, with pay-as-you-go pricing. From data warenousing to deployment tools, directories to content delivery, over 200 AWS services are available.\\nNew services can be provisioned quickly, without the upfront fixed expense. This allows enterprises, Start-ups, small and medium-sized businesses, and customers in the public sector to access the Duilding blocks they need to respond quickly to changing business requirements. This whitepaper provides you with an overview of the benefits of the AWS Cloud and introduces you to the services that make up the platform.'\n",
      "\n",
      "=== 89 ===\n",
      "chunk.text (167 tokens):\n",
      "'In 2006, Amazon Web Services (AWS) began offering IT infrastructure services to businesses as web services—now commonly known as cloud computing. One of the key benefits of cloud computing is the opportunity to replace upfront capital infrastructure expenses with low variable costs that scale with your business. With the cloud, businesses no longer need to plan for and procure servers and other IT infrastructure weeks or months in advance. Instead, they can instantly spin up hundreds or thousands of servers in minutes and deliver results faster.\\nToday, AWS provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers hundreds of thousands of businesses in 190 countries around the world.\\nThis video explores how millions of customers use AWS to take advantage of the efficiencies of cloud computing: What is AWS? | Amazon Web Services introduction'\n",
      "chunker.contextualize(chunk) (168 tokens):\n",
      "'Introduction\\nIn 2006, Amazon Web Services (AWS) began offering IT infrastructure services to businesses as web services—now commonly known as cloud computing. One of the key benefits of cloud computing is the opportunity to replace upfront capital infrastructure expenses with low variable costs that scale with your business. With the cloud, businesses no longer need to plan for and procure servers and other IT infrastructure weeks or months in advance. Instead, they can instantly spin up hundreds or thousands of servers in minutes and deliver results faster.\\nToday, AWS provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers hundreds of thousands of businesses in 190 countries around the world.\\nThis video explores how millions of customers use AWS to take advantage of the efficiencies of cloud computing: What is AWS? | Amazon Web Services introduction'\n",
      "\n",
      "=== 90 ===\n",
      "chunk.text (222 tokens):\n",
      "\"Cloud computing is the on-demand delivery of compute power, database, storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing. Whether you are running applications that share photos to millions of mobile users or you're supporting the critical operations of your business, a cloud services platform provides rapid access to flexible and low-cost IT resources. With cloud computing, you don't need to make large upfront investments in hardware and spend a lot of time on the heavy lifting of managing that hardware. Instead, you can provision exactly the right type and size of computing resources you need to power your newest bright idea or operate your IT department. You can access as many resources as you need, almost instantly, and only pay for what you use.\\nCloud computing provides a simple way to access servers, storage, databases and a broad set of application services over the internet. A cloud services platform such as Amazon Web Services owns and maintains the network-connected hardware required for these application services, while you provision and use what you need via a web application.\"\n",
      "chunker.contextualize(chunk) (227 tokens):\n",
      "\"What Is cloud computing?\\nCloud computing is the on-demand delivery of compute power, database, storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing. Whether you are running applications that share photos to millions of mobile users or you're supporting the critical operations of your business, a cloud services platform provides rapid access to flexible and low-cost IT resources. With cloud computing, you don't need to make large upfront investments in hardware and spend a lot of time on the heavy lifting of managing that hardware. Instead, you can provision exactly the right type and size of computing resources you need to power your newest bright idea or operate your IT department. You can access as many resources as you need, almost instantly, and only pay for what you use.\\nCloud computing provides a simple way to access servers, storage, databases and a broad set of application services over the internet. A cloud services platform such as Amazon Web Services owns and maintains the network-connected hardware required for these application services, while you provision and use what you need via a web application.\"\n",
      "\n",
      "=== 91 ===\n",
      "chunk.text (365 tokens):\n",
      "\"¢ Trade fixed expense for variable expense — Instead of having to invest heavily in data centers and servers before you know how you're going to use them, you can pay only when you consume computing resources, and pay only for how much you consume.\\n¢ Benefit from massive economies of scale — By using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, providers such as AWS can achieve higher economies of scale, which translates into lower pay aS-you-go prices.\\ne Stop guessing capacity — Eliminate guessing on your infrastructure capacity needs. When you make a Capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes' notice.\\n- Increase speed and agility — In a cloud computing environment, new IT resources are only a click away, which means that you reduce the time to make those resources available to your developers trom weeks to just minutes. This results in a dramatic increase in agility for the organization, since the cost and time it takes to experiment and develop is significantly lower.\\ne Stop spending money running and maintaining data centers — Focus on projects that ditferentiate your business, not the infrastructure. Cloud computing lets you focus on your own customers, rather than on the neavy lifting of racking, stacking, and powering servers.\\n- Go global in minutes — Easily deploy your application in multiple regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at minimal cost.\"\n",
      "chunker.contextualize(chunk) (370 tokens):\n",
      "\"Six advantages of cloud computing\\n¢ Trade fixed expense for variable expense — Instead of having to invest heavily in data centers and servers before you know how you're going to use them, you can pay only when you consume computing resources, and pay only for how much you consume.\\n¢ Benefit from massive economies of scale — By using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers is aggregated in the cloud, providers such as AWS can achieve higher economies of scale, which translates into lower pay aS-you-go prices.\\ne Stop guessing capacity — Eliminate guessing on your infrastructure capacity needs. When you make a Capacity decision prior to deploying an application, you often end up either sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little capacity as you need, and scale up and down as required with only a few minutes' notice.\\n- Increase speed and agility — In a cloud computing environment, new IT resources are only a click away, which means that you reduce the time to make those resources available to your developers trom weeks to just minutes. This results in a dramatic increase in agility for the organization, since the cost and time it takes to experiment and develop is significantly lower.\\ne Stop spending money running and maintaining data centers — Focus on projects that ditferentiate your business, not the infrastructure. Cloud computing lets you focus on your own customers, rather than on the neavy lifting of racking, stacking, and powering servers.\\n- Go global in minutes — Easily deploy your application in multiple regions around the world with just a few clicks. This means you can provide lower latency and a better experience for your customers at minimal cost.\"\n",
      "\n",
      "=== 92 ===\n",
      "chunk.text (74 tokens):\n",
      "'Cloud computing provides developers and IT departments with the ability to focus on what matters most and avoid undifferentiated work such as procurement, maintenance, and capacity planning. As cloud computing has grown in popularity, several different models and deployment strategies have emerged to help meet specific needs of different users. Each type provides you with different levels of control, flexibility, and management.'\n",
      "chunker.contextualize(chunk) (78 tokens):\n",
      "'Types of cloud computing\\nCloud computing provides developers and IT departments with the ability to focus on what matters most and avoid undifferentiated work such as procurement, maintenance, and capacity planning. As cloud computing has grown in popularity, several different models and deployment strategies have emerged to help meet specific needs of different users. Each type provides you with different levels of control, flexibility, and management.'\n",
      "\n",
      "=== 93 ===\n",
      "chunk.text (87 tokens):\n",
      "'A cloud-based application is fully deployed in the cloud and all parts of the application run in the cloud. Applications in the cloud have either been created in the cloud or have been migrated from an existing infrastructure to take advantage of the benefits of cloud computing. Cloudbased applications can be built on low-level infrastructure pieces or can use higher level services that provide abstraction from the management, architecting, and scaling requirements of core infrastructure.'\n",
      "chunker.contextualize(chunk) (89 tokens):\n",
      "'Deployment models\\nA cloud-based application is fully deployed in the cloud and all parts of the application run in the cloud. Applications in the cloud have either been created in the cloud or have been migrated from an existing infrastructure to take advantage of the benefits of cloud computing. Cloudbased applications can be built on low-level infrastructure pieces or can use higher level services that provide abstraction from the management, architecting, and scaling requirements of core infrastructure.'\n",
      "\n",
      "=== 94 ===\n",
      "chunk.text (83 tokens):\n",
      "\"The deployment of resources on-premises, using virtualization and resource management tools, is sometimes called the private cloud. On-premises deployment doesn't provide many of the benefits of cloud computing but it is sometimes sought for its ability to provide dedicated resources. In most cases, this deployment model is the same as legacy IT infrastructure while using application management and virtualization tecnnologies to try and increase resource utilization.\"\n",
      "chunker.contextualize(chunk) (90 tokens):\n",
      "\"Private cloud (on-premises)\\nThe deployment of resources on-premises, using virtualization and resource management tools, is sometimes called the private cloud. On-premises deployment doesn't provide many of the benefits of cloud computing but it is sometimes sought for its ability to provide dedicated resources. In most cases, this deployment model is the same as legacy IT infrastructure while using application management and virtualization tecnnologies to try and increase resource utilization.\"\n",
      "\n",
      "=== 95 ===\n",
      "chunk.text (97 tokens):\n",
      "\"A hybrid deployment is a way to connect infrastructure and applications between cloud-based resources and existing resources that are not located in the cloud. The most common method of hybrid deployment is between the cloud and existing on-premises infrastructure to extend, and grow, an organization's infrastructure into the cloud while connecting cloud resources to the internal system. For more information on how AWS can help you with your hybrid deployment, visit our AWS Solutions for Hybrid and Multicloud page.\\nDeployment models\"\n",
      "chunker.contextualize(chunk) (98 tokens):\n",
      "\"Hybrid\\nA hybrid deployment is a way to connect infrastructure and applications between cloud-based resources and existing resources that are not located in the cloud. The most common method of hybrid deployment is between the cloud and existing on-premises infrastructure to extend, and grow, an organization's infrastructure into the cloud while connecting cloud resources to the internal system. For more information on how AWS can help you with your hybrid deployment, visit our AWS Solutions for Hybrid and Multicloud page.\\nDeployment models\"\n",
      "\n",
      "=== 96 ===\n",
      "chunk.text (117 tokens):\n",
      "'The AWS Cloud infrastructure is built around AWS Regions and Availability Zones. An AWS Region is a physical location in the world where we have multiple Availability Zones. Availability Zones consist of one or more discrete data centers, each with redundant power, networking, and connectivity, housed in separate facilities. These Availability Zones offer you the ability to operate production applications and databases that are more highly available, fault tolerant, and scalable than would be possible from a single data center. For the latest information on the AWS Cloud Availability Zones and AWS Regions, refer to AWS Global Infrastructure.'\n",
      "chunker.contextualize(chunk) (119 tokens):\n",
      "'Global infrastructure\\nThe AWS Cloud infrastructure is built around AWS Regions and Availability Zones. An AWS Region is a physical location in the world where we have multiple Availability Zones. Availability Zones consist of one or more discrete data centers, each with redundant power, networking, and connectivity, housed in separate facilities. These Availability Zones offer you the ability to operate production applications and databases that are more highly available, fault tolerant, and scalable than would be possible from a single data center. For the latest information on the AWS Cloud Availability Zones and AWS Regions, refer to AWS Global Infrastructure.'\n",
      "\n",
      "=== 97 ===\n",
      "chunk.text (471 tokens):\n",
      "\"Cloud security at AWS is the highest priority. As organizations embrace the scalability and flexibility of the cloud, AWS is helping them evolve security, identity, and compliance into key business enablers. AWS builds security into the core of our cloud infrastructure, and offers foundational services to help organizations meet their unique security requirements in the cloud.\\nAs an AWS customer, you will benefit from a data center and network architecture built to meet the requirements of the most security-sensitive organizations. Security in the cloud is much like security in your on-premises data centers—only without the costs of maintaining facilities and nardware. In the cloud, you don't nave to manage physical servers or storage devices. Instead, you use software-based security tools to monitor and protect the tlow of information into and out of your cloud resources.\\nAn advantage of the AWS Cloud is that it allows you to scale and innovate, while maintaining a secure environment and paying only for the services you use. This means that you can have the security you need at a lower cost than in an on-premises environment.\\nAs an AWS customer you inherit all the best practices of AWS policies, architecture, and operational processes built to satisfy the requirements of our most security-sensitive customers. Get the flexibility and agility you need in security controls.\\nThe AWS Cloud enables a shared responsibility model. While AWS manages security of the cloud, you are responsible for security in the cloud. This means that you retain control of the security you choose to implement to protect your own content, platform, applications, systems, and networks no differently than you would in an on-site data center.\\nAWS provides you with guidance and expertise througn online resources, personnel, and partners. AWS provides you with advisories for current issues, plus you have the opportunity to work with AWS when you encounter security issues.\\nYou get access to hundreds of tools and features to help you to meet your security objectives. AWS provides security-specific tools and features across network security, configuration management, access control, and data encryption.\\nSecurity\\nFinally, AWS environments are continuously audited, with certifications from accreditation bodies across geographies and verticals. In the AWS environment, you can take advantage of automated tools for asset inventory and privileged access reporting.\"\n",
      "chunker.contextualize(chunk) (472 tokens):\n",
      "\"Security\\nCloud security at AWS is the highest priority. As organizations embrace the scalability and flexibility of the cloud, AWS is helping them evolve security, identity, and compliance into key business enablers. AWS builds security into the core of our cloud infrastructure, and offers foundational services to help organizations meet their unique security requirements in the cloud.\\nAs an AWS customer, you will benefit from a data center and network architecture built to meet the requirements of the most security-sensitive organizations. Security in the cloud is much like security in your on-premises data centers—only without the costs of maintaining facilities and nardware. In the cloud, you don't nave to manage physical servers or storage devices. Instead, you use software-based security tools to monitor and protect the tlow of information into and out of your cloud resources.\\nAn advantage of the AWS Cloud is that it allows you to scale and innovate, while maintaining a secure environment and paying only for the services you use. This means that you can have the security you need at a lower cost than in an on-premises environment.\\nAs an AWS customer you inherit all the best practices of AWS policies, architecture, and operational processes built to satisfy the requirements of our most security-sensitive customers. Get the flexibility and agility you need in security controls.\\nThe AWS Cloud enables a shared responsibility model. While AWS manages security of the cloud, you are responsible for security in the cloud. This means that you retain control of the security you choose to implement to protect your own content, platform, applications, systems, and networks no differently than you would in an on-site data center.\\nAWS provides you with guidance and expertise througn online resources, personnel, and partners. AWS provides you with advisories for current issues, plus you have the opportunity to work with AWS when you encounter security issues.\\nYou get access to hundreds of tools and features to help you to meet your security objectives. AWS provides security-specific tools and features across network security, configuration management, access control, and data encryption.\\nSecurity\\nFinally, AWS environments are continuously audited, with certifications from accreditation bodies across geographies and verticals. In the AWS environment, you can take advantage of automated tools for asset inventory and privileged access reporting.\"\n",
      "\n",
      "=== 98 ===\n",
      "chunk.text (121 tokens):\n",
      "'¢ Keep Your data safe — The AWS infrastructure puts strong safeguards in place to help protect your privacy. All data is stored in highly secure AWS data centers.\\ne Meet compliance requirements — AWS manages dozens of compliance programs in its infrastructure. This means that segments of your compliance have already been completed.\\ne Save money — Cut costs by using AWS data centers. Maintain the highest standard of security without having to manage your own facility\\ne Scale quickly — Security scales with your AWS Cloud usage. No matter the size of your business, the AWS infrastructure is designed to keep your data Safe.'\n",
      "chunker.contextualize(chunk) (126 tokens):\n",
      "'Benefits of AWS security\\n¢ Keep Your data safe — The AWS infrastructure puts strong safeguards in place to help protect your privacy. All data is stored in highly secure AWS data centers.\\ne Meet compliance requirements — AWS manages dozens of compliance programs in its infrastructure. This means that segments of your compliance have already been completed.\\ne Save money — Cut costs by using AWS data centers. Maintain the highest standard of security without having to manage your own facility\\ne Scale quickly — Security scales with your AWS Cloud usage. No matter the size of your business, the AWS infrastructure is designed to keep your data Safe.'\n",
      "\n",
      "=== 99 ===\n",
      "chunk.text (219 tokens):\n",
      "'AWS Cloud Compliance helps you understand the robust controls in place at AWS for security and data protection in the cloud. Compliance is a shared responsibility between AWS and the customer, and you can visit the Shared Responsibility Model to learn more. Customers can feel confident in operating and building on top of the security controls AWS uses on its infrastructure.\\nThe IT infrastructure that AWS provides to its customers is designed and managed in alignment with best security practices and a variety of IT security standards. The following is a partial list of assurance programs with which AWS complies:\\nSOC 1/ISAE 5402, SOC 2, SOC 3\\nFISMA, DIACAP, and FeqdRAMP\\nISO 90071, ISO 2/001, ISO 2/017, ISO 2/018\\nAWS provides customers a wide range of information on Its IT control environment in whitepapers, reports, certifications, accreditations, and other third-party attestations. More information is available in the Risk and Compliance whitepaper and the AWS Security Center.\\nBenents of AWS security'\n",
      "chunker.contextualize(chunk) (220 tokens):\n",
      "'Compliance\\nAWS Cloud Compliance helps you understand the robust controls in place at AWS for security and data protection in the cloud. Compliance is a shared responsibility between AWS and the customer, and you can visit the Shared Responsibility Model to learn more. Customers can feel confident in operating and building on top of the security controls AWS uses on its infrastructure.\\nThe IT infrastructure that AWS provides to its customers is designed and managed in alignment with best security practices and a variety of IT security standards. The following is a partial list of assurance programs with which AWS complies:\\nSOC 1/ISAE 5402, SOC 2, SOC 3\\nFISMA, DIACAP, and FeqdRAMP\\nISO 90071, ISO 2/001, ISO 2/017, ISO 2/018\\nAWS provides customers a wide range of information on Its IT control environment in whitepapers, reports, certifications, accreditations, and other third-party attestations. More information is available in the Risk and Compliance whitepaper and the AWS Security Center.\\nBenents of AWS security'\n",
      "\n",
      "=== 100 ===\n",
      "chunk.text (76 tokens):\n",
      "'AWS consists of many cloud services that you can use in combinations tailored to your business Or organizational needs. This section introduces the major AWS services by category. Choose a category to explore its services.\\nTo access the services, you can use the AWS Management Console, the AWS Command Line Interface (AWS CLI), or Software Development Kits (SDKs).'\n",
      "chunker.contextualize(chunk) (81 tokens):\n",
      "'AWS services by category\\nAWS consists of many cloud services that you can use in combinations tailored to your business Or organizational needs. This section introduces the major AWS services by category. Choose a category to explore its services.\\nTo access the services, you can use the AWS Management Console, the AWS Command Line Interface (AWS CLI), or Software Development Kits (SDKs).'\n",
      "\n",
      "=== 101 ===\n",
      "chunk.text (104 tokens):\n",
      "'e Accessing AWS services\\ne Analytics\\ne Application integration\\ne Blockcnain\\n¢ Business applications\\ne Cloud Financial Management\\ne Compute\\ne Customer enablement\\ne Containers\\ne Databases\\ne Developer tools\\ne End user computing\\ne Frontend web and mobile services\\ne Gametecn\\ne Internet of Things (loT)\\ne Machine Learning (ML) and Artificial Intelligence (Al)\\ne Management and governance\\ne Media\\ne Migration and transter\\ne Networking and content delivery\\n¢ Quantum technologies\\ne Ropotics\\ne Satellite\\ne Security, identity, and compliance\\ne Storage'\n",
      "chunker.contextualize(chunk) (105 tokens):\n",
      "'Topics\\ne Accessing AWS services\\ne Analytics\\ne Application integration\\ne Blockcnain\\n¢ Business applications\\ne Cloud Financial Management\\ne Compute\\ne Customer enablement\\ne Containers\\ne Databases\\ne Developer tools\\ne End user computing\\ne Frontend web and mobile services\\ne Gametecn\\ne Internet of Things (loT)\\ne Machine Learning (ML) and Artificial Intelligence (Al)\\ne Management and governance\\ne Media\\ne Migration and transter\\ne Networking and content delivery\\n¢ Quantum technologies\\ne Ropotics\\ne Satellite\\ne Security, identity, and compliance\\ne Storage'\n",
      "\n",
      "=== 102 ===\n",
      "chunk.text (204 tokens):\n",
      "'AWS Management Console\\nAccess and manage Amazon Web Services through the AWS Management Console, a simple and intuitive user interface. You can also use the AWS Management Console Application to quickly view resources on the go.\\nAWS Command Line Interface (AWS CLI)\\nThe AWS Command Line Interface (AWS CLI) is a unified tool to manage your AWS services. With just one tool to download and configure, you can control multiple AWS services from the command line and automate them through scripts.\\nAWS CloudShell, which can be found next to the search bar in the AWS Management Console, provides a browser-based shell that is pre-authenticated with your console credentials. Using CloudShnell, you can quickly run AWS commands and scripts without leaving your web browser.\\nSoftware Development Kits (SDKs)\\nOur Software Development Kits (SDKs) simplify using AWS services in your applications with an Application Program Interface (API) tailored to your programming language or platform.'\n",
      "chunker.contextualize(chunk) (209 tokens):\n",
      "'Accessing AWS services\\nAWS Management Console\\nAccess and manage Amazon Web Services through the AWS Management Console, a simple and intuitive user interface. You can also use the AWS Management Console Application to quickly view resources on the go.\\nAWS Command Line Interface (AWS CLI)\\nThe AWS Command Line Interface (AWS CLI) is a unified tool to manage your AWS services. With just one tool to download and configure, you can control multiple AWS services from the command line and automate them through scripts.\\nAWS CloudShell, which can be found next to the search bar in the AWS Management Console, provides a browser-based shell that is pre-authenticated with your console credentials. Using CloudShnell, you can quickly run AWS commands and scripts without leaving your web browser.\\nSoftware Development Kits (SDKs)\\nOur Software Development Kits (SDKs) simplify using AWS services in your applications with an Application Program Interface (API) tailored to your programming language or platform.'\n",
      "\n",
      "=== 103 ===\n",
      "chunk.text (104 tokens):\n",
      "'AWS provides a comprehensive set of analytics services that fit all your data analytics needs and enables organizations of all sizes and industries to reinvent their business with data. From storage and management, data governance, actions, and experiences, AWS offers purpose-built services that provide the best price-performance, scalability, and lowest cost.\\nAccessing AWS services\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS analytics service. For general information, see'\n",
      "chunker.contextualize(chunk) (105 tokens):\n",
      "'Analytics\\nAWS provides a comprehensive set of analytics services that fit all your data analytics needs and enables organizations of all sizes and industries to reinvent their business with data. From storage and management, data governance, actions, and experiences, AWS offers purpose-built services that provide the best price-performance, scalability, and lowest cost.\\nAccessing AWS services\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS analytics service. For general information, see'\n",
      "\n",
      "=== 104 ===\n",
      "chunk.text (46 tokens):\n",
      "'Analytics\\ne Amazon Redshift Serverless\\n¢ QuickSight\\ne AWS Data Exchange\\ne AWS Data Pipeline\\n¢ AWS Entity Resolution\\nGlue\\ne AWS Lake Formation\\ne Amazon Managed Streaming for Apache Kafka (Amazon MSK)'\n",
      "chunker.contextualize(chunk) (48 tokens):\n",
      "'Analytics services\\nAnalytics\\ne Amazon Redshift Serverless\\n¢ QuickSight\\ne AWS Data Exchange\\ne AWS Data Pipeline\\n¢ AWS Entity Resolution\\nGlue\\ne AWS Lake Formation\\ne Amazon Managed Streaming for Apache Kafka (Amazon MSK)'\n",
      "\n",
      "=== 105 ===\n",
      "chunk.text (188 tokens):\n",
      "\"Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to manage, and you pay only for the queries that you run.\\nAthena is easy to use. Simply point to your data in Amazon S3, define the schema, and start querying using standard SQL. Most results are delivered within seconds. With Athena, there's no need for complex extract, transform, and load (ETL) jobs to prepare your data for analysis. This makes it easy for anyone with SQL skills to quickly analyze large-scale datasets.\\nAthena is out-of-the-box integrated with AWS Glue Data Catalog, allowing you to create a unified metadata repository across various services, crawl data sources to discover schemas and populate your Catalog with new and modified table and partition definitions, and maintain schema versioning.\"\n",
      "chunker.contextualize(chunk) (190 tokens):\n",
      "\"Amazon Athena\\nAmazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to manage, and you pay only for the queries that you run.\\nAthena is easy to use. Simply point to your data in Amazon S3, define the schema, and start querying using standard SQL. Most results are delivered within seconds. With Athena, there's no need for complex extract, transform, and load (ETL) jobs to prepare your data for analysis. This makes it easy for anyone with SQL skills to quickly analyze large-scale datasets.\\nAthena is out-of-the-box integrated with AWS Glue Data Catalog, allowing you to create a unified metadata repository across various services, crawl data sources to discover schemas and populate your Catalog with new and modified table and partition definitions, and maintain schema versioning.\"\n",
      "\n",
      "=== 106 ===\n",
      "chunk.text (66 tokens):\n",
      "'Amazon CloudSearch Is a managed service in the AWS Cloud that makes it simple and costeffective to set up, Manage, and scale a search solution for your website or application. Amazon CloudSearch supports 34 languages and popular search features such as highlighting, autocomplete, and geospatial search.'\n",
      "chunker.contextualize(chunk) (71 tokens):\n",
      "'Amazon CloudaSearch\\nAmazon CloudSearch Is a managed service in the AWS Cloud that makes it simple and costeffective to set up, Manage, and scale a search solution for your website or application. Amazon CloudSearch supports 34 languages and popular search features such as highlighting, autocomplete, and geospatial search.'\n",
      "\n",
      "=== 107 ===\n",
      "chunk.text (260 tokens):\n",
      "'Amazon DataZone is a data management service that you can use to publish data and make it available to the business data catalog through your personalized web application. You can\\nAmazon Athena\\naccess your data more securely regardless of where it is stored—on AWS, on premises, or in SaaS applications such as Salesforce. Amazon DataZone simplifies your experience across AWS services such as Amazon Redshift, Amazon Athena, AWS Glue, AWS Lake Formation, and QuickSight.\\nAmazon EMR is the industry-leading cloud big data platform for processing vast amounts of data using open source tools sucn as Apache Spark, Apache Hive, Apache HBase, Apache Flink, Apache Hudi, and Presto. Amazon EMR makes It easy to set up, operate, and scale your big data environments by automating time-consuming tasks such as provisioning capacity and tuning clusters. With Amazon EMR, you can run petabyte-scale analysis at less than half of the cost of traditional on-premises solutions and over 3x faster than standard Apache Spark. You can run workloads on Amazon EC2 instances, on Amazon Elastic Kubernetes Service (Amazon EKS) clusters, Or on-premises using Amazon EMR on AWS Outposts.'\n",
      "chunker.contextualize(chunk) (263 tokens):\n",
      "'Amazon DataZone\\nAmazon DataZone is a data management service that you can use to publish data and make it available to the business data catalog through your personalized web application. You can\\nAmazon Athena\\naccess your data more securely regardless of where it is stored—on AWS, on premises, or in SaaS applications such as Salesforce. Amazon DataZone simplifies your experience across AWS services such as Amazon Redshift, Amazon Athena, AWS Glue, AWS Lake Formation, and QuickSight.\\nAmazon EMR is the industry-leading cloud big data platform for processing vast amounts of data using open source tools sucn as Apache Spark, Apache Hive, Apache HBase, Apache Flink, Apache Hudi, and Presto. Amazon EMR makes It easy to set up, operate, and scale your big data environments by automating time-consuming tasks such as provisioning capacity and tuning clusters. With Amazon EMR, you can run petabyte-scale analysis at less than half of the cost of traditional on-premises solutions and over 3x faster than standard Apache Spark. You can run workloads on Amazon EC2 instances, on Amazon Elastic Kubernetes Service (Amazon EKS) clusters, Or on-premises using Amazon EMR on AWS Outposts.'\n",
      "\n",
      "=== 108 ===\n",
      "chunk.text (242 tokens):\n",
      "'Amazon FinSpace is a data management and analytics service purpose-built for the financial services industry (FSI). FinSpace reduces the time you spend finding and preparing petabytes of financial data to be ready for analysis from months to minutes.\\nFinancial services organizations analyze data from internal data stores such as portfolio, actuarial, and risk management systems as well as petabytes of data from third-party data feeds, such as historical securities prices from stock exchanges. It can take months to find the right data, get permissions to access the data in a compliant way, and prepare it for analysis.\\nFinSpace removes the heavy lifting of building and maintaining a data management system for financial analytics. With FinSpace, you collect data and catalog it by relevant business concepts such as asset class, risk classification, or geographic region. FinSpace makes it easy to discover and share data across your organization in accordance with your compliance requirements. You define your data access policies in one place and FinSpace enforces them while keeping audit logs to allow for compliance and activity reporting. FinSpace also includes a library of 100+ functions, such as time bars and Bollinger bands, for you to prepare data for analysis.'\n",
      "chunker.contextualize(chunk) (245 tokens):\n",
      "'Amazon FinSpace\\nAmazon FinSpace is a data management and analytics service purpose-built for the financial services industry (FSI). FinSpace reduces the time you spend finding and preparing petabytes of financial data to be ready for analysis from months to minutes.\\nFinancial services organizations analyze data from internal data stores such as portfolio, actuarial, and risk management systems as well as petabytes of data from third-party data feeds, such as historical securities prices from stock exchanges. It can take months to find the right data, get permissions to access the data in a compliant way, and prepare it for analysis.\\nFinSpace removes the heavy lifting of building and maintaining a data management system for financial analytics. With FinSpace, you collect data and catalog it by relevant business concepts such as asset class, risk classification, or geographic region. FinSpace makes it easy to discover and share data across your organization in accordance with your compliance requirements. You define your data access policies in one place and FinSpace enforces them while keeping audit logs to allow for compliance and activity reporting. FinSpace also includes a library of 100+ functions, such as time bars and Bollinger bands, for you to prepare data for analysis.'\n",
      "\n",
      "=== 109 ===\n",
      "chunk.text (177 tokens):\n",
      "'Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. Amazon Kinesis offers key capabilities to cost-effectively process streaming data at any scale, along with the flexibility to choose the\\nAmazon EMR\\ntools that best suit the requirements of your application. With Amazon Kinesis, you can ingest realtime data such as video, audio, application logs, website clickstreams, and loT telemetry data for machine learning (ML), analytics, and other applications. Amazon Kinesis enables you to process and analyze data as it arrives and respond instantly instead of having to wait until all your data is collected before the processing can begin.\\nAmazon Kinesis currently offers four services: Firehose, Managed Service for Apache Flink, Kinesis Data Streams, and Kinesis Video Streams.'\n",
      "chunker.contextualize(chunk) (180 tokens):\n",
      "'Amazon Kinesis\\nAmazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information. Amazon Kinesis offers key capabilities to cost-effectively process streaming data at any scale, along with the flexibility to choose the\\nAmazon EMR\\ntools that best suit the requirements of your application. With Amazon Kinesis, you can ingest realtime data such as video, audio, application logs, website clickstreams, and loT telemetry data for machine learning (ML), analytics, and other applications. Amazon Kinesis enables you to process and analyze data as it arrives and respond instantly instead of having to wait until all your data is collected before the processing can begin.\\nAmazon Kinesis currently offers four services: Firehose, Managed Service for Apache Flink, Kinesis Data Streams, and Kinesis Video Streams.'\n",
      "\n",
      "=== 110 ===\n",
      "chunk.text (238 tokens):\n",
      "\"Amazon Data Firehose is the easiest way to reliably load streaming data into data stores and analytics tools. It can capture, transform, and load streaming data into Amazon $3, Amazon Redshift, Amazon OpenSearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you're already using today. It is a Tully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, transform, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security.\\nYou can easily create a Firehose delivery stream from the AWS Management Console, configure it with a few clicks, and start sending data to the stream from hundreds of thousands of data sources to be loaded continuously to AWS—all in just a few minutes. You can also configure your delivery stream to automatically convert the incoming data to columnar formats such as Apache Parquet and Apache ORC, before the data Is delivered to Amazon S3, for cost-effective storage and analytics.\"\n",
      "chunker.contextualize(chunk) (243 tokens):\n",
      "\"Amazon Data Firehose\\nAmazon Data Firehose is the easiest way to reliably load streaming data into data stores and analytics tools. It can capture, transform, and load streaming data into Amazon $3, Amazon Redshift, Amazon OpenSearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you're already using today. It is a Tully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, transform, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security.\\nYou can easily create a Firehose delivery stream from the AWS Management Console, configure it with a few clicks, and start sending data to the stream from hundreds of thousands of data sources to be loaded continuously to AWS—all in just a few minutes. You can also configure your delivery stream to automatically convert the incoming data to columnar formats such as Apache Parquet and Apache ORC, before the data Is delivered to Amazon S3, for cost-effective storage and analytics.\"\n",
      "\n",
      "=== 111 ===\n",
      "chunk.text (146 tokens):\n",
      "'Amazon Managed Service for Apache Flink is the easiest way to analyze streaming data, gain actionable insights, and respond to your business and customer needs in real time. Amazon Managed Service for Apache Flink reduces the complexity of building, managing, and integrating streaming applications with other AWS services. SQL users can easily query streaming data or Duild entire streaming applications using templates and an interactive SQL editor. Java developers Can quickly build sophisticated streaming applications using open source Java libraries and AWS integrations to transform and analyze data in real-time.\\nAmazon Managed Service for Apache Flink takes care of everything required to run your queries continuously and scales automatically to match the volume and throughput rate of your incoming\\nAmazon Data Firenose'\n",
      "chunker.contextualize(chunk) (153 tokens):\n",
      "'Amazon Managed Service for Apache Flink\\nAmazon Managed Service for Apache Flink is the easiest way to analyze streaming data, gain actionable insights, and respond to your business and customer needs in real time. Amazon Managed Service for Apache Flink reduces the complexity of building, managing, and integrating streaming applications with other AWS services. SQL users can easily query streaming data or Duild entire streaming applications using templates and an interactive SQL editor. Java developers Can quickly build sophisticated streaming applications using open source Java libraries and AWS integrations to transform and analyze data in real-time.\\nAmazon Managed Service for Apache Flink takes care of everything required to run your queries continuously and scales automatically to match the volume and throughput rate of your incoming\\nAmazon Data Firenose'\n",
      "\n",
      "=== 112 ===\n",
      "chunk.text (108 tokens):\n",
      "'Amazon Kinesis Data Streams is a massively scalable and durable real-time data streaming service. Kinesis Data Streams can continuously capture gigabytes of data per second from hundreds of thousands of sources such as website clickstreams, database event streams, financial transactions, social media feeds, IT logs, and location-tracking events. The data collected is available in milliseconds to enable real-time analytics use cases such as real-time dasnboardas, real-time anomaly detection, dynamic pricing, and more.'\n",
      "chunker.contextualize(chunk) (113 tokens):\n",
      "'Amazon Kinesis Data Streams\\nAmazon Kinesis Data Streams is a massively scalable and durable real-time data streaming service. Kinesis Data Streams can continuously capture gigabytes of data per second from hundreds of thousands of sources such as website clickstreams, database event streams, financial transactions, social media feeds, IT logs, and location-tracking events. The data collected is available in milliseconds to enable real-time analytics use cases such as real-time dasnboardas, real-time anomaly detection, dynamic pricing, and more.'\n",
      "\n",
      "=== 113 ===\n",
      "chunk.text (152 tokens):\n",
      "'Amazon Kinesis Video Streams makes it easy to securely stream video from connected devices to AWS for analytics, ML, playback, and other processing. Kinesis Video Streams automatically provisions and elastically scales all the infrastructure needed to ingest streaming video data from millions of devices. It also durably stores, encrypts, and indexes video data in your streams, and allows you to access your data through easy-to-use APIs. Kinesis Video Streams enables you to playback video for live and on-demand viewing, and quickly build applications that take advantage of computer vision and video analytics through integration with Amazon Rekognition Video, and libraries for ML frameworks such as Apache MxNet, TensorFlow, and OpenCvV.'\n",
      "chunker.contextualize(chunk) (157 tokens):\n",
      "'Amazon Kinesis Video Streams\\nAmazon Kinesis Video Streams makes it easy to securely stream video from connected devices to AWS for analytics, ML, playback, and other processing. Kinesis Video Streams automatically provisions and elastically scales all the infrastructure needed to ingest streaming video data from millions of devices. It also durably stores, encrypts, and indexes video data in your streams, and allows you to access your data through easy-to-use APIs. Kinesis Video Streams enables you to playback video for live and on-demand viewing, and quickly build applications that take advantage of computer vision and video analytics through integration with Amazon Rekognition Video, and libraries for ML frameworks such as Apache MxNet, TensorFlow, and OpenCvV.'\n",
      "\n",
      "=== 114 ===\n",
      "chunk.text (210 tokens):\n",
      "'Amazon OpenSearch Service (OpenSearch Service) makes it easy to deploy, secure, operate, and scale OpenSearcn to search, analyze, and visualize data in real-time. With Amazon OpenSearcn Service, you get easy-to-use APIs and real-time analytics capabilities to power use-cases sucn as log analytics, full-text search, application monitoring, and clickstream analytics, with enterprisegrade availability, scalability, and security. The service offers integrations with open-source tools such as OpenSearch Dashboards and Logstash for data ingestion and visualization. It also integrates seamlessly with other AWS services such as Amazon Virtual Private Cloud (Amazon VPC), AWS Key Management Service (AWS KMS), Amazon Data Firehose, AWS Lambda, AWS Identity and Access Management (IAM), Amazon Cognito, and Amazon CloudWatch, so that you can go from raw data to actionable insights quickly.'\n",
      "chunker.contextualize(chunk) (215 tokens):\n",
      "'Amazon OpenSearch Service\\nAmazon OpenSearch Service (OpenSearch Service) makes it easy to deploy, secure, operate, and scale OpenSearcn to search, analyze, and visualize data in real-time. With Amazon OpenSearcn Service, you get easy-to-use APIs and real-time analytics capabilities to power use-cases sucn as log analytics, full-text search, application monitoring, and clickstream analytics, with enterprisegrade availability, scalability, and security. The service offers integrations with open-source tools such as OpenSearch Dashboards and Logstash for data ingestion and visualization. It also integrates seamlessly with other AWS services such as Amazon Virtual Private Cloud (Amazon VPC), AWS Key Management Service (AWS KMS), Amazon Data Firehose, AWS Lambda, AWS Identity and Access Management (IAM), Amazon Cognito, and Amazon CloudWatch, so that you can go from raw data to actionable insights quickly.'\n",
      "\n",
      "=== 115 ===\n",
      "chunk.text (174 tokens):\n",
      "'Amazon OpenSearch Serverltess is a serverless option in Amazon OpenSearcnh Service. As a developer, you can use OpenSearch Serverless to run petabyte-scale workloads without\\nAmazon Kinesis Vata Streams\\nconfiguring, managing, and scaling OpenSearch clusters. You get the same interactive millisecond response times as OpenSearch Service with the simplicity of a serverless environment.\\nThe vector engine tor Amazon OpenSearch Serverless, adds a simple, scalable, and highperforming vector storage and search capability to help developers build ML-augmented search experiences and generative Al applications without having to manage vector database infrastructure. Use cases for vector search collections include image search, document searcn, music retrieval, product recommendation, video search, location-based search, fraud detection, and anomaly detection.'\n",
      "chunker.contextualize(chunk) (181 tokens):\n",
      "'Amazon OpenSearch Servertess\\nAmazon OpenSearch Serverltess is a serverless option in Amazon OpenSearcnh Service. As a developer, you can use OpenSearch Serverless to run petabyte-scale workloads without\\nAmazon Kinesis Vata Streams\\nconfiguring, managing, and scaling OpenSearch clusters. You get the same interactive millisecond response times as OpenSearch Service with the simplicity of a serverless environment.\\nThe vector engine tor Amazon OpenSearch Serverless, adds a simple, scalable, and highperforming vector storage and search capability to help developers build ML-augmented search experiences and generative Al applications without having to manage vector database infrastructure. Use cases for vector search collections include image search, document searcn, music retrieval, product recommendation, video search, location-based search, fraud detection, and anomaly detection.'\n",
      "\n",
      "=== 116 ===\n",
      "chunk.text (148 tokens):\n",
      "'Amazon Redshift is the most widely used cloud data warehouse. It makes it fast, simple and costeffective to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. It allows you to run complex analytic queries against terabytes to petabytes of structured and semi-structured data, using sopnisticated query optimization, columnar storage on highperformance storage, and massively parallel query completion. Most results come back in seconds. You can start small for just $0.25 per hour with no commitments and scale out to petabytes of data for $1,000 per terabyte per year, less than a tenth the cost of traditional on-premises solutions.'\n",
      "chunker.contextualize(chunk) (152 tokens):\n",
      "'Amazon Reashift\\nAmazon Redshift is the most widely used cloud data warehouse. It makes it fast, simple and costeffective to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. It allows you to run complex analytic queries against terabytes to petabytes of structured and semi-structured data, using sopnisticated query optimization, columnar storage on highperformance storage, and massively parallel query completion. Most results come back in seconds. You can start small for just $0.25 per hour with no commitments and scale out to petabytes of data for $1,000 per terabyte per year, less than a tenth the cost of traditional on-premises solutions.'\n",
      "\n",
      "=== 117 ===\n",
      "chunk.text (174 tokens):\n",
      "'Amazon Redshift Serverless makes it easier to run and scale analytics without having to manage your data warehouse infrastructure. Developers, data scientists, and analysts can work across databases, data warehouses, and data lakes to build reporting and dasnhboarding applications, perform near real-time analytics, share and collaborate on data, and build and train machine learning (ML) models. Go from large amounts of data to insights in seconds. Amazon Redshift Serverless automatically provisions and intelligently scales data warehouse capacity to deliver fast performance for even the most demanding and unpredictable workloads, and you pay only for what you use. Just load data and start querying right away in Amazon Redshift Query Editor or in your favorite business intelligence (BI) tool and continue to enjoy the best price performance and familiar SQL features in an easy-to-use, zero administration environment.'\n",
      "chunker.contextualize(chunk) (180 tokens):\n",
      "'Amazon Redshift Serverless\\nAmazon Redshift Serverless makes it easier to run and scale analytics without having to manage your data warehouse infrastructure. Developers, data scientists, and analysts can work across databases, data warehouses, and data lakes to build reporting and dasnhboarding applications, perform near real-time analytics, share and collaborate on data, and build and train machine learning (ML) models. Go from large amounts of data to insights in seconds. Amazon Redshift Serverless automatically provisions and intelligently scales data warehouse capacity to deliver fast performance for even the most demanding and unpredictable workloads, and you pay only for what you use. Just load data and start querying right away in Amazon Redshift Query Editor or in your favorite business intelligence (BI) tool and continue to enjoy the best price performance and familiar SQL features in an easy-to-use, zero administration environment.'\n",
      "\n",
      "=== 118 ===\n",
      "chunk.text (110 tokens):\n",
      "'QuickSignt is a fast, cloud-powered business intelligence (BI) service that makes it easy Tor you to deliver insights to everyone in your organization. QuickSight lets you create and publish interactive dasnboaras that can be accessed trom browsers or mobile devices. You can embed dasnboarads\\nAmazon Reashitt\\ninto your applications, providing your customers with powertul self-service analytics. QuickSight easily scales to tens of thousands of users without any software to install, servers to deploy, or infrastructure to manage.'\n",
      "chunker.contextualize(chunk) (112 tokens):\n",
      "'QuickSight\\nQuickSignt is a fast, cloud-powered business intelligence (BI) service that makes it easy Tor you to deliver insights to everyone in your organization. QuickSight lets you create and publish interactive dasnboaras that can be accessed trom browsers or mobile devices. You can embed dasnboarads\\nAmazon Reashitt\\ninto your applications, providing your customers with powertul self-service analytics. QuickSight easily scales to tens of thousands of users without any software to install, servers to deploy, or infrastructure to manage.'\n",
      "\n",
      "=== 119 ===\n",
      "chunk.text (82 tokens):\n",
      "\"AWS Clean Rooms helps companies and their partners more easily and securely analyze and collaborate on their collective datasets—witnhout snaring or copying one another's underlying data. With AWS Clean Rooms, customers can create a secure data clean room in minutes, and collaborate with any other company on the AWS Cloud to generate unique insights about advertising Campaigns, investment decisions, and research and development.\"\n",
      "chunker.contextualize(chunk) (86 tokens):\n",
      "\"AWS Clean Rooms\\nAWS Clean Rooms helps companies and their partners more easily and securely analyze and collaborate on their collective datasets—witnhout snaring or copying one another's underlying data. With AWS Clean Rooms, customers can create a secure data clean room in minutes, and collaborate with any other company on the AWS Cloud to generate unique insights about advertising Campaigns, investment decisions, and research and development.\"\n",
      "\n",
      "=== 120 ===\n",
      "chunk.text (297 tokens):\n",
      "'AWS Data Exchange makes it easy to find, subscribe to, and use third-party data in the cloud. Qualified data providers include category-leading brands such as Reuters, who curate data from over 2.2 million unique news stories per year in multiple languages; Change Healthcare, wno process and anonymize more than 14 billion healthcare transactions and $1 trillion in claims annually; Dun & Bradstreet, who maintain a database of more than 330 million global business records; and Foursquare, whose location data is derived from 220 million unique consumers and includes more than 60 million global commercial venues.\\nOnce subscribed to a data product, you can use the AWS Data Exchange API to load data directly into Amazon S3 and then analyze it with a wide variety of AWS analytics and ML services. For example, property insurers can subscribe to data to analyze historical weather patterns to calibrate insurance coverage requirements in different geographies; restaurants can subscribe to population and location data to identify optimal regions for expansion; academic researchers can conduct studies on climate change by subscribing to data on carbon dioxide emissions; and healthcare professionals can subscribe to aggregated data from historical clinical trials to accelerate their research activities.\\nFor data providers, AWS Data Exchange makes it easy to reach the millions of AWS customers migrating to the cloud by removing the need to build and maintain infrastructure for data storage, delivery, billing, and entitling.'\n",
      "chunker.contextualize(chunk) (301 tokens):\n",
      "'AWS Data Exchange\\nAWS Data Exchange makes it easy to find, subscribe to, and use third-party data in the cloud. Qualified data providers include category-leading brands such as Reuters, who curate data from over 2.2 million unique news stories per year in multiple languages; Change Healthcare, wno process and anonymize more than 14 billion healthcare transactions and $1 trillion in claims annually; Dun & Bradstreet, who maintain a database of more than 330 million global business records; and Foursquare, whose location data is derived from 220 million unique consumers and includes more than 60 million global commercial venues.\\nOnce subscribed to a data product, you can use the AWS Data Exchange API to load data directly into Amazon S3 and then analyze it with a wide variety of AWS analytics and ML services. For example, property insurers can subscribe to data to analyze historical weather patterns to calibrate insurance coverage requirements in different geographies; restaurants can subscribe to population and location data to identify optimal regions for expansion; academic researchers can conduct studies on climate change by subscribing to data on carbon dioxide emissions; and healthcare professionals can subscribe to aggregated data from historical clinical trials to accelerate their research activities.\\nFor data providers, AWS Data Exchange makes it easy to reach the millions of AWS customers migrating to the cloud by removing the need to build and maintain infrastructure for data storage, delivery, billing, and entitling.'\n",
      "\n",
      "=== 121 ===\n",
      "chunk.text (191 tokens):\n",
      "\"AWS Data Pipeline is a web service that helps you reliably process and move data between ditferent AWS compute and storage services, as well aS on-premises data sources, at specified\\nAWS Clean Rooms\\nintervals. With AWS Data Pipeline, you can regularly access your data where it's stored, transform and process it at scale, and efficiently transfer the results to AWS services such as Amazon S3, Amazon RDS, Amazon DynamoDB, and Amazon EMR.\\nAWS Data Pipeline helps you easily create complex data processing workloads that are fault tolerant, repeatable, and nighly available. You don't have to worry about ensuring resource availability, managing inter-task dependencies, retrying transient failures or timeouts in individual tasks, or creating a failure notification system. AWS Data Pipeline also allows you to move and process data that was previously locked up in on-premises data silos.\"\n",
      "chunker.contextualize(chunk) (195 tokens):\n",
      "\"AWS Data Pipeline\\nAWS Data Pipeline is a web service that helps you reliably process and move data between ditferent AWS compute and storage services, as well aS on-premises data sources, at specified\\nAWS Clean Rooms\\nintervals. With AWS Data Pipeline, you can regularly access your data where it's stored, transform and process it at scale, and efficiently transfer the results to AWS services such as Amazon S3, Amazon RDS, Amazon DynamoDB, and Amazon EMR.\\nAWS Data Pipeline helps you easily create complex data processing workloads that are fault tolerant, repeatable, and nighly available. You don't have to worry about ensuring resource availability, managing inter-task dependencies, retrying transient failures or timeouts in individual tasks, or creating a failure notification system. AWS Data Pipeline also allows you to move and process data that was previously locked up in on-premises data silos.\"\n",
      "\n",
      "=== 122 ===\n",
      "chunk.text (444 tokens):\n",
      "'AWS Entity Resolution is a service that helps you match and link related records stored across multiple applications, channels, and data stores without building a custom solution. Using flexible, configurable ML and rule-based techniques, AWS Entity Resolution can remove duplicate records, create customer profiles by connecting different customer interactions, and personalize experiences across advertising and marketing campaigns, loyalty programs, and e-commerce. For example, you can create a unified view of customer interactions by linking recent events, such as ad clicks, cart abandonment, and purchases, into a unique match ID.\\nAWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy for customers to prepare and load their data for analytics. You can create and run an ETL job with a Tew clicks in the AWS Management Console. You simply point AWS Glue to your data stored in AWS, and AWS Glue discovers your data and stores the associated metadata (such as table definition and schema) in the AWS Glue Data Catalog. Once cataloged, your data is immediately searchable, queryable, and available for ETL.\\nAWS Glue Data Integration Engines provide access to data using Apacne Spark, PySpark, and Python. With the addition of AWS Glue for Ray, you can further scale your workloads using Ray, an open-source unified compute framework.\\nAWS Glue Data Quality can measure and monitor the data quality of Amazon S3 based data lakes, data warehouses, and other data repositories. It automatically computes statistics, recommends quality rules, and can monitor and alert you when it detects missing, stale, or bad data. You can access it in the AWS Glue Data Catalog and in AWS Glue Data Catalog ETL jobs.\\nAWS Entity Resolution\\nAWS Lake Formation Is a service that makes It easy to set up a secure data lake In days. A data lake is a centralized, curated, and secured repository that stores all your data, both in its original form and prepared for analysis. A data lake enables you to break down data silos and combine different types of analytics to gain insights and guide better business decisions.'\n",
      "chunker.contextualize(chunk) (448 tokens):\n",
      "'AWS Entity Resolution\\nAWS Entity Resolution is a service that helps you match and link related records stored across multiple applications, channels, and data stores without building a custom solution. Using flexible, configurable ML and rule-based techniques, AWS Entity Resolution can remove duplicate records, create customer profiles by connecting different customer interactions, and personalize experiences across advertising and marketing campaigns, loyalty programs, and e-commerce. For example, you can create a unified view of customer interactions by linking recent events, such as ad clicks, cart abandonment, and purchases, into a unique match ID.\\nAWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy for customers to prepare and load their data for analytics. You can create and run an ETL job with a Tew clicks in the AWS Management Console. You simply point AWS Glue to your data stored in AWS, and AWS Glue discovers your data and stores the associated metadata (such as table definition and schema) in the AWS Glue Data Catalog. Once cataloged, your data is immediately searchable, queryable, and available for ETL.\\nAWS Glue Data Integration Engines provide access to data using Apacne Spark, PySpark, and Python. With the addition of AWS Glue for Ray, you can further scale your workloads using Ray, an open-source unified compute framework.\\nAWS Glue Data Quality can measure and monitor the data quality of Amazon S3 based data lakes, data warehouses, and other data repositories. It automatically computes statistics, recommends quality rules, and can monitor and alert you when it detects missing, stale, or bad data. You can access it in the AWS Glue Data Catalog and in AWS Glue Data Catalog ETL jobs.\\nAWS Entity Resolution\\nAWS Lake Formation Is a service that makes It easy to set up a secure data lake In days. A data lake is a centralized, curated, and secured repository that stores all your data, both in its original form and prepared for analysis. A data lake enables you to break down data silos and combine different types of analytics to gain insights and guide better business decisions.'\n",
      "\n",
      "=== 123 ===\n",
      "chunk.text (236 tokens):\n",
      "'However, setting up and managing data lakes today involves a lot of manual, complicated, and time-consuming tasks. This work includes loading data from diverse sources, monitoring those data Tlows, setting up partitions, turning on encryption and managing keys, defining transformation jobs and monitoring their operation, re-organizing data into a columnar format, configuring access control settings, deduplicating redundant data, matching linked records, granting access to data sets, and auditing access over time.\\nCreating a data lake with Lake Formation Is as simple as defining where your data resides and what data access and security policies you want to apply. Lake Formation then collects and catalogs data from databases and object storage, moves the data into your new Amazon S34 data lake, cleans and classifies data using ML algorithms, and secures access to your sensitive data. Your users can then access a centralized catalog of data which describes available data sets and their appropriate usage. Your users then leverage these data sets with their choice of analytics and ML services, such as Amazon EMR for Apache Spark, Amazon Redshift, Amazon Athena, SageMaker Al, and QuickSight.'\n",
      "chunker.contextualize(chunk) (240 tokens):\n",
      "'AWS Entity Resolution\\nHowever, setting up and managing data lakes today involves a lot of manual, complicated, and time-consuming tasks. This work includes loading data from diverse sources, monitoring those data Tlows, setting up partitions, turning on encryption and managing keys, defining transformation jobs and monitoring their operation, re-organizing data into a columnar format, configuring access control settings, deduplicating redundant data, matching linked records, granting access to data sets, and auditing access over time.\\nCreating a data lake with Lake Formation Is as simple as defining where your data resides and what data access and security policies you want to apply. Lake Formation then collects and catalogs data from databases and object storage, moves the data into your new Amazon S34 data lake, cleans and classifies data using ML algorithms, and secures access to your sensitive data. Your users can then access a centralized catalog of data which describes available data sets and their appropriate usage. Your users then leverage these data sets with their choice of analytics and ML services, such as Amazon EMR for Apache Spark, Amazon Redshift, Amazon Athena, SageMaker Al, and QuickSight.'\n",
      "\n",
      "=== 124 ===\n",
      "chunk.text (326 tokens):\n",
      "\"Amazon Managed Streaming for Apache Katka (Amazon MSK) is a fully managed service that makes it easy for you to build and run applications that use Apache Katka to process streaming data. Apache Katka is an open-source platform for building real-time streaming data pipelines and applications. With Amazon MSK, you can use Apache Kafka APIs to populate data lakes, stream changes to and from databases, and power ML and analytics applications.\\nApache Katka clusters are challenging to setup, scale, and manage in production. When you run Apache Katka on your own, you need to provision servers, configure Apache Kafka manually, replace servers when they fail, orchestrate server patches and upgrades, architect the cluster for nigh availability, ensure data is durably stored and secured, setup monitoring and alarms, and careTully plan scaling events to support load changes. Amazon MSK makes it easy Tor you to build and run production applications on Apache Kafka without needing Apache Kafka infrastructure management expertise. That means you spend less time managing infrastructure and more time pbuilding applications.\\nAWS Lake Formation\\nWith a few clicks in the Amazon MSK console you can create highly available Apache Kafka clusters with settings and configuration based on Apache Katka's deployment best practices. Amazon MSK automatically provisions and runs your Apache Kafka clusters. Amazon MSK continuously monitors cluster health and automatically replaces unhealthy nodes with no downtime to your application. In addition, Amazon MSK secures your Apache Kafka cluster by encrypting data at rest.\"\n",
      "chunker.contextualize(chunk) (339 tokens):\n",
      "\"Amazon Managed Streaming for Apache Kafka (Amazon MSK)\\nAmazon Managed Streaming for Apache Katka (Amazon MSK) is a fully managed service that makes it easy for you to build and run applications that use Apache Katka to process streaming data. Apache Katka is an open-source platform for building real-time streaming data pipelines and applications. With Amazon MSK, you can use Apache Kafka APIs to populate data lakes, stream changes to and from databases, and power ML and analytics applications.\\nApache Katka clusters are challenging to setup, scale, and manage in production. When you run Apache Katka on your own, you need to provision servers, configure Apache Kafka manually, replace servers when they fail, orchestrate server patches and upgrades, architect the cluster for nigh availability, ensure data is durably stored and secured, setup monitoring and alarms, and careTully plan scaling events to support load changes. Amazon MSK makes it easy Tor you to build and run production applications on Apache Kafka without needing Apache Kafka infrastructure management expertise. That means you spend less time managing infrastructure and more time pbuilding applications.\\nAWS Lake Formation\\nWith a few clicks in the Amazon MSK console you can create highly available Apache Kafka clusters with settings and configuration based on Apache Katka's deployment best practices. Amazon MSK automatically provisions and runs your Apache Kafka clusters. Amazon MSK continuously monitors cluster health and automatically replaces unhealthy nodes with no downtime to your application. In addition, Amazon MSK secures your Apache Kafka cluster by encrypting data at rest.\"\n",
      "\n",
      "=== 125 ===\n",
      "chunk.text (128 tokens):\n",
      "\"Application integration on AWS is a suite of services that enable communication between decoupled components within microservices, distributed systems, and serverless applications. You don't need to refactor your entire architecture to benefit—decoupling applications at any scale can reduce the impact of changes, making it easier to update and faster to release new features.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS application integration service or Amazon SQS, Amazon SNS, or Amazon EventBridge?. For general information, see Application Integration on AWS.\\nApplication integration\"\n",
      "chunker.contextualize(chunk) (130 tokens):\n",
      "\"Application integration\\nApplication integration on AWS is a suite of services that enable communication between decoupled components within microservices, distributed systems, and serverless applications. You don't need to refactor your entire architecture to benefit—decoupling applications at any scale can reduce the impact of changes, making it easier to update and faster to release new features.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS application integration service or Amazon SQS, Amazon SNS, or Amazon EventBridge?. For general information, see Application Integration on AWS.\\nApplication integration\"\n",
      "\n",
      "=== 126 ===\n",
      "chunk.text (60 tokens):\n",
      "'e AWS Step Functions\\ne Amazon AppFlow\\n© AWS B2B Data Interchange\\ne Amazon EventBridge\\ne Amazon Managed Workflows for Apache Airflow (MWAA)\\ne Amazon MQ\\n* Amazon Simple Notification Service\\n¢ Amazon Simpte Queue Service\\ne Amazon Simple Worktlow Service\\nApplication integration'\n",
      "chunker.contextualize(chunk) (61 tokens):\n",
      "'Services\\ne AWS Step Functions\\ne Amazon AppFlow\\n© AWS B2B Data Interchange\\ne Amazon EventBridge\\ne Amazon Managed Workflows for Apache Airflow (MWAA)\\ne Amazon MQ\\n* Amazon Simple Notification Service\\n¢ Amazon Simpte Queue Service\\ne Amazon Simple Worktlow Service\\nApplication integration'\n",
      "\n",
      "=== 127 ===\n",
      "chunk.text (186 tokens):\n",
      "'AWS Step Functions is a Tully managed service that makes it easy to coordinate the components of distributed applications and microservices using visual worktlows. Building applications from individual components that each perform a discrete Tunction lets you scale easily and change applications quickly. Step Functions is a reliable way to coordinate components and step through the functions of your application. Step Functions provides a graphical console to arrange and visualize the components of your application as a series of steps. This makes it simple to build and run multi-step applications. Step Functions automatically initiates and tracks each step, and retries when there are errors, SO your application runs in order and as expected. Step Functions logs the State of each step, so when things do go wrong, you can diagnose and debug problems quickly. You can change and add steps without even writing code, so you can easily evolve your application and innovate taster.'\n",
      "chunker.contextualize(chunk) (190 tokens):\n",
      "'AWS Step Functions\\nAWS Step Functions is a Tully managed service that makes it easy to coordinate the components of distributed applications and microservices using visual worktlows. Building applications from individual components that each perform a discrete Tunction lets you scale easily and change applications quickly. Step Functions is a reliable way to coordinate components and step through the functions of your application. Step Functions provides a graphical console to arrange and visualize the components of your application as a series of steps. This makes it simple to build and run multi-step applications. Step Functions automatically initiates and tracks each step, and retries when there are errors, SO your application runs in order and as expected. Step Functions logs the State of each step, so when things do go wrong, you can diagnose and debug problems quickly. You can change and add steps without even writing code, so you can easily evolve your application and innovate taster.'\n",
      "\n",
      "=== 128 ===\n",
      "chunk.text (183 tokens):\n",
      "'Amazon AppFlow Is a Tully managed integration service that enables you to securely transfer data between Software-as-a-Service (SaaS) applications such as Salesforce, Zendesk, Slack, and ServiceNow, and AWS services such as Amazon $4 and Amazon Reasnhift, in just a few clicks. With Amazon AppFlow, you can run data Tlows at enterprise scale at the frequency you choose - ona schedule, in response to a business event, or on demand. You can configure data transformation Capabilities such as filtering and validation to generate rich, ready-to-use data as part of the Tlow itself, without additional steps. Amazon AppFlow; automatically encrypts data in motion, and allows users to restrict data from flowing over the public internet for SaaS applications that are integrated with AWS PrivateLink, reducing exposure to security threats.'\n",
      "chunker.contextualize(chunk) (186 tokens):\n",
      "'Amazon AppFlow\\nAmazon AppFlow Is a Tully managed integration service that enables you to securely transfer data between Software-as-a-Service (SaaS) applications such as Salesforce, Zendesk, Slack, and ServiceNow, and AWS services such as Amazon $4 and Amazon Reasnhift, in just a few clicks. With Amazon AppFlow, you can run data Tlows at enterprise scale at the frequency you choose - ona schedule, in response to a business event, or on demand. You can configure data transformation Capabilities such as filtering and validation to generate rich, ready-to-use data as part of the Tlow itself, without additional steps. Amazon AppFlow; automatically encrypts data in motion, and allows users to restrict data from flowing over the public internet for SaaS applications that are integrated with AWS PrivateLink, reducing exposure to security threats.'\n",
      "\n",
      "=== 129 ===\n",
      "chunk.text (173 tokens):\n",
      "'AWS B2B Data Interchange (B2Bi) automates the transformation of Electronic Data Interchange (EDI) documents into JSON and XML formats to simplify your downstream data integrations. Businesses use EDI documents to exchange transactional data with trading partners, such as suppliers and end customers, using standardized formats such as X12.\\nWith B2Bi, you can onboard and manage your trading partners and automate the transtormation of EDI documents into common data representations such as JSON and XML using a low-code interface. This approach reduces the time, complexity, and cost associated with preparing and integrating EDI data into their business applications and purpose-built data lakes. As a result,\\nAWS Step Functions\\nyou can concentrate on using transactional data to drive business insights using the AWS suite of analytics, Al, and ML services.'\n",
      "chunker.contextualize(chunk) (180 tokens):\n",
      "'AWS B2B Data Interchange\\nAWS B2B Data Interchange (B2Bi) automates the transformation of Electronic Data Interchange (EDI) documents into JSON and XML formats to simplify your downstream data integrations. Businesses use EDI documents to exchange transactional data with trading partners, such as suppliers and end customers, using standardized formats such as X12.\\nWith B2Bi, you can onboard and manage your trading partners and automate the transtormation of EDI documents into common data representations such as JSON and XML using a low-code interface. This approach reduces the time, complexity, and cost associated with preparing and integrating EDI data into their business applications and purpose-built data lakes. As a result,\\nAWS Step Functions\\nyou can concentrate on using transactional data to drive business insights using the AWS suite of analytics, Al, and ML services.'\n",
      "\n",
      "=== 130 ===\n",
      "chunk.text (117 tokens):\n",
      "'Amazon EventBridge is a serverless event bus that makes it easier to build event-driven applications at scale using events generated from your applications, integrated Software-asa-Service (SaaS) applications, and AWS services. EventBridge delivers a stream of real-time data from event sources such as Zendesk or Shopity to targets such as AWS Lambda and other SaaS applications. You can set up routing rules to determine where to send your data to build application architectures that react in real-time to your data sources with event publisher and consumer completely decoupled.'\n",
      "chunker.contextualize(chunk) (120 tokens):\n",
      "'Amazon EventBridge\\nAmazon EventBridge is a serverless event bus that makes it easier to build event-driven applications at scale using events generated from your applications, integrated Software-asa-Service (SaaS) applications, and AWS services. EventBridge delivers a stream of real-time data from event sources such as Zendesk or Shopity to targets such as AWS Lambda and other SaaS applications. You can set up routing rules to determine where to send your data to build application architectures that react in real-time to your data sources with event publisher and consumer completely decoupled.'\n",
      "\n",
      "=== 131 ===\n",
      "chunk.text (149 tokens):\n",
      "'Amazon Managed Workflows for Apache Airflow (MWAA) is a managed orchestration service for Apache Airflow that makes it easier to set up and operate end-to-end data pipelines in the cloud at scale. Apache Airflow is an open-source tool used to programmatically author, schedule, and monitor sequences of processes and tasks referred to as \"workflows.\" With Managed Workflows, you can use Airflow and Python to create workflows without having to manage the underlying infrastructure for scalability, availability, and security. Managed Workflows automatically scales its workflow capacity to meet your needs, and is integrated with AWS security services to help provide you with fast and secure access to data.'\n",
      "chunker.contextualize(chunk) (162 tokens):\n",
      "'Amazon Managed Workflows for Apache Airflow (MWAA)\\nAmazon Managed Workflows for Apache Airflow (MWAA) is a managed orchestration service for Apache Airflow that makes it easier to set up and operate end-to-end data pipelines in the cloud at scale. Apache Airflow is an open-source tool used to programmatically author, schedule, and monitor sequences of processes and tasks referred to as \"workflows.\" With Managed Workflows, you can use Airflow and Python to create workflows without having to manage the underlying infrastructure for scalability, availability, and security. Managed Workflows automatically scales its workflow capacity to meet your needs, and is integrated with AWS security services to help provide you with fast and secure access to data.'\n",
      "\n",
      "=== 132 ===\n",
      "chunk.text (174 tokens):\n",
      "\"Amazon MQ is a managed message broker service for Apache ActiveMQ Classic and RabbitMQ that makes it easy to set up and Operate message brokers in the cloud. Message brokers allow ditferent software systems-—often using different programming languages, and on different platforms—to communicate and exchange information. Amazon MQ reduces your operational load by managing the provisioning, setup, and maintenance of ActiveMQ and RabbitMQ, popular opensource message brokers. Connecting your current applications to Amazon MQ is easy because it uses industry-standard APIs and protocols for messaging, including JMS, NMS, AMQP, STOMP, MQTT, and WebSocket. Using standards means that in most cases, there's no need to rewrite any messaging code when you migrate to AWS.\\nAmazon EventBridge\"\n",
      "chunker.contextualize(chunk) (177 tokens):\n",
      "\"Amazon MQ\\nAmazon MQ is a managed message broker service for Apache ActiveMQ Classic and RabbitMQ that makes it easy to set up and Operate message brokers in the cloud. Message brokers allow ditferent software systems-—often using different programming languages, and on different platforms—to communicate and exchange information. Amazon MQ reduces your operational load by managing the provisioning, setup, and maintenance of ActiveMQ and RabbitMQ, popular opensource message brokers. Connecting your current applications to Amazon MQ is easy because it uses industry-standard APIs and protocols for messaging, including JMS, NMS, AMQP, STOMP, MQTT, and WebSocket. Using standards means that in most cases, there's no need to rewrite any messaging code when you migrate to AWS.\\nAmazon EventBridge\"\n",
      "\n",
      "=== 133 ===\n",
      "chunk.text (145 tokens):\n",
      "'Amazon Simple Notincation Service (Amazon SNS) is a highly available, durable, secure, Tully managed pub/sub messaging service that enables you to decouple microservices, distributed systems, and serverless applications. Amazon SNS provides topics for high-throughput, pushbased, many-to-many messaging. Using Amazon SNS topics, your publisher systems can Tan out messages to a large number of subscriber endpoints for parallel processing, including Amazon SQS queues, AWS Lambda Tunctions, and HT TP/S webhooks. Additionally, SNS can be used to Tan out notifications to end users using mobile push, SMS, and email.'\n",
      "chunker.contextualize(chunk) (149 tokens):\n",
      "'Amazon Simple Notification Service\\nAmazon Simple Notincation Service (Amazon SNS) is a highly available, durable, secure, Tully managed pub/sub messaging service that enables you to decouple microservices, distributed systems, and serverless applications. Amazon SNS provides topics for high-throughput, pushbased, many-to-many messaging. Using Amazon SNS topics, your publisher systems can Tan out messages to a large number of subscriber endpoints for parallel processing, including Amazon SQS queues, AWS Lambda Tunctions, and HT TP/S webhooks. Additionally, SNS can be used to Tan out notifications to end users using mobile push, SMS, and email.'\n",
      "\n",
      "=== 134 ===\n",
      "chunk.text (194 tokens):\n",
      "'Amazon Simple Queue Service (Amazon SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using Amazon SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with Amazon SQS in minutes using the AWS Management Console, AWS CLI, or SDK of your choice, and three simple commanas.\\nAmazon SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. Amazon SQS FIFO queues are designed to Guarantee that messages are processed exactly once, in the exact order that they are sent.'\n",
      "chunker.contextualize(chunk) (198 tokens):\n",
      "'Amazon Simple Queue Service\\nAmazon Simple Queue Service (Amazon SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using Amazon SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with Amazon SQS in minutes using the AWS Management Console, AWS CLI, or SDK of your choice, and three simple commanas.\\nAmazon SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. Amazon SQS FIFO queues are designed to Guarantee that messages are processed exactly once, in the exact order that they are sent.'\n",
      "\n",
      "=== 135 ===\n",
      "chunk.text (94 tokens):\n",
      "\"Amazon Simple Worktlow Service (Amazon SWF) helps developers build, run, and scale background jobs that Nave parallel or sequential steps. You can think of Amazon SWF as a fully managed State tracker and task coordinator in the cloud. If your application's steps take more than 500 milliseconds to complete, you need to track the state of processing. If you need to recover or retry it a task Tails, Amazon SWF can help you.\"\n",
      "chunker.contextualize(chunk) (99 tokens):\n",
      "\"Amazon Simple Workflow Service\\nAmazon Simple Worktlow Service (Amazon SWF) helps developers build, run, and scale background jobs that Nave parallel or sequential steps. You can think of Amazon SWF as a fully managed State tracker and task coordinator in the cloud. If your application's steps take more than 500 milliseconds to complete, you need to track the state of processing. If you need to recover or retry it a task Tails, Amazon SWF can help you.\"\n",
      "\n",
      "=== 136 ===\n",
      "chunk.text (339 tokens):\n",
      "'Amazon Managed Blockchain is a Tully managed service that makes it easy to create and manage scalable blockchain networks using the popular open source frameworks Hyperledger Fabric ana Ethereum.\\nBlockchain makes it possible to build applications where multiple parties can run transactions without the need for a trusted, central authority. Today, building a scalable blockchain network with existing technologies is complex to set up and hard to manage. To create a blockchain network, each network member needs to manually provision hardware, install software, create and manage certificates for access control, and configure networking components. Once the blockchain network is running, you need to continuously monitor the infrastructure and adapt to changes, such as an increase in transaction requests, or new members joining or leaving the network.\\nAmazon Managed Blockchain is a fully managed service that allows you to set up and manage a scalable blockchain network with just a few clicks. Amazon Managed Blockchain eliminates the overhead required to create the network, and automatically scales to meet the demands of thousands of applications running millions of transactions. Once your network Is up and running, Managed Blockchain makes it easy to manage and maintain your blockchain network. it manages your certificates, lets you easily invite new members to join the network, and tracks operational metrics such as usage of compute, memory, and storage resources. In addition, Managed Blockchain can replicate an immutable copy of your blockchain network activity into Amazon Quantum Ledger Database (Amazon QLDB), a fully managed ledger database. This allows you to easily analyze the network activity outside the network and gain insights into trenas.'\n",
      "chunker.contextualize(chunk) (344 tokens):\n",
      "'Amazon Managed Blockchain\\nAmazon Managed Blockchain is a Tully managed service that makes it easy to create and manage scalable blockchain networks using the popular open source frameworks Hyperledger Fabric ana Ethereum.\\nBlockchain makes it possible to build applications where multiple parties can run transactions without the need for a trusted, central authority. Today, building a scalable blockchain network with existing technologies is complex to set up and hard to manage. To create a blockchain network, each network member needs to manually provision hardware, install software, create and manage certificates for access control, and configure networking components. Once the blockchain network is running, you need to continuously monitor the infrastructure and adapt to changes, such as an increase in transaction requests, or new members joining or leaving the network.\\nAmazon Managed Blockchain is a fully managed service that allows you to set up and manage a scalable blockchain network with just a few clicks. Amazon Managed Blockchain eliminates the overhead required to create the network, and automatically scales to meet the demands of thousands of applications running millions of transactions. Once your network Is up and running, Managed Blockchain makes it easy to manage and maintain your blockchain network. it manages your certificates, lets you easily invite new members to join the network, and tracks operational metrics such as usage of compute, memory, and storage resources. In addition, Managed Blockchain can replicate an immutable copy of your blockchain network activity into Amazon Quantum Ledger Database (Amazon QLDB), a fully managed ledger database. This allows you to easily analyze the network activity outside the network and gain insights into trenas.'\n",
      "\n",
      "=== 137 ===\n",
      "chunk.text (42 tokens):\n",
      "'Innovative business applications with the same on-demand scalability, reliability, pay-as-you go pricing, and machine learning that drives AWS cloud infrastructure.\\nFor general information, see AWS Business Applications.'\n",
      "chunker.contextualize(chunk) (44 tokens):\n",
      "'Business applications\\nInnovative business applications with the same on-demand scalability, reliability, pay-as-you go pricing, and machine learning that drives AWS cloud infrastructure.\\nFor general information, see AWS Business Applications.'\n",
      "\n",
      "=== 138 ===\n",
      "chunk.text (42 tokens):\n",
      "'Business applications\\ne Alexa for Business\\n¢ AWS AppFabric\\ne Amazon Chime\\ne Amazon Chime SDK\\nAmazon Connect\\ne Amazon Pinpoint\\ne Amazon SES\\ne Amazon WorkDocs\\ne Amazon WorkMail'\n",
      "chunker.contextualize(chunk) (43 tokens):\n",
      "'Applications\\nBusiness applications\\ne Alexa for Business\\n¢ AWS AppFabric\\ne Amazon Chime\\ne Amazon Chime SDK\\nAmazon Connect\\ne Amazon Pinpoint\\ne Amazon SES\\ne Amazon WorkDocs\\ne Amazon WorkMail'\n",
      "\n",
      "=== 139 ===\n",
      "chunk.text (58 tokens):\n",
      "'Alexa Tor Business is a service that enables organizations and employees to use Alexa to get more work done. With Alexa for Business, employees can use Alexa as their intelligent assistant to be more productive in meeting rooms, at their desks, and even with the Alexa devices they already Nave at home.'\n",
      "chunker.contextualize(chunk) (61 tokens):\n",
      "'Alexa for Business\\nAlexa Tor Business is a service that enables organizations and employees to use Alexa to get more work done. With Alexa for Business, employees can use Alexa as their intelligent assistant to be more productive in meeting rooms, at their desks, and even with the Alexa devices they already Nave at home.'\n",
      "\n",
      "=== 140 ===\n",
      "chunk.text (173 tokens):\n",
      "'AWS AppFabric is a fully managed service that aggregates and normalizes security data across software as a service (SaaS) applications. Previously, integrating SaaS applications with existing security tools required teams to build, manage, and maintain their own point-to-point (P2P) integrations so that security teams could monitor event logs and understand activity from each application. With AppFabric, you can quickly connect multiple SaaS applications to increase observability, productivity, and security—with no coding required.\\nAfter the SaaS applications are authorized and connected, AppFabric ingests the data and normalizes it using the Open Cybersecurity Schema Framework (OCSF). OCSF allows you to set common policies, standardize security alerts, and quickly manage user access across multiple applications.'\n",
      "chunker.contextualize(chunk) (179 tokens):\n",
      "'AWS AppFabric\\nAWS AppFabric is a fully managed service that aggregates and normalizes security data across software as a service (SaaS) applications. Previously, integrating SaaS applications with existing security tools required teams to build, manage, and maintain their own point-to-point (P2P) integrations so that security teams could monitor event logs and understand activity from each application. With AppFabric, you can quickly connect multiple SaaS applications to increase observability, productivity, and security—with no coding required.\\nAfter the SaaS applications are authorized and connected, AppFabric ingests the data and normalizes it using the Open Cybersecurity Schema Framework (OCSF). OCSF allows you to set common policies, standardize security alerts, and quickly manage user access across multiple applications.'\n",
      "\n",
      "=== 141 ===\n",
      "chunk.text (155 tokens):\n",
      "'Amazon Chime is a communications service that transforms online meetings with a secure, easyto-use application that you can trust. Amazon Chime works seamlessly across your devices so that\\nAlexa Tor Business\\nyou can stay connected. You can use Amazon Chime for online meetings, video conferencing, calls, cnat, and to share content, both inside and outside your organization.\\nAmazon Chime works with Alexa for Business, which means you can use Alexa to start your meetings with your voice. Alexa can start your video meetings in large conference rooms, and automatically dial into online meetings in smaller huddle rooms and from your desk.\\nWith the Amazon Chime SDK, builders can easily add real-time voice, video, and messaging powered by ML into their applications.'\n",
      "chunker.contextualize(chunk) (158 tokens):\n",
      "'Amazon Chime\\nAmazon Chime is a communications service that transforms online meetings with a secure, easyto-use application that you can trust. Amazon Chime works seamlessly across your devices so that\\nAlexa Tor Business\\nyou can stay connected. You can use Amazon Chime for online meetings, video conferencing, calls, cnat, and to share content, both inside and outside your organization.\\nAmazon Chime works with Alexa for Business, which means you can use Alexa to start your meetings with your voice. Alexa can start your video meetings in large conference rooms, and automatically dial into online meetings in smaller huddle rooms and from your desk.\\nWith the Amazon Chime SDK, builders can easily add real-time voice, video, and messaging powered by ML into their applications.'\n",
      "\n",
      "=== 142 ===\n",
      "chunk.text (132 tokens):\n",
      "'Amazon Connect is a self-service, omnichannel cloud contact center service that makes it easy for any business to deliver better customer service at lower cost. Amazon Connect is based on the same contact center technology used by Amazon customer service associates around the world to power millions of customer conversations. The self-service graphical interface in Amazon Connect makes it easy for non-technical users to design contact flows, manage agents, and track performance metrics — no specialized skills required. There are no up-front payments or longterm commitments and no infrastructure to manage with Amazon Connect; customers pay by the minute for Amazon Connect usage plus any associated telephony services.'\n",
      "chunker.contextualize(chunk) (134 tokens):\n",
      "'Amazon Connect\\nAmazon Connect is a self-service, omnichannel cloud contact center service that makes it easy for any business to deliver better customer service at lower cost. Amazon Connect is based on the same contact center technology used by Amazon customer service associates around the world to power millions of customer conversations. The self-service graphical interface in Amazon Connect makes it easy for non-technical users to design contact flows, manage agents, and track performance metrics — no specialized skills required. There are no up-front payments or longterm commitments and no infrastructure to manage with Amazon Connect; customers pay by the minute for Amazon Connect usage plus any associated telephony services.'\n",
      "\n",
      "=== 143 ===\n",
      "chunk.text (326 tokens):\n",
      "'Amazon Pinpoint makes it easy to send targeted messages to your customers through multiple engagement channels. Examples of targeted campaigns are promotional alerts and customer retention campaigns, and transactional messages are messages such as order confirmations and password reset messages.\\nYou can integrate Amazon Pinpoint into your mobile and web apps to capture usage data to provide you with insight into how customers interact with your apps. Amazon Pinpoint also tracks the ways that your customers respond to the messages you send—for example, by showing you the number of messages that were delivered, opened, or clicked.\\nYou can develop custom audience segments and send them pre-scheduled targeted campaigns via email, SMS, and push notifications. Targeted campaigns are useTful for sending promotional or educational content to re-engage and retain your users.\\nAmazon Chime SDK\\nYou can send transactional messages using the console or the Amazon Pinpoint REST API. Transactional campaigns can be sent via email, SMS, push notifications, and voice messages. You can also use the API to build custom applications that deliver campaign and transactional MESSaGes.\\nAmazon Simple Email Service (Amazon SES) is a cost-effective, flexible, and scalable email service that enables developers to send mail from within any application. You can configure Amazon SES quickly to support several email use cases, including transactional, marketing, or mass email communications. The Amazon SES flexible IP deployment and email authentication options help drive higher deliverability and protect sender reputation, while sending analytics measure the impact of each email. With Amazon SES, you can send email securely, globally, and at scale.'\n",
      "chunker.contextualize(chunk) (329 tokens):\n",
      "'Amazon Pinpoint\\nAmazon Pinpoint makes it easy to send targeted messages to your customers through multiple engagement channels. Examples of targeted campaigns are promotional alerts and customer retention campaigns, and transactional messages are messages such as order confirmations and password reset messages.\\nYou can integrate Amazon Pinpoint into your mobile and web apps to capture usage data to provide you with insight into how customers interact with your apps. Amazon Pinpoint also tracks the ways that your customers respond to the messages you send—for example, by showing you the number of messages that were delivered, opened, or clicked.\\nYou can develop custom audience segments and send them pre-scheduled targeted campaigns via email, SMS, and push notifications. Targeted campaigns are useTful for sending promotional or educational content to re-engage and retain your users.\\nAmazon Chime SDK\\nYou can send transactional messages using the console or the Amazon Pinpoint REST API. Transactional campaigns can be sent via email, SMS, push notifications, and voice messages. You can also use the API to build custom applications that deliver campaign and transactional MESSaGes.\\nAmazon Simple Email Service (Amazon SES) is a cost-effective, flexible, and scalable email service that enables developers to send mail from within any application. You can configure Amazon SES quickly to support several email use cases, including transactional, marketing, or mass email communications. The Amazon SES flexible IP deployment and email authentication options help drive higher deliverability and protect sender reputation, while sending analytics measure the impact of each email. With Amazon SES, you can send email securely, globally, and at scale.'\n",
      "\n",
      "=== 144 ===\n",
      "chunk.text (154 tokens):\n",
      "'New customer sign-ups and account upgrades are no longer available for Amazon WorkDocs. Learn about migration steps here: How to migrate data from Amazon WorkDocs.\\nAmazon WorkDocs is a fully managed, secure enterprise storage and sharing service with strong administrative controls and feedback capabilities that improve user productivity.\\nUsers can comment on files, send them to others for feedback, and upload new versions without having to resort to emailing multiple versions of their files as attachments. Users can take advantage of these capabilities wherever they are, using the device of their choice, including PCs, Macs, tablets, and phones. Amazon WorkDocs offers IT administrators the option of integrating with existing corporate directories, flexible sharing policies and control of the location where data is stored.'\n",
      "chunker.contextualize(chunk) (155 tokens):\n",
      "'Notice\\nNew customer sign-ups and account upgrades are no longer available for Amazon WorkDocs. Learn about migration steps here: How to migrate data from Amazon WorkDocs.\\nAmazon WorkDocs is a fully managed, secure enterprise storage and sharing service with strong administrative controls and feedback capabilities that improve user productivity.\\nUsers can comment on files, send them to others for feedback, and upload new versions without having to resort to emailing multiple versions of their files as attachments. Users can take advantage of these capabilities wherever they are, using the device of their choice, including PCs, Macs, tablets, and phones. Amazon WorkDocs offers IT administrators the option of integrating with existing corporate directories, flexible sharing policies and control of the location where data is stored.'\n",
      "\n",
      "=== 145 ===\n",
      "chunk.text (156 tokens):\n",
      "'Amazon WorkMail is a secure, managed business email and calendar service with support for existing desktop and mobile email client applications. Amazon WorkMail gives users the ability to seamlessly access their email, contacts, and calendars using the client application of their choice, including Microsoft Outlook, native iOS and Android email applications, any\\nAmazon SES\\nclient application supporting the IMAP protocol, or directly through a web browser. You can integrate Amazon WorkMail with your existing corporate directory, use email journaling to meet compliance requirements, and control both the keys that encrypt your data and the location in which your data Is stored. You can also set up interoperability with Microsoft Exchange Server, and programmatically manage users, groups, and resources using the Amazon WorkMail SDK.'\n",
      "chunker.contextualize(chunk) (159 tokens):\n",
      "'Amazon WorkMail\\nAmazon WorkMail is a secure, managed business email and calendar service with support for existing desktop and mobile email client applications. Amazon WorkMail gives users the ability to seamlessly access their email, contacts, and calendars using the client application of their choice, including Microsoft Outlook, native iOS and Android email applications, any\\nAmazon SES\\nclient application supporting the IMAP protocol, or directly through a web browser. You can integrate Amazon WorkMail with your existing corporate directory, use email journaling to meet compliance requirements, and control both the keys that encrypt your data and the location in which your data Is stored. You can also set up interoperability with Microsoft Exchange Server, and programmatically manage users, groups, and resources using the Amazon WorkMail SDK.'\n",
      "\n",
      "=== 146 ===\n",
      "chunk.text (78 tokens):\n",
      "'Whether you were born in the cloud, or you are just starting your migration journey to the cloud, AWS has a set of solutions to help you manage and optimize your spend.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS cost management strategy. For general information, see Cloud Financial Management with AWS.'\n",
      "chunker.contextualize(chunk) (81 tokens):\n",
      "'Cloud Financial Management\\nWhether you were born in the cloud, or you are just starting your migration journey to the cloud, AWS has a set of solutions to help you manage and optimize your spend.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS cost management strategy. For general information, see Cloud Financial Management with AWS.'\n",
      "\n",
      "=== 147 ===\n",
      "chunk.text (45 tokens):\n",
      "'- e AWS Application Cost Pronfier\\nCloud Financial Management\\n¢ AWS Billing Conductor\\n© AWS Cost Explorer\\n¢« AWS Budgets\\ne AWS Cost and Usage Report\\ne Reserved Instance (RI) reporting\\ne Savings Plans'\n",
      "chunker.contextualize(chunk) (46 tokens):\n",
      "'Services\\n- e AWS Application Cost Pronfier\\nCloud Financial Management\\n¢ AWS Billing Conductor\\n© AWS Cost Explorer\\n¢« AWS Budgets\\ne AWS Cost and Usage Report\\ne Reserved Instance (RI) reporting\\ne Savings Plans'\n",
      "\n",
      "=== 148 ===\n",
      "chunk.text (109 tokens):\n",
      "'AWS Application Cost Profiler provides you the ability to track the consumption of shared AWS resources used by software applications and report granular cost breakdown across tenant base. You can achieve economies of scale with the shared infrastructure model, while still maintaining a clear line of sight to detailed resource consumption information across multiple dimensions.\\nWith the proportionate cost insights of shared AWS resources, organizations running applications can establish the data foundation for accurate cost allocation model, and ISV selling applications can better understand your profitability and customize pricing strategies for your end customers.'\n",
      "chunker.contextualize(chunk) (115 tokens):\n",
      "'AWS Application Cost Profiler\\nAWS Application Cost Profiler provides you the ability to track the consumption of shared AWS resources used by software applications and report granular cost breakdown across tenant base. You can achieve economies of scale with the shared infrastructure model, while still maintaining a clear line of sight to detailed resource consumption information across multiple dimensions.\\nWith the proportionate cost insights of shared AWS resources, organizations running applications can establish the data foundation for accurate cost allocation model, and ISV selling applications can better understand your profitability and customize pricing strategies for your end customers.'\n",
      "\n",
      "=== 149 ===\n",
      "chunk.text (268 tokens):\n",
      "\"AWS Billing Conductor is a fully managed service that can support the showback and chargeback workflows of AWS Solution Providers and Enterprise customers. Using AWS Billing Conductor, you can customize your montnly billing data. Tne console models the billing relationship between you and your customers or business units. You can also customize a pro forma version of your billing data each month to accurately show or charge back your customers.\\nAWS Billing Conductor doesn't change the way that you're billed by Amazon Web Services each month. Instead, it provides you with a mechanism to configure, generate, and display rates to certain customers over a given billing period. You can also use it to analyze the difference between the rates you apply to your accounting groupings relative to your actual rates from AWS. As a result of your AWS Billing Conductor configuration, the payer account can also see the custom rate that's applied on the billing details page of the AWS Billing console, or configure a cost and usage report per billing group.\\nYou can configure the billing groups and pricing plans using the AWS Billing Conductor or the AWS Billing Conductor API. For more information about AWS Billing Conductor service quotas, refer to Quotas and restrictions.\\nAWS Application Cost Profiler\"\n",
      "chunker.contextualize(chunk) (272 tokens):\n",
      "\"AWS Billing Conductor\\nAWS Billing Conductor is a fully managed service that can support the showback and chargeback workflows of AWS Solution Providers and Enterprise customers. Using AWS Billing Conductor, you can customize your montnly billing data. Tne console models the billing relationship between you and your customers or business units. You can also customize a pro forma version of your billing data each month to accurately show or charge back your customers.\\nAWS Billing Conductor doesn't change the way that you're billed by Amazon Web Services each month. Instead, it provides you with a mechanism to configure, generate, and display rates to certain customers over a given billing period. You can also use it to analyze the difference between the rates you apply to your accounting groupings relative to your actual rates from AWS. As a result of your AWS Billing Conductor configuration, the payer account can also see the custom rate that's applied on the billing details page of the AWS Billing console, or configure a cost and usage report per billing group.\\nYou can configure the billing groups and pricing plans using the AWS Billing Conductor or the AWS Billing Conductor API. For more information about AWS Billing Conductor service quotas, refer to Quotas and restrictions.\\nAWS Application Cost Profiler\"\n",
      "\n",
      "=== 150 ===\n",
      "chunk.text (100 tokens):\n",
      "'AWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time. Get started quickly by creating custom reports (including charts and tabular data) that analyze cost and usage data, both at a high level (such as total costs and usage across all accounts) and for highly-specific requests (such as m2. 2xlarge costs within account Y that are tagged \"project: secretProject\").'\n",
      "chunker.contextualize(chunk) (104 tokens):\n",
      "'AWS Cost Explorer\\nAWS Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time. Get started quickly by creating custom reports (including charts and tabular data) that analyze cost and usage data, both at a high level (such as total costs and usage across all accounts) and for highly-specific requests (such as m2. 2xlarge costs within account Y that are tagged \"project: secretProject\").'\n",
      "\n",
      "=== 151 ===\n",
      "chunk.text (180 tokens):\n",
      "'AWS Budgets gives you the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount. You can also use AWS Budgets to set RI utilization or coverage targets and receive alerts when your utilization drops below the threshold you define. RI alerts support Amazon EC2, Amazon RDS, Amazon Redshift, and Amazon ElastiCache reservations.\\nBudgets can be tracked at the monthly, quarterly, or yearly level, and you can customize the start and end dates. You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others. Budget alerts can be sent via email and/or Amazon Simple Notification Service (Amazon SNS) topic.\\nBudgets can be created and tracked from the AWS Budgets dashboard or via the AWS Budgets API.'\n",
      "chunker.contextualize(chunk) (183 tokens):\n",
      "'AWS Budgets\\nAWS Budgets gives you the ability to set custom budgets that alert you when your costs or usage exceed (or are forecasted to exceed) your budgeted amount. You can also use AWS Budgets to set RI utilization or coverage targets and receive alerts when your utilization drops below the threshold you define. RI alerts support Amazon EC2, Amazon RDS, Amazon Redshift, and Amazon ElastiCache reservations.\\nBudgets can be tracked at the monthly, quarterly, or yearly level, and you can customize the start and end dates. You can further refine your budget to track costs associated with multiple dimensions, such as AWS service, linked account, tag, and others. Budget alerts can be sent via email and/or Amazon Simple Notification Service (Amazon SNS) topic.\\nBudgets can be created and tracked from the AWS Budgets dashboard or via the AWS Budgets API.'\n",
      "\n",
      "=== 152 ===\n",
      "chunk.text (93 tokens):\n",
      "'The AWS Cost and Usage Report is a single location for accessing comprehensive information about your AWS costs and usage.\\nThe AWS Cost and Usage Report lists AWS usage for each service category used by an account and its IAM users in hourly or daily line items, as well as any tags that you have activated for cost allocation purposes. You can also customize the AWS Cost and Usage Report to aggregate your usage data to the daily or monthly level.'\n",
      "chunker.contextualize(chunk) (99 tokens):\n",
      "'AWS Cost and Usage Report\\nThe AWS Cost and Usage Report is a single location for accessing comprehensive information about your AWS costs and usage.\\nThe AWS Cost and Usage Report lists AWS usage for each service category used by an account and its IAM users in hourly or daily line items, as well as any tags that you have activated for cost allocation purposes. You can also customize the AWS Cost and Usage Report to aggregate your usage data to the daily or monthly level.'\n",
      "\n",
      "=== 153 ===\n",
      "chunk.text (114 tokens):\n",
      "'AWS provides a number of RI-specific cost management solutions out-of-the-box to help you petter understand and manage your Rls. Using the RI Utilization and Coverage reports available in AWS Cost Explorer, you can visualize your RI data at an aggregate level or inspect a particular\\nAWS Cost Explorer\\nRI subscription. To access the most detailed RI information available, you can leverage the AWS Cost and Usage Report. You can also set a custom RI utilization target via AWS Budgets and receive alerts when your utilization drops below the threshold you define.'\n",
      "chunker.contextualize(chunk) (120 tokens):\n",
      "'Reserved Instance (RI) reporting\\nAWS provides a number of RI-specific cost management solutions out-of-the-box to help you petter understand and manage your Rls. Using the RI Utilization and Coverage reports available in AWS Cost Explorer, you can visualize your RI data at an aggregate level or inspect a particular\\nAWS Cost Explorer\\nRI subscription. To access the most detailed RI information available, you can leverage the AWS Cost and Usage Report. You can also set a custom RI utilization target via AWS Budgets and receive alerts when your utilization drops below the threshold you define.'\n",
      "\n",
      "=== 154 ===\n",
      "chunk.text (156 tokens):\n",
      "'Savings Plans is a flexible pricing model offering lower prices compared to On-Demand pricing, in exchange for a specific usage commitment (measured in $/hour) for a one or three-year period. AWS offers three types of Savings Plans —- Compute Savings Plans, Amazon EC2 Instance Savings Plans, and Amazon SageMaker Al Savings Plans. Compute Savings Plans apply to usage across Amazon EC2, AWS Lambda, and AWS Fargate. The Amazon EC2 Instance Savings Plans apply to EC2 usage, and Amazon SageMaker Al Savings Plans apply to Amazon SageMaker Al usage. You can easily sign up a One- or three-year term Savings Plans in AWS Cost Explorer and manage your plans by taking advantage of recommendations, performance reporting, and budget alerts.'\n",
      "chunker.contextualize(chunk) (158 tokens):\n",
      "'Savings Plans\\nSavings Plans is a flexible pricing model offering lower prices compared to On-Demand pricing, in exchange for a specific usage commitment (measured in $/hour) for a one or three-year period. AWS offers three types of Savings Plans —- Compute Savings Plans, Amazon EC2 Instance Savings Plans, and Amazon SageMaker Al Savings Plans. Compute Savings Plans apply to usage across Amazon EC2, AWS Lambda, and AWS Fargate. The Amazon EC2 Instance Savings Plans apply to EC2 usage, and Amazon SageMaker Al Savings Plans apply to Amazon SageMaker Al usage. You can easily sign up a One- or three-year term Savings Plans in AWS Cost Explorer and manage your plans by taking advantage of recommendations, performance reporting, and budget alerts.'\n",
      "\n",
      "=== 155 ===\n",
      "chunk.text (71 tokens):\n",
      "'Millions of organizations run diverse workloads using AWS compute services.\\nEacn service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS compute service or Amazon Lightsail, AWS Elastic Beanstalk, or Amazon EC2?. For general information, see Compute on AWS.\\nSavings Plans'\n",
      "chunker.contextualize(chunk) (72 tokens):\n",
      "'Compute\\nMillions of organizations run diverse workloads using AWS compute services.\\nEacn service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS compute service or Amazon Lightsail, AWS Elastic Beanstalk, or Amazon EC2?. For general information, see Compute on AWS.\\nSavings Plans'\n",
      "\n",
      "=== 156 ===\n",
      "chunk.text (50 tokens):\n",
      "'Compare AWS compute services\\nAmazon EC2 Auto Scaling\\nAmazon EC2 Image Builder\\nAmazon Lightsall\\nAmazon Linux 7074\\nWS App Runner\\nAWS Elastic Beanstalk\\nAWS Fargate\\nAWS Servertess Application Repository\\nAWS Outposts\\nAWS Wavelength'\n",
      "chunker.contextualize(chunk) (51 tokens):\n",
      "'Topics\\nCompare AWS compute services\\nAmazon EC2 Auto Scaling\\nAmazon EC2 Image Builder\\nAmazon Lightsall\\nAmazon Linux 7074\\nWS App Runner\\nAWS Elastic Beanstalk\\nAWS Fargate\\nAWS Servertess Application Repository\\nAWS Outposts\\nAWS Wavelength'\n",
      "\n",
      "=== 157 ===\n",
      "chunk.text (475 tokens):\n",
      "'Instances (virtual machines), AWS service = • Amazon Elastic Compute Cloud (Amazon  EC2) - Secure and resizeable compute  capacity (virtual servers) in the cloud • Amazon EC2 Spot Instances- Run fault-tol  erant workloads for up to 90% off • Amazon EC2 Auto Scaling - Automatically  add or remove compute capacity to meet  changes in demand • Amazon Lightsail - Easy-to-use cloud  platform that offers you everything you  need to build an application or website • AWS Batch - Fully managed batch. Containers, AWS service = • Amazon Elastic Container Service (Amazon  ECS) - Highly secure, reliable, and scalable  way to run containers • Amazon ECS Anywhere - Run containers on  customer managed infrastructure • Amazon Elastic Container Registry (Amazon  ECR) - Easily store, manage, and deploy  container images • Amazon Elastic Kubernetes Service (Amazon  EKS) - Fully managed Kubernetes service • Amazon EKS Anywhere - Create and  operate Kubernetes clusters on your own  infrastructure\\nServerless, AWS service = • AWS Fargate - Serverless compute for  containers • AWS App Runner - Build and run container  ized applications on a fully managed service • AWS Lambda - Run code without thinking. Edge and hybrid, AWS service = • AWS Outposts - Run AWS infrastru  cture and services on premises for a truly  consistent hybrid experience • AWS Snow Family - Collect and process  data in rugged or disconnected edge  environments • AWS Wavelength - Deliver ultra-low  latency application for 5G devices • VMware Cloud on AWS - Preferred service  for all vSphere workloads to rapidly extend  and migrate to the cloud • AWS Local Zones - Run latency sensitive  applications closer to end-users\\nCost and capacity management, AWS service = • AWS Savings Plan - Flexible pricing model  that provides savings of up to 72% on AWS  compute usage • AWS Compute Optimizer - Recommend  s optimal AWS compute resources for your  workloads to reduce costs and improve  performance • AWS Elastic Beanstalk - Easy-to-use service  for deploying and scaling web applications  and services • EC2 Image Builder - Build and maintain  secure Linux or Windows Server images • Elastic Load Balancing (ELB) - Automatic  ally distribute incoming application traffic  across multiple targets'\n",
      "chunker.contextualize(chunk) (480 tokens):\n",
      "'Compare AWS compute services\\nInstances (virtual machines), AWS service = • Amazon Elastic Compute Cloud (Amazon  EC2) - Secure and resizeable compute  capacity (virtual servers) in the cloud • Amazon EC2 Spot Instances- Run fault-tol  erant workloads for up to 90% off • Amazon EC2 Auto Scaling - Automatically  add or remove compute capacity to meet  changes in demand • Amazon Lightsail - Easy-to-use cloud  platform that offers you everything you  need to build an application or website • AWS Batch - Fully managed batch. Containers, AWS service = • Amazon Elastic Container Service (Amazon  ECS) - Highly secure, reliable, and scalable  way to run containers • Amazon ECS Anywhere - Run containers on  customer managed infrastructure • Amazon Elastic Container Registry (Amazon  ECR) - Easily store, manage, and deploy  container images • Amazon Elastic Kubernetes Service (Amazon  EKS) - Fully managed Kubernetes service • Amazon EKS Anywhere - Create and  operate Kubernetes clusters on your own  infrastructure\\nServerless, AWS service = • AWS Fargate - Serverless compute for  containers • AWS App Runner - Build and run container  ized applications on a fully managed service • AWS Lambda - Run code without thinking. Edge and hybrid, AWS service = • AWS Outposts - Run AWS infrastru  cture and services on premises for a truly  consistent hybrid experience • AWS Snow Family - Collect and process  data in rugged or disconnected edge  environments • AWS Wavelength - Deliver ultra-low  latency application for 5G devices • VMware Cloud on AWS - Preferred service  for all vSphere workloads to rapidly extend  and migrate to the cloud • AWS Local Zones - Run latency sensitive  applications closer to end-users\\nCost and capacity management, AWS service = • AWS Savings Plan - Flexible pricing model  that provides savings of up to 72% on AWS  compute usage • AWS Compute Optimizer - Recommend  s optimal AWS compute resources for your  workloads to reduce costs and improve  performance • AWS Elastic Beanstalk - Easy-to-use service  for deploying and scaling web applications  and services • EC2 Image Builder - Build and maintain  secure Linux or Windows Server images • Elastic Load Balancing (ELB) - Automatic  ally distribute incoming application traffic  across multiple targets'\n",
      "\n",
      "=== 158 ===\n",
      "chunk.text (177 tokens):\n",
      "\"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale computing easier for developers.\\nThe simple web interface of Amazon EC2 allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon's proven computing environment. Amazon EC2 reduces the time required to obtain and poot new server instances (called Amazon EC2 instances) to minutes, allowing you to quickly scale Capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use. Amazon EC2 provides developers and system administrators the tools to build failure resilient applications and isolate themselves trom common failure scenarios.\\nAmazon ECZ7\"\n",
      "chunker.contextualize(chunk) (182 tokens):\n",
      "\"Compare AWS compute services\\nAmazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale computing easier for developers.\\nThe simple web interface of Amazon EC2 allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon's proven computing environment. Amazon EC2 reduces the time required to obtain and poot new server instances (called Amazon EC2 instances) to minutes, allowing you to quickly scale Capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use. Amazon EC2 provides developers and system administrators the tools to build failure resilient applications and isolate themselves trom common failure scenarios.\\nAmazon ECZ7\"\n",
      "\n",
      "=== 159 ===\n",
      "chunk.text (466 tokens):\n",
      "\"Amazon EC2 passes on to you the financial benefits of Amazon scale. You pay a very low rate for the compute capacity you actually consume. For a more detailed description, refer to Amazon EC2 Dricing.\\nAmazon EC2 instance types are named based on their family, generation, processor family, additional capabilities, and size.\\ne On-Demand Instances — With On-Demand Instances, you pay for compute capacity by the hour or the second depending on which instances you run. No longer-term commitments or uptront payments are needed. You can increase or decrease your compute capacity depending on the demands of your application and only pay the specified per hourly rates for the instance you use. On-Demand Instances are recommended for:\\ne Users that prefer the low cost and flexibility of Amazon EC2 without any up-front payment or Long-term commitment\\ne Applications with short-term, spiky, or unpredictable workloads that cannot be interrupted\\ne Applications being developed or tested on Amazon EC2 for the first time\\n¢ Spot Instances —Spot Instances are available at up to a 90% discount compared to On-Demand prices and let you take advantage of unused Amazon EC2 capacity in the AWS Cloud. You can Significantly reduce the cost of running your applications, grow your application's compute Capacity and throughput for the same budget, and enable new types of cloud computing applications. Spot Instances are recommended for:\\ne Applications that have flexible start and end times\\ne Applications that are only feasible at very low compute prices\\ne Users with urgent computing needs for large amounts of additional capacity\\n- Reserved Instances — Reserved Instances provide you with a significant discount (up to 72%) compared to On-Demand Instance pricing. You Nave the flexibility to change families, operating system types, and tenancies while benefiting from Reserved Instance pricing when you use Convertible Reserved Instances.\\n« C7g Instances — C/g Instances, powered by the latest generation AWS Graviton3 processors, provide the best price performance in Amazon EC2 for compute-intensive workloads. C/7g instances are ideal for high performance computing (HPC), batch processing, electronic design automation (EDA), gaming, video encoding, scientific modeling, distriduted analytics, CPU-based ML inference, and ad serving.\\nAmazon ECZ7\"\n",
      "chunker.contextualize(chunk) (468 tokens):\n",
      "\"instance types\\nAmazon EC2 passes on to you the financial benefits of Amazon scale. You pay a very low rate for the compute capacity you actually consume. For a more detailed description, refer to Amazon EC2 Dricing.\\nAmazon EC2 instance types are named based on their family, generation, processor family, additional capabilities, and size.\\ne On-Demand Instances — With On-Demand Instances, you pay for compute capacity by the hour or the second depending on which instances you run. No longer-term commitments or uptront payments are needed. You can increase or decrease your compute capacity depending on the demands of your application and only pay the specified per hourly rates for the instance you use. On-Demand Instances are recommended for:\\ne Users that prefer the low cost and flexibility of Amazon EC2 without any up-front payment or Long-term commitment\\ne Applications with short-term, spiky, or unpredictable workloads that cannot be interrupted\\ne Applications being developed or tested on Amazon EC2 for the first time\\n¢ Spot Instances —Spot Instances are available at up to a 90% discount compared to On-Demand prices and let you take advantage of unused Amazon EC2 capacity in the AWS Cloud. You can Significantly reduce the cost of running your applications, grow your application's compute Capacity and throughput for the same budget, and enable new types of cloud computing applications. Spot Instances are recommended for:\\ne Applications that have flexible start and end times\\ne Applications that are only feasible at very low compute prices\\ne Users with urgent computing needs for large amounts of additional capacity\\n- Reserved Instances — Reserved Instances provide you with a significant discount (up to 72%) compared to On-Demand Instance pricing. You Nave the flexibility to change families, operating system types, and tenancies while benefiting from Reserved Instance pricing when you use Convertible Reserved Instances.\\n« C7g Instances — C/g Instances, powered by the latest generation AWS Graviton3 processors, provide the best price performance in Amazon EC2 for compute-intensive workloads. C/7g instances are ideal for high performance computing (HPC), batch processing, electronic design automation (EDA), gaming, video encoding, scientific modeling, distriduted analytics, CPU-based ML inference, and ad serving.\\nAmazon ECZ7\"\n",
      "\n",
      "=== 160 ===\n",
      "chunk.text (421 tokens):\n",
      "'e Inf2 Instances — Inf2 Instances are purpose--built for deep learning inference. They deliver high performance at the lowest cost in Amazon EC2 for generative Al models, including large language models (LLMs) and vision transformers. Inf2 instances are powered by AWS Inferentia2, the second-generation AWS Inferentia accelerator.\\ne M7g Instances — M/g instances, powered by the latest generation AWS Graviton3 processors, provide the best price performance in Amazon EC2 for general purpose workloads. M7gq instances are ideal for applications built on open-source software such as application servers, microservices, gaming servers, mid-size data stores, and caching fleets.\\n¢ R7g Instances — R/g Instances, powered by the latest generation AWS GravitonS processors, provide the best price performance in Amazon EC2 for memory-intensive workloads. R7gq instances are ideal for memory-intensive workloads such as open-source databases, in-memory caches, and near real-time big data analytics.\\n¢ Trn1 Instances — Trn71 Instances, powered by AWS Trainium accelerators, are purpose-built for high-performance deep learning training of generative Al models, including LLMs and latent diffusion models. Trn1 instances offer up to 50% cost-to-train savings over other comparable Amazon EC? instances.\\ne Savings Plans — Savings Plans are a flexible pricing model that offer low prices on EC2 and Fargate usage, in exchange for a commitment to a consistent amount of usage (measured in $/ hour) for a one or three year term.\\ne Dedicated Hosts — A Dedicated Host is a physical EC2 server dedicated for your use. Dedicated Hosts can help you reduce costs by allowing you to use your existing server-bound software licenses, including Windows Server, Microsoft SQL Server, and SUSE Linux Enterprise Server (Subject to your license terms), and can also help you meet compliance requirements.'\n",
      "chunker.contextualize(chunk) (423 tokens):\n",
      "'instance types\\ne Inf2 Instances — Inf2 Instances are purpose--built for deep learning inference. They deliver high performance at the lowest cost in Amazon EC2 for generative Al models, including large language models (LLMs) and vision transformers. Inf2 instances are powered by AWS Inferentia2, the second-generation AWS Inferentia accelerator.\\ne M7g Instances — M/g instances, powered by the latest generation AWS Graviton3 processors, provide the best price performance in Amazon EC2 for general purpose workloads. M7gq instances are ideal for applications built on open-source software such as application servers, microservices, gaming servers, mid-size data stores, and caching fleets.\\n¢ R7g Instances — R/g Instances, powered by the latest generation AWS GravitonS processors, provide the best price performance in Amazon EC2 for memory-intensive workloads. R7gq instances are ideal for memory-intensive workloads such as open-source databases, in-memory caches, and near real-time big data analytics.\\n¢ Trn1 Instances — Trn71 Instances, powered by AWS Trainium accelerators, are purpose-built for high-performance deep learning training of generative Al models, including LLMs and latent diffusion models. Trn1 instances offer up to 50% cost-to-train savings over other comparable Amazon EC? instances.\\ne Savings Plans — Savings Plans are a flexible pricing model that offer low prices on EC2 and Fargate usage, in exchange for a commitment to a consistent amount of usage (measured in $/ hour) for a one or three year term.\\ne Dedicated Hosts — A Dedicated Host is a physical EC2 server dedicated for your use. Dedicated Hosts can help you reduce costs by allowing you to use your existing server-bound software licenses, including Windows Server, Microsoft SQL Server, and SUSE Linux Enterprise Server (Subject to your license terms), and can also help you meet compliance requirements.'\n",
      "\n",
      "=== 161 ===\n",
      "chunk.text (118 tokens):\n",
      "'Amazon EC2 Auto Scaling helps you maintain application availability and allows you to automatically add or remove EC2 instances according to conditions you define. You can use the fleet management features of Amazon EC2 Auto Scaling to maintain the health and availability of your fleet. You can also use the dynamic and predictive scaling features of Amazon EC2 Auto Scaling to add or remove EC2 instances. Dynamic scaling responds to changing demand and predictive scaling automatically schedules the right number of EC2 instances based on predicted demand. Dynamic scaling and predictive scaling can be used together to scale faster.\\nAmazon EC2 Auto Scaling'\n",
      "chunker.contextualize(chunk) (123 tokens):\n",
      "'Amazon EC2 Auto Scaling\\nAmazon EC2 Auto Scaling helps you maintain application availability and allows you to automatically add or remove EC2 instances according to conditions you define. You can use the fleet management features of Amazon EC2 Auto Scaling to maintain the health and availability of your fleet. You can also use the dynamic and predictive scaling features of Amazon EC2 Auto Scaling to add or remove EC2 instances. Dynamic scaling responds to changing demand and predictive scaling automatically schedules the right number of EC2 instances based on predicted demand. Dynamic scaling and predictive scaling can be used together to scale faster.\\nAmazon EC2 Auto Scaling'\n",
      "\n",
      "=== 162 ===\n",
      "chunk.text (174 tokens):\n",
      "'EC2 Image Builder simplifies the building, testing, and deployment of VMs and container images for use on AWS or on-premises.\\nKeeping virtual machine (VM) and container images up-to-date can be time consuming, resource intensive, and error-prone. Currently, customers either manually update and snapshot VMs or have teams that build automation scripts to maintain images.\\nEC2 Image Builder significantly reduces the effort of keeping images up-to-date and secure by providing a simple graphical interface, built-in automation, and AWS-provided security settings. With Image Builder, there are no manual steps for updating an image nor do you Nave to build your own automation pipetine.\\nImage Builder is offered at no cost, other than the cost of the underlying AWS resources used to create, store, and snare the images.'\n",
      "chunker.contextualize(chunk) (179 tokens):\n",
      "'Amazon EC2 Image Builder\\nEC2 Image Builder simplifies the building, testing, and deployment of VMs and container images for use on AWS or on-premises.\\nKeeping virtual machine (VM) and container images up-to-date can be time consuming, resource intensive, and error-prone. Currently, customers either manually update and snapshot VMs or have teams that build automation scripts to maintain images.\\nEC2 Image Builder significantly reduces the effort of keeping images up-to-date and secure by providing a simple graphical interface, built-in automation, and AWS-provided security settings. With Image Builder, there are no manual steps for updating an image nor do you Nave to build your own automation pipetine.\\nImage Builder is offered at no cost, other than the cost of the underlying AWS resources used to create, store, and snare the images.'\n",
      "\n",
      "=== 163 ===\n",
      "chunk.text (68 tokens):\n",
      "'Amazon Lightsail is designed to be the easiest way to launch and manage a virtual private server with AWS. Lightsail plans include everything you need to jumpstart your project —-a VM, SSD-basea storage, data transfer, DNS management, and a static IP address — for a low, predictable price.'\n",
      "chunker.contextualize(chunk) (71 tokens):\n",
      "'Amazon Lightsail\\nAmazon Lightsail is designed to be the easiest way to launch and manage a virtual private server with AWS. Lightsail plans include everything you need to jumpstart your project —-a VM, SSD-basea storage, data transfer, DNS management, and a static IP address — for a low, predictable price.'\n",
      "\n",
      "=== 164 ===\n",
      "chunk.text (314 tokens):\n",
      "'Amazon Linux 2024 (AL2023) is our new Linux-based operating system for AWS that is designed to provide a secure, stable, high-performance environment to develop and run your cloud applications. AL2025 provides seamless integration with various AWS services and development tools, and offers optimized performance tor Amazon EC2 Graviton-based instances and Support at no additional licensing cost. Starting with AL2024, a new Amazon Linux major release will be available every two years. This cadence provides you with a more predictable release cycle and up to 5 years of support, making it easier for you to plan your upgrades.\\nAL2023 otters several improvements over Amazon Linux 2 (AL2). For example, AL2023 takes a security-by-detault approach to help improve your security posture with preconfigured security policies, SELinux in permissive mode and IMDSv2 enabled by default, and the availability of kernel tive patching. With deterministic upgrades through versioned repositories, you can lock to a specific version of the Amazon Linux package repository, giving you control over how and when you absorb\\nAmazon EC2 Image Builder\\nupdates. With this capability, you can adhere to operational best practices more efficiently by ensuring consistency between package versions and updates across your environment. For a full comparison, refer to Comparing Amazon Linux 2 and Amazon Linux 2023.\\nAmazon Linux 2023 is generally available in all AWS Regions, including the AWS GovCloud (US) and the China Regions.'\n",
      "chunker.contextualize(chunk) (318 tokens):\n",
      "'Amazon Linux 2023\\nAmazon Linux 2024 (AL2023) is our new Linux-based operating system for AWS that is designed to provide a secure, stable, high-performance environment to develop and run your cloud applications. AL2025 provides seamless integration with various AWS services and development tools, and offers optimized performance tor Amazon EC2 Graviton-based instances and Support at no additional licensing cost. Starting with AL2024, a new Amazon Linux major release will be available every two years. This cadence provides you with a more predictable release cycle and up to 5 years of support, making it easier for you to plan your upgrades.\\nAL2023 otters several improvements over Amazon Linux 2 (AL2). For example, AL2023 takes a security-by-detault approach to help improve your security posture with preconfigured security policies, SELinux in permissive mode and IMDSv2 enabled by default, and the availability of kernel tive patching. With deterministic upgrades through versioned repositories, you can lock to a specific version of the Amazon Linux package repository, giving you control over how and when you absorb\\nAmazon EC2 Image Builder\\nupdates. With this capability, you can adhere to operational best practices more efficiently by ensuring consistency between package versions and updates across your environment. For a full comparison, refer to Comparing Amazon Linux 2 and Amazon Linux 2023.\\nAmazon Linux 2023 is generally available in all AWS Regions, including the AWS GovCloud (US) and the China Regions.'\n",
      "\n",
      "=== 165 ===\n",
      "chunk.text (244 tokens):\n",
      "'AWS App Runner is a fully managed service that makes it easy for developers to quickly deploy containerized web applications and APIs, at scale and with no prior infrastructure experience required. Start with your source code or a container image. AWS App Runner automatically builds and deploys the web application and load balances trafic with encryption. App Runner also scales up or down automatically to meet your traffic needs. With App Runner, rather than thinking about servers or scaling, you have more time to focus on your applications.\\nAWS Batch enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources (such as CPU or memory-optimized instances) based on the volume and specific resource requirements of the batch jobs submitted. With AWS Batch, there is no need to install and manage batch computing software or server clusters that you use to run your jobs, allowing you to focus on analyzing results and solving problems. AWS Batch plans, schedules, and runs your batch computing workloads across the full range of AWS compute services and features, such as Amazon EC2 and Spot Instances.'\n",
      "chunker.contextualize(chunk) (248 tokens):\n",
      "'AWS App Runner\\nAWS App Runner is a fully managed service that makes it easy for developers to quickly deploy containerized web applications and APIs, at scale and with no prior infrastructure experience required. Start with your source code or a container image. AWS App Runner automatically builds and deploys the web application and load balances trafic with encryption. App Runner also scales up or down automatically to meet your traffic needs. With App Runner, rather than thinking about servers or scaling, you have more time to focus on your applications.\\nAWS Batch enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources (such as CPU or memory-optimized instances) based on the volume and specific resource requirements of the batch jobs submitted. With AWS Batch, there is no need to install and manage batch computing software or server clusters that you use to run your jobs, allowing you to focus on analyzing results and solving problems. AWS Batch plans, schedules, and runs your batch computing workloads across the full range of AWS compute services and features, such as Amazon EC2 and Spot Instances.'\n",
      "\n",
      "=== 166 ===\n",
      "chunk.text (134 tokens):\n",
      "'AWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and Internet Information Services (IIS).\\nYou can simply upload your code, and AWS Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, and auto scaling to application health monitoring. At the same time, you retain full control over the AWS resources powering your application and can access the underlying resources at any time.\\nAWS App Runner'\n",
      "chunker.contextualize(chunk) (139 tokens):\n",
      "'AWS Elastic Beanstalk\\nAWS Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and Internet Information Services (IIS).\\nYou can simply upload your code, and AWS Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, and auto scaling to application health monitoring. At the same time, you retain full control over the AWS resources powering your application and can access the underlying resources at any time.\\nAWS App Runner'\n",
      "\n",
      "=== 167 ===\n",
      "chunk.text (352 tokens):\n",
      "'AWS Fargate is a compute engine for Amazon ECS that allows you to run containers without naving to manage servers or clusters. With AWS Fargate, you no longer Nave to provision, configure, and Scale clusters of VMs to run containers. This removes the need to choose server types, decide wnen to scale your clusters, or optimize cluster packing. Fargate removes the need for you to interact with or think about servers or clusters. Fargate lets you focus on designing and building your applications instead of managing the infrastructure that runs them.\\nAmazon ECS has two modes: Fargate launch type and EC2 launch type. With Fargate launch type, all you have to do is package your application in containers, specify the CPU and memory requirements, define networking and IAM policies, and launch the application. EC2 launch type allows you to Nave server-level, more granular control over the infrastructure that runs your container applications. With EC2 launch type, you can use Amazon ECS to manage a cluster of servers and schedule placement of containers on the servers. Amazon ECS keeps track of all the CPU, memory and other resources in your cluster, and also finds the best server for a container to run on based on your specified resource requirements.\\nYou are responsible for provisioning, patching, and scaling clusters of servers. You can decide which type of server to use, which applications and how many containers to run in a cluster to optimize utilization, and when you should add or remove servers from a cluster. EC2 launch type gives you more control of your server clusters and provides a broader range of customization options, which might be required to support some specific applications or possible compliance and government requirements.'\n",
      "chunker.contextualize(chunk) (356 tokens):\n",
      "'AWS Fargate\\nAWS Fargate is a compute engine for Amazon ECS that allows you to run containers without naving to manage servers or clusters. With AWS Fargate, you no longer Nave to provision, configure, and Scale clusters of VMs to run containers. This removes the need to choose server types, decide wnen to scale your clusters, or optimize cluster packing. Fargate removes the need for you to interact with or think about servers or clusters. Fargate lets you focus on designing and building your applications instead of managing the infrastructure that runs them.\\nAmazon ECS has two modes: Fargate launch type and EC2 launch type. With Fargate launch type, all you have to do is package your application in containers, specify the CPU and memory requirements, define networking and IAM policies, and launch the application. EC2 launch type allows you to Nave server-level, more granular control over the infrastructure that runs your container applications. With EC2 launch type, you can use Amazon ECS to manage a cluster of servers and schedule placement of containers on the servers. Amazon ECS keeps track of all the CPU, memory and other resources in your cluster, and also finds the best server for a container to run on based on your specified resource requirements.\\nYou are responsible for provisioning, patching, and scaling clusters of servers. You can decide which type of server to use, which applications and how many containers to run in a cluster to optimize utilization, and when you should add or remove servers from a cluster. EC2 launch type gives you more control of your server clusters and provides a broader range of customization options, which might be required to support some specific applications or possible compliance and government requirements.'\n",
      "\n",
      "=== 168 ===\n",
      "chunk.text (111 tokens):\n",
      "'AWS Lambda lets you run code without provisioning or managing servers. You pay only for the compute time you consume—tnhere is no charge when your code Is not running. With Lambda, you can run code for virtually any type of application or backend service—all with zero administration. Just upload your code, and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically run from other AWS services, or you can call it directly from any web or mobile app.'\n",
      "chunker.contextualize(chunk) (114 tokens):\n",
      "'AWS Lambda\\nAWS Lambda lets you run code without provisioning or managing servers. You pay only for the compute time you consume—tnhere is no charge when your code Is not running. With Lambda, you can run code for virtually any type of application or backend service—all with zero administration. Just upload your code, and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically run from other AWS services, or you can call it directly from any web or mobile app.'\n",
      "\n",
      "=== 169 ===\n",
      "chunk.text (185 tokens):\n",
      "\"The AWS Servertess Application Repository enables you to quickly deploy code samples, components, and complete applications for common use cases such as web and mobile backends,\\nAWS Fargate\\nevent and data processing, logging, monitoring, Internet of Things (loT), and more. Each application is packaged with an AWS Serverless Application Model (AWS SAM) template that defines the AWS resources used. Publicly shared applications also include a link to the application's source code. There is no additional charge to use the AWS Serverless Application Repository - you only pay for the AWS resources used in the applications you deploy.\\nYou can also use the AWS Servertess Application Repository to publish your own applications and Snare them within your team, across your organization, or with the community at large. To share an application you've built, publish it to the AWS Servertess Application Repository.\"\n",
      "chunker.contextualize(chunk) (191 tokens):\n",
      "\"AWS Serverless Application Repository\\nThe AWS Servertess Application Repository enables you to quickly deploy code samples, components, and complete applications for common use cases such as web and mobile backends,\\nAWS Fargate\\nevent and data processing, logging, monitoring, Internet of Things (loT), and more. Each application is packaged with an AWS Serverless Application Model (AWS SAM) template that defines the AWS resources used. Publicly shared applications also include a link to the application's source code. There is no additional charge to use the AWS Serverless Application Repository - you only pay for the AWS resources used in the applications you deploy.\\nYou can also use the AWS Servertess Application Repository to publish your own applications and Snare them within your team, across your organization, or with the community at large. To share an application you've built, publish it to the AWS Servertess Application Repository.\"\n",
      "\n",
      "=== 170 ===\n",
      "chunk.text (250 tokens):\n",
      "'AWS Outposts bring native AWS services, infrastructure, and operating models to virtually any data center, co-location space, or on-premises facility. You can use the same APIs, the same tools, the Same hardware, and the same functionality across on-premises and the cloud to deliver a truly consistent hybrid experience. Outposts can be used to support workloads that need to remain onpremises due to low latency or local data processing needs.\\nAWS Outposts come in two variants:\\n¢ VMware Cloud on AWS Outposts allows you to use the same VMware control plane and APIs you use to run your infrastructure.\\ne AWS-native variant of AWS Outposts allows you to use the same exact APIs and control plane you use to run in the AWS Cloud, but on-premises.\\nAWS Outposts infrastructure is Tully managed, maintained, and supported by AWS to deliver access to the latest AWS services. Getting started is easy, you simply log into the AWS Management Console to order your Outposts servers, choosing from a wide range of compute and storage options. You can order one or more servers, or quarter, half, and full rack units.'\n",
      "chunker.contextualize(chunk) (254 tokens):\n",
      "'AWS Outposts\\nAWS Outposts bring native AWS services, infrastructure, and operating models to virtually any data center, co-location space, or on-premises facility. You can use the same APIs, the same tools, the Same hardware, and the same functionality across on-premises and the cloud to deliver a truly consistent hybrid experience. Outposts can be used to support workloads that need to remain onpremises due to low latency or local data processing needs.\\nAWS Outposts come in two variants:\\n¢ VMware Cloud on AWS Outposts allows you to use the same VMware control plane and APIs you use to run your infrastructure.\\ne AWS-native variant of AWS Outposts allows you to use the same exact APIs and control plane you use to run in the AWS Cloud, but on-premises.\\nAWS Outposts infrastructure is Tully managed, maintained, and supported by AWS to deliver access to the latest AWS services. Getting started is easy, you simply log into the AWS Management Console to order your Outposts servers, choosing from a wide range of compute and storage options. You can order one or more servers, or quarter, half, and full rack units.'\n",
      "\n",
      "=== 171 ===\n",
      "chunk.text (128 tokens):\n",
      "\"AWS Wavelength Is an AWS Infrastructure offering optimized for mobile edge computing applications. Wavelength Zones are AWS infrastructure deployments that embed AWS compute and storage services within communications service providers' (CSP) datacenters at the edge oT the 5G network, so application traffic from 5G devices can reach application servers running in Wavelength Zones without leaving the telecommunications network. This avoids the latency that would result from application trafic having to traverse multiple hops across the Internet to reach\\nAWS Outposts\\ntheir destination, enabling customers to take full advantage of the latency and bandwidth benefits offered by modern 5G networks.\"\n",
      "chunker.contextualize(chunk) (131 tokens):\n",
      "\"AWS Wavelength\\nAWS Wavelength Is an AWS Infrastructure offering optimized for mobile edge computing applications. Wavelength Zones are AWS infrastructure deployments that embed AWS compute and storage services within communications service providers' (CSP) datacenters at the edge oT the 5G network, so application traffic from 5G devices can reach application servers running in Wavelength Zones without leaving the telecommunications network. This avoids the latency that would result from application trafic having to traverse multiple hops across the Internet to reach\\nAWS Outposts\\ntheir destination, enabling customers to take full advantage of the latency and bandwidth benefits offered by modern 5G networks.\"\n",
      "\n",
      "=== 172 ===\n",
      "chunk.text (440 tokens):\n",
      "\"VMware Cloud on AWS is an integrated cloud offering jointly developed by AWS and VMware delivering a highly scalable, secure and innovative service that allows organizations to seamlessly migrate and extend their on-premises VMware vSphere-based environments to the AWS Cloud running on next-generation Amazon Elastic Compute Cloud (Amazon EC2) bare metal infrastructure. VMware Cloud on AWS Is ideal for enterprise IT infrastructure and operations organizations looking to migrate their on-premises vSphere-based workloads to the public cloud, consolidate and extend their data center capacities, and optimize, simplify and modernize their disaster recovery solutions.\\nVMware Cloud on AWS Is delivered, sold, and supported globally by VMware and Its partners with availability in the following AWS Regions: AWS Europe (Stockholm), AWS US East (Northern Virginia), AWS US East (Ohio), AWS US West (Northern California), AWS US West (Oregon), AWS Canada (Central), AWS Europe (Frankfurt), AWS Europe (Ireland), AWS Europe (London), AWS Europe (Paris), AWS Europe (Milan), AWS Asia Pacific (Singapore), AWS Asia Pacific (Sydney), AWS Asia Pacific (Tokyo), AWS Asia Pacific (Mumbai) Region, AWS South America (Sao Paulo), AWS Asia Pacific (Seoul), and AWS GovCloud (US West). With each release, VMware Cloud on AWS availability will expand into additional global regions.\\nVMware Cloud on AWS brings the broad, diverse and rich innovations of AWS services natively to the enterprise applications running on VMware's compute, storage and network virtualization platforms. This allows organizations to easily and rapidly add new innovations to their enterprise applications by natively integrating AWS infrastructure and platform capabilities such as AWS Lambda, Amazon Simple Queue Service (Amazon SQS), Amazon S3, Elastic Load Balancing, Amazon RDS, Amazon DynamoDB, Amazon Kinesis, and Amazon Redshift, among many others.\"\n",
      "chunker.contextualize(chunk) (447 tokens):\n",
      "\"VMware Cloud on AWS\\nVMware Cloud on AWS is an integrated cloud offering jointly developed by AWS and VMware delivering a highly scalable, secure and innovative service that allows organizations to seamlessly migrate and extend their on-premises VMware vSphere-based environments to the AWS Cloud running on next-generation Amazon Elastic Compute Cloud (Amazon EC2) bare metal infrastructure. VMware Cloud on AWS Is ideal for enterprise IT infrastructure and operations organizations looking to migrate their on-premises vSphere-based workloads to the public cloud, consolidate and extend their data center capacities, and optimize, simplify and modernize their disaster recovery solutions.\\nVMware Cloud on AWS Is delivered, sold, and supported globally by VMware and Its partners with availability in the following AWS Regions: AWS Europe (Stockholm), AWS US East (Northern Virginia), AWS US East (Ohio), AWS US West (Northern California), AWS US West (Oregon), AWS Canada (Central), AWS Europe (Frankfurt), AWS Europe (Ireland), AWS Europe (London), AWS Europe (Paris), AWS Europe (Milan), AWS Asia Pacific (Singapore), AWS Asia Pacific (Sydney), AWS Asia Pacific (Tokyo), AWS Asia Pacific (Mumbai) Region, AWS South America (Sao Paulo), AWS Asia Pacific (Seoul), and AWS GovCloud (US West). With each release, VMware Cloud on AWS availability will expand into additional global regions.\\nVMware Cloud on AWS brings the broad, diverse and rich innovations of AWS services natively to the enterprise applications running on VMware's compute, storage and network virtualization platforms. This allows organizations to easily and rapidly add new innovations to their enterprise applications by natively integrating AWS infrastructure and platform capabilities such as AWS Lambda, Amazon Simple Queue Service (Amazon SQS), Amazon S3, Elastic Load Balancing, Amazon RDS, Amazon DynamoDB, Amazon Kinesis, and Amazon Redshift, among many others.\"\n",
      "\n",
      "=== 173 ===\n",
      "chunk.text (150 tokens):\n",
      "'With VMware Cloud on AWS, organizations can simplify their Hybrid IT operations by using the Same VMware Cloud Foundation technologies including vSpnere, vSAN, NSX, and vCenter Server across their on-premises data centers and on the AWS Cloud without having to purchase any new or custom hardware, rewrite applications, or modify their operating models. The service automatically provisions intrastructure and provides Tull VM compatibility and workload portability between your on-premises environments and the AWS Cloud. With VMware Cloud on AWS, you can use a broad range of AWS services, including compute, databases, analytics, lol, security, mobile, deployment, application services, and more.'\n",
      "chunker.contextualize(chunk) (157 tokens):\n",
      "'VMware Cloud on AWS\\nWith VMware Cloud on AWS, organizations can simplify their Hybrid IT operations by using the Same VMware Cloud Foundation technologies including vSpnere, vSAN, NSX, and vCenter Server across their on-premises data centers and on the AWS Cloud without having to purchase any new or custom hardware, rewrite applications, or modify their operating models. The service automatically provisions intrastructure and provides Tull VM compatibility and workload portability between your on-premises environments and the AWS Cloud. With VMware Cloud on AWS, you can use a broad range of AWS services, including compute, databases, analytics, lol, security, mobile, deployment, application services, and more.'\n",
      "\n",
      "=== 174 ===\n",
      "chunk.text (273 tokens):\n",
      "'AWS Managed Services provides ongoing management of your AWS infrastructure so you can focus on your applications. By implementing best practices to maintain your infrastructure, AWS Managed Services helps to reduce your operational overhead and risk. AWS Managed Services automates common activities such as change requests, monitoring, patch management, security, and backup services, and provides Tull lifecycle services to provision, run, and support your infrastructure. Our rigor and controls help to enforce your corporate and security infrastructure policies, and enables you to develop solutions and applications using your preferred development approach. AWS Managed Services improves agility, reduces cost, and unburdens you trom infrastructure operations so that you can direct resources toward ditferentiating your business.\\nAWS re:Post Private is a private version of AWS re:Post for enterprises with Enterprise Support or Enterprise On-Ramp Support plans. It provides access to knowledge and experts to accelerate cloud adoption and increase developer productivity. With your organizationspecific re:Post Private, you can build an organization-specific developer community that drives efficiencies at scale and provides access to valuable knowledge resources. re:Post Private centralizes trusted AWS technical content and offers private discussion forums to improve now your teams collaborate internally and with AWS to remove technical obstacles, accelerate innovation, and scale more efficiently in the cloud.'\n",
      "chunker.contextualize(chunk) (277 tokens):\n",
      "'AWS Managed Services\\nAWS Managed Services provides ongoing management of your AWS infrastructure so you can focus on your applications. By implementing best practices to maintain your infrastructure, AWS Managed Services helps to reduce your operational overhead and risk. AWS Managed Services automates common activities such as change requests, monitoring, patch management, security, and backup services, and provides Tull lifecycle services to provision, run, and support your infrastructure. Our rigor and controls help to enforce your corporate and security infrastructure policies, and enables you to develop solutions and applications using your preferred development approach. AWS Managed Services improves agility, reduces cost, and unburdens you trom infrastructure operations so that you can direct resources toward ditferentiating your business.\\nAWS re:Post Private is a private version of AWS re:Post for enterprises with Enterprise Support or Enterprise On-Ramp Support plans. It provides access to knowledge and experts to accelerate cloud adoption and increase developer productivity. With your organizationspecific re:Post Private, you can build an organization-specific developer community that drives efficiencies at scale and provides access to valuable knowledge resources. re:Post Private centralizes trusted AWS technical content and offers private discussion forums to improve now your teams collaborate internally and with AWS to remove technical obstacles, accelerate innovation, and scale more efficiently in the cloud.'\n",
      "\n",
      "=== 175 ===\n",
      "chunk.text (121 tokens):\n",
      "\"AWS offers services that give you a secure place to store and manage your container images, orchestration that manages when and where your containers run, and flexible compute engines to\\nCustomer enablement\\npower your containers. AWS can help manage your containers and their deployments for you, so you don't have to worry about the underlying infrastructure.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS container service or Amazon Lightsail, AWS Elastic Beanstalk, or Amazon EC2?. For general information, see Containers on AWS.\"\n",
      "chunker.contextualize(chunk) (122 tokens):\n",
      "\"Containers\\nAWS offers services that give you a secure place to store and manage your container images, orchestration that manages when and where your containers run, and flexible compute engines to\\nCustomer enablement\\npower your containers. AWS can help manage your containers and their deployments for you, so you don't have to worry about the underlying infrastructure.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS container service or Amazon Lightsail, AWS Elastic Beanstalk, or Amazon EC2?. For general information, see Containers on AWS.\"\n",
      "\n",
      "=== 176 ===\n",
      "chunk.text (31 tokens):\n",
      "'Amazon Elastic Container Registry\\nAmazon Elastic Container Service\\nAmazon Elastic Kubernetes Service\\nAWS App2Container\\nRed Hat OpenSnitt Service on AWS'\n",
      "chunker.contextualize(chunk) (32 tokens):\n",
      "'Services\\nAmazon Elastic Container Registry\\nAmazon Elastic Container Service\\nAmazon Elastic Kubernetes Service\\nAWS App2Container\\nRed Hat OpenSnitt Service on AWS'\n",
      "\n",
      "=== 177 ===\n",
      "chunk.text (170 tokens):\n",
      "'Amazon Elastic Container Registry (Amazon ECR) is a fully managed Docker container registry that makes it easy Tor developers to store, manage, and deploy Docker container images. Amazon ECR is integrated with Amazon Elastic Container Service (Amazon ECS), simplifying your development to\\nproduction workflow. Amazon ECR eliminates the need to operate your own container repositories or worry about scaling the underlying infrastructure. Amazon ECR hosts your images in a highly available and scalable architecture, allowing you to reliably deploy containers for your applications. Integration with AWS Identity and Access Management (IAM) provides resource-level control of each repository. With Amazon ECR, there are no upfront fees or commitments. You pay only for the amount of data you store in your repositories and data transferred to the internet.'\n",
      "chunker.contextualize(chunk) (174 tokens):\n",
      "'Amazon Elastic Container Registry\\nAmazon Elastic Container Registry (Amazon ECR) is a fully managed Docker container registry that makes it easy Tor developers to store, manage, and deploy Docker container images. Amazon ECR is integrated with Amazon Elastic Container Service (Amazon ECS), simplifying your development to\\nproduction workflow. Amazon ECR eliminates the need to operate your own container repositories or worry about scaling the underlying infrastructure. Amazon ECR hosts your images in a highly available and scalable architecture, allowing you to reliably deploy containers for your applications. Integration with AWS Identity and Access Management (IAM) provides resource-level control of each repository. With Amazon ECR, there are no upfront fees or commitments. You pay only for the amount of data you store in your repositories and data transferred to the internet.'\n",
      "\n",
      "=== 178 ===\n",
      "chunk.text (149 tokens):\n",
      "'Amazon Elastic Container Service (Amazon ECS) is a highly scalable, high-performance container orchestration service that supports Docker containers and allows you to easily run and scale containerized applications on AWS. Amazon ECS eliminates the need for you to install and operate your own container orchestration software, manage and scale a cluster of virtual machines (VMs), or schedule containers on those VMs.\\nWith simple API calls, you can launch and stop Docker-enabled applications, query the complete State of your application, and access many familiar features such as IAM roles, security groups, load pbalancers, Amazon CloudWatcnh Events, AWS CloudFormation templates, and AWS CloudtTrail logs.'\n",
      "chunker.contextualize(chunk) (153 tokens):\n",
      "'Amazon Elastic Container Service\\nAmazon Elastic Container Service (Amazon ECS) is a highly scalable, high-performance container orchestration service that supports Docker containers and allows you to easily run and scale containerized applications on AWS. Amazon ECS eliminates the need for you to install and operate your own container orchestration software, manage and scale a cluster of virtual machines (VMs), or schedule containers on those VMs.\\nWith simple API calls, you can launch and stop Docker-enabled applications, query the complete State of your application, and access many familiar features such as IAM roles, security groups, load pbalancers, Amazon CloudWatcnh Events, AWS CloudFormation templates, and AWS CloudtTrail logs.'\n",
      "\n",
      "=== 179 ===\n",
      "chunk.text (116 tokens):\n",
      "'Amazon Elastic Kubernetes Service (Amazon EKS) makes it easy to deploy, manage, and scale containerized applications using Kubernetes on AWS.\\nAmazon EKS runs the Kubernetes management infrastructure for you across multiple AWS Availability Zones to eliminate a single point of failure. Amazon EKS is certified Kubernetes contormant so you can use existing tooling and plugins from partners and the Kubernetes community. Applications running on any standard Kubernetes environment are fully compatible and can be easily migrated to Amazon EKS.'\n",
      "chunker.contextualize(chunk) (123 tokens):\n",
      "'Amazon Elastic Kubernetes Service\\nAmazon Elastic Kubernetes Service (Amazon EKS) makes it easy to deploy, manage, and scale containerized applications using Kubernetes on AWS.\\nAmazon EKS runs the Kubernetes management infrastructure for you across multiple AWS Availability Zones to eliminate a single point of failure. Amazon EKS is certified Kubernetes contormant so you can use existing tooling and plugins from partners and the Kubernetes community. Applications running on any standard Kubernetes environment are fully compatible and can be easily migrated to Amazon EKS.'\n",
      "\n",
      "=== 180 ===\n",
      "chunk.text (164 tokens):\n",
      "'AWS App2Container (A2C) is a commanac-tine tool for modernizing .NET and Java applications into containerized applications. A2C analyzes and builds an inventory of all applications running in VMs, on-premises or in the cloud. You simply select the application you want to containerize, and A2C packages the application artifact and identifned dependencies into container images, configures the network ports, and generates the ECS task and Kubernetes pod definitions. A2C provisions, through AWS CloudFormation, the cloud infrastructure and CI/CD pipelines required to deploy the\\ncontainerized .NET or Java application into production. With A2C, you can easily modernize your existing applications and standardize the deployment and operations through containers.'\n",
      "chunker.contextualize(chunk) (171 tokens):\n",
      "'AWS App2Container\\nAWS App2Container (A2C) is a commanac-tine tool for modernizing .NET and Java applications into containerized applications. A2C analyzes and builds an inventory of all applications running in VMs, on-premises or in the cloud. You simply select the application you want to containerize, and A2C packages the application artifact and identifned dependencies into container images, configures the network ports, and generates the ECS task and Kubernetes pod definitions. A2C provisions, through AWS CloudFormation, the cloud infrastructure and CI/CD pipelines required to deploy the\\ncontainerized .NET or Java application into production. With A2C, you can easily modernize your existing applications and standardize the deployment and operations through containers.'\n",
      "\n",
      "=== 181 ===\n",
      "chunk.text (187 tokens):\n",
      "'Red Hat OpenShift Service on AWS (ROSA) provides an integrated experience to use OpenSnift. It you are already familiar with OpenShift, you can accelerate your application development process py leveraging familiar OpenShitt APIs and tools for deployments on AWS. With ROSA, you can use the wide range of AWS compute, database, analytics, machine learning (ML), networking, mobile, and other services to build secure and scalable applications faster. ROSA comes with pay-as-you-go nourly and annual billing, a 99.95% SLA, and joint support from AWS and Red Hat.\\nROSA makes it easier Tor you to focus on deploying applications and accelerating innovation by moving the cluster lifecycle management to Red Hat and AWS. With ROSA, you can run containerized applications with your existing OpenShitt workflows and reduce the complexity of management.'\n",
      "chunker.contextualize(chunk) (197 tokens):\n",
      "'Red Hat OpenSnhift Service on AWS\\nRed Hat OpenShift Service on AWS (ROSA) provides an integrated experience to use OpenSnift. It you are already familiar with OpenShift, you can accelerate your application development process py leveraging familiar OpenShitt APIs and tools for deployments on AWS. With ROSA, you can use the wide range of AWS compute, database, analytics, machine learning (ML), networking, mobile, and other services to build secure and scalable applications faster. ROSA comes with pay-as-you-go nourly and annual billing, a 99.95% SLA, and joint support from AWS and Red Hat.\\nROSA makes it easier Tor you to focus on deploying applications and accelerating innovation by moving the cluster lifecycle management to Red Hat and AWS. With ROSA, you can run containerized applications with your existing OpenShitt workflows and reduce the complexity of management.'\n",
      "\n",
      "=== 182 ===\n",
      "chunk.text (78 tokens):\n",
      "'AWS databases offer a high-performance, secure, and reliable foundation to power generative Al solutions and data-driven applications that drive value for your business and customers.\\nEacn service is described after the diagram. To help you decide wnicn service best meets your needs, see Choosing an AWS database service. For general information, see AWS Cloud Databases.\\nNatabases'\n",
      "chunker.contextualize(chunk) (79 tokens):\n",
      "'Databases\\nAWS databases offer a high-performance, secure, and reliable foundation to power generative Al solutions and data-driven applications that drive value for your business and customers.\\nEacn service is described after the diagram. To help you decide wnicn service best meets your needs, see Choosing an AWS database service. For general information, see AWS Cloud Databases.\\nNatabases'\n",
      "\n",
      "=== 183 ===\n",
      "chunk.text (484 tokens):\n",
      "'Relational, Use cases = Traditional applications,  enterprise resource planning  (ERP), customer relations  hip management (CRM), e- commerce. Relational, AWS services = • Amazon Aurora  -  Designed for unparalle  led high performance  and availability at global  scale with full MySQL and  PostgreSQL compatibility • Amazon RDS  - Set up,  operate, and scale a  relational database in the  cloud with just a few clicks • Amazon Redshift  -  Accelerate your time to  insights with fast, easy,  and secure cloud data. Key-value, Use cases = High-traffic web applications,  e-commerce systems, gaming  applications. Key-value, AWS services = • Amazon DynamoDB - Fast, flexible NoSQL  database service for single- digit millisecond performan  ce at any scale. In-memory, Use cases = Caching, session managemen  t, gaming leaderboards,  geospatial applications. In-memory, AWS services = • Amazon ElastiCache  -  Unlock microsecond latency  and scale with in-memory  caching • Amazon MemoryDB  -  Redis-compatible, durable,  in-memory database  service for ultra-fast\\nDocument, Use cases = Content management,  catalogs, user profiles. Document, AWS services = • Amazon DocumentDB  (with MongoDB compatibi  lity)  - Scale JSON  workloads with ease using  a fully managed document  database service. Wide column, Use cases = High-scale industrial apps  for equipment maintenance,  fleet management, and route  optimization. Wide column, AWS services = • Amazon Keyspaces  - A  scalable, highly available  , and managed Apache  Cassandra-compatible  database service. Graph, Use cases = Fraud detection, social  networking, recommendation  engines. Graph, AWS services = • Amazon Neptune  - Build  and run graph applicati  ons with highly connected  datasets. Time series, Use cases = Internet of Things (IoT)  applications, DevOps,  industrial telemetry. Time series, AWS services = • Amazon Timestream  -  Fast, scalable, serverless  time series database. Ledger, Use cases = Systems of record, supply  chain, registrations, banking  transactions. Ledger, AWS services = • Amazon Ledger Database  Service (QLDB)  - Maintain  an immutable, cryptogra  phically verifiable log of  data changes'\n",
      "chunker.contextualize(chunk) (489 tokens):\n",
      "'Compare AWS database services\\nRelational, Use cases = Traditional applications,  enterprise resource planning  (ERP), customer relations  hip management (CRM), e- commerce. Relational, AWS services = • Amazon Aurora  -  Designed for unparalle  led high performance  and availability at global  scale with full MySQL and  PostgreSQL compatibility • Amazon RDS  - Set up,  operate, and scale a  relational database in the  cloud with just a few clicks • Amazon Redshift  -  Accelerate your time to  insights with fast, easy,  and secure cloud data. Key-value, Use cases = High-traffic web applications,  e-commerce systems, gaming  applications. Key-value, AWS services = • Amazon DynamoDB - Fast, flexible NoSQL  database service for single- digit millisecond performan  ce at any scale. In-memory, Use cases = Caching, session managemen  t, gaming leaderboards,  geospatial applications. In-memory, AWS services = • Amazon ElastiCache  -  Unlock microsecond latency  and scale with in-memory  caching • Amazon MemoryDB  -  Redis-compatible, durable,  in-memory database  service for ultra-fast\\nDocument, Use cases = Content management,  catalogs, user profiles. Document, AWS services = • Amazon DocumentDB  (with MongoDB compatibi  lity)  - Scale JSON  workloads with ease using  a fully managed document  database service. Wide column, Use cases = High-scale industrial apps  for equipment maintenance,  fleet management, and route  optimization. Wide column, AWS services = • Amazon Keyspaces  - A  scalable, highly available  , and managed Apache  Cassandra-compatible  database service. Graph, Use cases = Fraud detection, social  networking, recommendation  engines. Graph, AWS services = • Amazon Neptune  - Build  and run graph applicati  ons with highly connected  datasets. Time series, Use cases = Internet of Things (IoT)  applications, DevOps,  industrial telemetry. Time series, AWS services = • Amazon Timestream  -  Fast, scalable, serverless  time series database. Ledger, Use cases = Systems of record, supply  chain, registrations, banking  transactions. Ledger, AWS services = • Amazon Ledger Database  Service (QLDB)  - Maintain  an immutable, cryptogra  phically verifiable log of  data changes'\n",
      "\n",
      "=== 184 ===\n",
      "chunk.text (372 tokens):\n",
      "'Amazon Aurora is a MySQL and PostgreSQL compatible relational database engine that combines the speed and availability of high-end commercial databases with the simplicity and costeffectiveness of open source databases.\\nAmazon Aurora is up to five times faster than standard MySQL databases and three times faster than standard PostgreSQL databases. It provides the security, availability, and reliability of\\ncommercial databases at 110\" the cost. Amazon Aurora is fully managed by Amazon Relational Database Service (Amazon RDS), which automates time-consuming administration tasks such as nardware provisioning, database setup, patching, and backups.\\nAmazon Aurora features a distributed, fault-tolerant, self-healing storage system that auto-scales up to 128TB per database instance. It delivers high performance and availability with up to 15 lowtatency read replicas, point-in-time recovery, continuous Dackup to Amazon S3, and replication across three Availability Zones (AZs).\\nAmazon Aurora |I/O-Optimized is a cluster configuration that offers improved price performance and predictable pricing for customers with |/O-intensive applications, such as e-commerce applications, payment processing systems, and financial applications. Aurora-Optimized offers improved performance, increasing throughput and reducing latency to support your most demanding workloads, with up to 40 percent cost savings when your I/O spend exceeds 25 percent of your current Aurora database spend.\\nAmazon Aurora MySQL zero-ETL integration with Amazon Redshift, now available in public preview, enables near real-time analytics and machine learning of data stored in Aurora MySQLCompatible Edition. Transactional data written to Aurora is available to you in Amazon Redshift within seconds, without building and maintaining complex data pipelines.'\n",
      "chunker.contextualize(chunk) (374 tokens):\n",
      "'Amazon Aurora\\nAmazon Aurora is a MySQL and PostgreSQL compatible relational database engine that combines the speed and availability of high-end commercial databases with the simplicity and costeffectiveness of open source databases.\\nAmazon Aurora is up to five times faster than standard MySQL databases and three times faster than standard PostgreSQL databases. It provides the security, availability, and reliability of\\ncommercial databases at 110\" the cost. Amazon Aurora is fully managed by Amazon Relational Database Service (Amazon RDS), which automates time-consuming administration tasks such as nardware provisioning, database setup, patching, and backups.\\nAmazon Aurora features a distributed, fault-tolerant, self-healing storage system that auto-scales up to 128TB per database instance. It delivers high performance and availability with up to 15 lowtatency read replicas, point-in-time recovery, continuous Dackup to Amazon S3, and replication across three Availability Zones (AZs).\\nAmazon Aurora |I/O-Optimized is a cluster configuration that offers improved price performance and predictable pricing for customers with |/O-intensive applications, such as e-commerce applications, payment processing systems, and financial applications. Aurora-Optimized offers improved performance, increasing throughput and reducing latency to support your most demanding workloads, with up to 40 percent cost savings when your I/O spend exceeds 25 percent of your current Aurora database spend.\\nAmazon Aurora MySQL zero-ETL integration with Amazon Redshift, now available in public preview, enables near real-time analytics and machine learning of data stored in Aurora MySQLCompatible Edition. Transactional data written to Aurora is available to you in Amazon Redshift within seconds, without building and maintaining complex data pipelines.'\n",
      "\n",
      "=== 185 ===\n",
      "chunk.text (208 tokens):\n",
      "\"Amazon DynamoDB Is a key-value and document database that delivers single-digit millisecond performance at any scale. It's a fully managed, multi-Region database with built-in security, backup and restore, and in-memory caching for internet-scale applications. DynamoDB can handle more than 10 trillion requests per day and support peaks of more than 20 million requests per second.\\nMany of the world's fastest growing businesses such as Lyft, Airbnb, and Redfin, as well as enterprises such as Samsung, Toyota, and Capital One, depend on the scale and performance of DynamoDB to support their mission-critical workloads.\\nHundreds of thousands of AWS customers have chosen DynamoDB as their key-value and document database for mobile, web, gaming, ad tech, Internet of Things (loT), and other applications that need low-latency data access at any scale. Create a new table for your application and tet DynamoDB handle the rest.\\nAmazon DynamovDB\"\n",
      "chunker.contextualize(chunk) (211 tokens):\n",
      "\"Amazon DynamoDB\\nAmazon DynamoDB Is a key-value and document database that delivers single-digit millisecond performance at any scale. It's a fully managed, multi-Region database with built-in security, backup and restore, and in-memory caching for internet-scale applications. DynamoDB can handle more than 10 trillion requests per day and support peaks of more than 20 million requests per second.\\nMany of the world's fastest growing businesses such as Lyft, Airbnb, and Redfin, as well as enterprises such as Samsung, Toyota, and Capital One, depend on the scale and performance of DynamoDB to support their mission-critical workloads.\\nHundreds of thousands of AWS customers have chosen DynamoDB as their key-value and document database for mobile, web, gaming, ad tech, Internet of Things (loT), and other applications that need low-latency data access at any scale. Create a new table for your application and tet DynamoDB handle the rest.\\nAmazon DynamovDB\"\n",
      "\n",
      "=== 186 ===\n",
      "chunk.text (427 tokens):\n",
      "'Amazon ElastiCache Is a web service that makes it easy to deploy, operate, and scale an in-memory cache in the cloud. The service improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying entirely on slower disk-based databases.\\nFlastiCache supports two open-source in-memory caching engines:\\ne Redis — a fast, open-source, in-memory key-value data store for use as a database, cache, message broker, and queue. Amazon ElastiCache (Redis OSS) is a Redis-compatible in-memory service that delivers the ease-of-use and power of Redis along with the availability, reliability, and performance suitable for the most demanding applications. Both single-node and up to 15Snard clusters are available, enabling scalability to up to 5.55 TiB of in-memory data. Amazon ElastiCache (Redis OSS) is Tully managed, scalable, and secure. This makes it an ideal candidate to power high-performance use cases such as web, mobile apps, gaming, ad-tech, and loT.\\ne Memcached — a widely adopted memory object caching system. Amazon ElastiCacne (Memcached) is protocol compliant with Memcached, so popular tools that you use today with existing Memcached environments will work seamlessly with the service.\\nAmazon ElastiCache Serverless is a serverless option for Amazon ElastiCache that simplifies cache management and Instantly scales to support the most demanding applications. With EtastiCacne Serverless, you can create a highly available and scalable cache in less than a minute, eliminating the need to plan for, provision, and manage cache cluster capacity. ElastiCache Serverless automatically stores data redundantly across multiple Availability Zones (AZs) and provides a 99.99% availability Service Level Agreement (SLA). With ElastiCache Serverless, you pay for data stored and compute consumed by your workload, with no upfront commitments or qadaitional costs.'\n",
      "chunker.contextualize(chunk) (430 tokens):\n",
      "'Amazon ElastiCache\\nAmazon ElastiCache Is a web service that makes it easy to deploy, operate, and scale an in-memory cache in the cloud. The service improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying entirely on slower disk-based databases.\\nFlastiCache supports two open-source in-memory caching engines:\\ne Redis — a fast, open-source, in-memory key-value data store for use as a database, cache, message broker, and queue. Amazon ElastiCache (Redis OSS) is a Redis-compatible in-memory service that delivers the ease-of-use and power of Redis along with the availability, reliability, and performance suitable for the most demanding applications. Both single-node and up to 15Snard clusters are available, enabling scalability to up to 5.55 TiB of in-memory data. Amazon ElastiCache (Redis OSS) is Tully managed, scalable, and secure. This makes it an ideal candidate to power high-performance use cases such as web, mobile apps, gaming, ad-tech, and loT.\\ne Memcached — a widely adopted memory object caching system. Amazon ElastiCacne (Memcached) is protocol compliant with Memcached, so popular tools that you use today with existing Memcached environments will work seamlessly with the service.\\nAmazon ElastiCache Serverless is a serverless option for Amazon ElastiCache that simplifies cache management and Instantly scales to support the most demanding applications. With EtastiCacne Serverless, you can create a highly available and scalable cache in less than a minute, eliminating the need to plan for, provision, and manage cache cluster capacity. ElastiCache Serverless automatically stores data redundantly across multiple Availability Zones (AZs) and provides a 99.99% availability Service Level Agreement (SLA). With ElastiCache Serverless, you pay for data stored and compute consumed by your workload, with no upfront commitments or qadaitional costs.'\n",
      "\n",
      "=== 187 ===\n",
      "chunk.text (203 tokens):\n",
      "\"Amazon Keyspaces (for Apache Cassandra) Is a scalable, highly available, and managed Apache Cassandra—compatible database service. With Amazon Keyspaces, you can run your Cassandra workloads on AWS using the same Cassandra application code and developer tools that you use today. You don't Nave to provision, patch, or manage servers, and you don't have to install, maintain, or operate software. Amazon Keyspaces is serverless, SO you pay Tor only the resources you use and the service can automatically scale tables up and down in response to application\\nAmazon ElastiCache\\ntraffic. You can build applications that serve thousands of requests per second with virtually unlimited throughput and storage. Data is encrypted by default and Amazon Keyspaces enables you to back up your table data continuously using point-in-time recovery. Amazon Keyspaces gives you the performance, elasticity, and enterprise features you need to operate business-critical Cassanara workloaas at scale.\"\n",
      "chunker.contextualize(chunk) (212 tokens):\n",
      "\"Amazon Keyspaces (for Apache Cassandra)\\nAmazon Keyspaces (for Apache Cassandra) Is a scalable, highly available, and managed Apache Cassandra—compatible database service. With Amazon Keyspaces, you can run your Cassandra workloads on AWS using the same Cassandra application code and developer tools that you use today. You don't Nave to provision, patch, or manage servers, and you don't have to install, maintain, or operate software. Amazon Keyspaces is serverless, SO you pay Tor only the resources you use and the service can automatically scale tables up and down in response to application\\nAmazon ElastiCache\\ntraffic. You can build applications that serve thousands of requests per second with virtually unlimited throughput and storage. Data is encrypted by default and Amazon Keyspaces enables you to back up your table data continuously using point-in-time recovery. Amazon Keyspaces gives you the performance, elasticity, and enterprise features you need to operate business-critical Cassanara workloaas at scale.\"\n",
      "\n",
      "=== 188 ===\n",
      "chunk.text (199 tokens):\n",
      "'Amazon MemoryDB is a Redis-compatible, durable, in-memory database service that delivers ultrafast performance. It is purpose-built Tor modern applications with microservices architectures.\\nMemoryDB is compatible with Redis, a popular open source data store, enabling customers to quickly build applications using the same flexible and friendly Redis data structures, APIs, and commands that they already use today. With MemoryDB, all of your data is stored in memory, which enables you to achieve microsecond read and single-digit millisecond write latency and high throughput. MemoryDB also stores data durably across multiple Availability Zones using a distributed transactional log to allow fast failover, database recovery, and node restarts. Delivering both in-memory performance and Multi-AZ durability, MemoryDB can be used as a high-performance primary database for your microservices applications eliminating the need to separately manage both a cache and durable database.'\n",
      "chunker.contextualize(chunk) (202 tokens):\n",
      "'Amazon MemoryDB\\nAmazon MemoryDB is a Redis-compatible, durable, in-memory database service that delivers ultrafast performance. It is purpose-built Tor modern applications with microservices architectures.\\nMemoryDB is compatible with Redis, a popular open source data store, enabling customers to quickly build applications using the same flexible and friendly Redis data structures, APIs, and commands that they already use today. With MemoryDB, all of your data is stored in memory, which enables you to achieve microsecond read and single-digit millisecond write latency and high throughput. MemoryDB also stores data durably across multiple Availability Zones using a distributed transactional log to allow fast failover, database recovery, and node restarts. Delivering both in-memory performance and Multi-AZ durability, MemoryDB can be used as a high-performance primary database for your microservices applications eliminating the need to separately manage both a cache and durable database.'\n",
      "\n",
      "=== 189 ===\n",
      "chunk.text (294 tokens):\n",
      "\"Amazon Neptune is a fast, reliable, fully managed graph database service that makes it easy to build and run applications that work with highly connected datasets. The core of Amazon Neptune is a purpose-built, high-performance graph database engine optimized for storing billions of relationsnips and querying the graph with milliseconds latency. Amazon Neptune supports popular graph models Property Graph and W3C's RDF, and their respective query languages Apache TinkerPop Gremlin and SPARQL, allowing you to easily build queries that efficiently navigate highly connected datasets. Neptune powers graph use cases such as recommendation engines, fraud detection, Knowledge graphs, drug discovery, and network security.\\nAmazon Neptune is highly available, with read replicas, point-in-time recovery, continuous backup to Amazon S3, and replication across Availability Zones. Neptune is secure with support Tor encryption at rest. Neptune is Tully managed, so you no longer need to worry about database management tasks such as Nardware provisioning, software patching, setup, configuration, or DaCcKups.\\nAmazon MemoryDB\\nAmazon Neptune Analytics is an analytics database engine for quickly analyzing large volumes of graph data to get insights and find trends from data stored in Amazon S3 buckets or a Neptune database. Neptune Analytics uses built-in algorithms, vector search, and in-memory computing to run queries on data with tens of billions of relationships in seconds.\"\n",
      "chunker.contextualize(chunk) (296 tokens):\n",
      "\"Amazon Neptune\\nAmazon Neptune is a fast, reliable, fully managed graph database service that makes it easy to build and run applications that work with highly connected datasets. The core of Amazon Neptune is a purpose-built, high-performance graph database engine optimized for storing billions of relationsnips and querying the graph with milliseconds latency. Amazon Neptune supports popular graph models Property Graph and W3C's RDF, and their respective query languages Apache TinkerPop Gremlin and SPARQL, allowing you to easily build queries that efficiently navigate highly connected datasets. Neptune powers graph use cases such as recommendation engines, fraud detection, Knowledge graphs, drug discovery, and network security.\\nAmazon Neptune is highly available, with read replicas, point-in-time recovery, continuous backup to Amazon S3, and replication across Availability Zones. Neptune is secure with support Tor encryption at rest. Neptune is Tully managed, so you no longer need to worry about database management tasks such as Nardware provisioning, software patching, setup, configuration, or DaCcKups.\\nAmazon MemoryDB\\nAmazon Neptune Analytics is an analytics database engine for quickly analyzing large volumes of graph data to get insights and find trends from data stored in Amazon S3 buckets or a Neptune database. Neptune Analytics uses built-in algorithms, vector search, and in-memory computing to run queries on data with tens of billions of relationships in seconds.\"\n",
      "\n",
      "=== 190 ===\n",
      "chunk.text (177 tokens):\n",
      "'Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups. It frees you to focus On your applications so you can give them the fast performance, high availability, security and compatibility they need.\\nAmazon RDS is available on several database instance types—optimized for memory, performance or |/O—and provides you with six familiar database engines to choose from, including MySQL, MariaDB, PostgreSQL, Oracle Database, Microsoft SQL Server, and Amazon RDS on AWS Outposts. You can use the AWS Database Migration Service to easily migrate or replicate your existing databases to Amazon RDS.'\n",
      "chunker.contextualize(chunk) (181 tokens):\n",
      "'Amazon Relational Database Service\\nAmazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups. It frees you to focus On your applications so you can give them the fast performance, high availability, security and compatibility they need.\\nAmazon RDS is available on several database instance types—optimized for memory, performance or |/O—and provides you with six familiar database engines to choose from, including MySQL, MariaDB, PostgreSQL, Oracle Database, Microsoft SQL Server, and Amazon RDS on AWS Outposts. You can use the AWS Database Migration Service to easily migrate or replicate your existing databases to Amazon RDS.'\n",
      "\n",
      "=== 191 ===\n",
      "chunk.text (126 tokens):\n",
      "'Amazon RDS Tor Db2 makes it easy to set up, operate, and scale Db2 deployments in the cloud. Amazon RDS automates time-consuming database administration tasks, such as provisioning, backups, software patching, monitoring, and more, to free up time to innovate and drive business value. It also offers high availability with Multi-AZ deployment, disaster recovery solutions with cross-Region backups, and security features to support your business-critical workloads. In addition, you can integrate with other IBM and AWS services to gain new insights and scale your analytics workloads.'\n",
      "chunker.contextualize(chunk) (132 tokens):\n",
      "'Amazon RDS for Db2\\nAmazon RDS Tor Db2 makes it easy to set up, operate, and scale Db2 deployments in the cloud. Amazon RDS automates time-consuming database administration tasks, such as provisioning, backups, software patching, monitoring, and more, to free up time to innovate and drive business value. It also offers high availability with Multi-AZ deployment, disaster recovery solutions with cross-Region backups, and security features to support your business-critical workloads. In addition, you can integrate with other IBM and AWS services to gain new insights and scale your analytics workloads.'\n",
      "\n",
      "=== 192 ===\n",
      "chunk.text (232 tokens):\n",
      "'Amazon Relational Database Service (Amazon RDS) on VMware lets you deploy managed databases in on-premises VMware environments using the Amazon RDS technology enjoyed by nundreds of thousands of AWS customers. Amazon RDS provides cost-etncient and resizable Capacity while automating time-consuming administration tasks including Nardware provisioning, database setup, patching, and backups, Treeing you to focus on your applications. Amazon RDS on VMware brings these same benefits to your on-premises deployments, making it easy to set up, operate, and scale databases in VMware vSpnere private data centers, or to migrate them to AWS.\\nAmazon RDS on VMware allows you to utilize the same simple interface for managing databases in on-premises VMware environments as you would use in AWS. You can easily replicate Amazon RDS on VMware databases to Amazon RDS instances in AWS, enabling low-cost hybrid deployments for disaster recovery, read replica bursting, and optional long-term backup retention in Amazon Simple Storage Service (Amazon S3).'\n",
      "chunker.contextualize(chunk) (239 tokens):\n",
      "'Amazon RDS on VMware\\nAmazon Relational Database Service (Amazon RDS) on VMware lets you deploy managed databases in on-premises VMware environments using the Amazon RDS technology enjoyed by nundreds of thousands of AWS customers. Amazon RDS provides cost-etncient and resizable Capacity while automating time-consuming administration tasks including Nardware provisioning, database setup, patching, and backups, Treeing you to focus on your applications. Amazon RDS on VMware brings these same benefits to your on-premises deployments, making it easy to set up, operate, and scale databases in VMware vSpnere private data centers, or to migrate them to AWS.\\nAmazon RDS on VMware allows you to utilize the same simple interface for managing databases in on-premises VMware environments as you would use in AWS. You can easily replicate Amazon RDS on VMware databases to Amazon RDS instances in AWS, enabling low-cost hybrid deployments for disaster recovery, read replica bursting, and optional long-term backup retention in Amazon Simple Storage Service (Amazon S3).'\n",
      "\n",
      "=== 193 ===\n",
      "chunk.text (483 tokens):\n",
      "\"Amazon QLDB Is a fully managed ledger database that provides a transparent, immutable, and cryptograpnically verifiable transaction log owned by a central trusted authority. Amazon QLDB tracks each and every application data change and maintains a complete and verifiable history of changes over time.\\nLedgers are typically used to record a history of economic and financial activity in an organization. Many organizations build applications with ledger-like functionality because they want to maintain an accurate history of their applications' data, for example, tracking the history of credits and debits in banking transactions, verifying the data lineage of an insurance claim, or tracing movement of an item in a supply chain network. Ledger applications are often implemented using custom audit tables or audit trails created in relational databases. However, building audit functionality with relational databases is time-consuming and prone to human error. It requires custom development, and since relational databases are not inherently immutable, any unintended changes to the data are hard to track and verity. Alternatively, blockchain frameworks, such as Hyperledger Fabric and Ethereum, can also be used as a ledger. However, this adds complexity as you need to set-up an entire blockchain network with multiple nodes, manage its infrastructure, and require the nodes to validate each transaction before it can be added to the ledger.\\nAmazon QLDB Is a new class of database that eliminates the need to engage in the complex development effort of building your own ledger-like applications. With QLDB, your data's change nistory is immutable — it cannot be altered or deleted — and using cryptography, you can easily verify that there have been no unintended modifications to your application's data. QLDB uses an immutable transactional log, Known as a journal, that tracks eacn application data change and maintains a complete and verifiable history of changes over time. QLDB is easy to use because it provides developers with a familiar SQL-like API, a flexible document data model, and full support for transactions. QLDB Is also serverless, so it automatically scales to support the demands of your application. There are no servers to manage and no read or write limits to configure. With QLDB, you only pay for what you use.\"\n",
      "chunker.contextualize(chunk) (493 tokens):\n",
      "\"Amazon Quantum Ledger Database (Amazon QLDB)\\nAmazon QLDB Is a fully managed ledger database that provides a transparent, immutable, and cryptograpnically verifiable transaction log owned by a central trusted authority. Amazon QLDB tracks each and every application data change and maintains a complete and verifiable history of changes over time.\\nLedgers are typically used to record a history of economic and financial activity in an organization. Many organizations build applications with ledger-like functionality because they want to maintain an accurate history of their applications' data, for example, tracking the history of credits and debits in banking transactions, verifying the data lineage of an insurance claim, or tracing movement of an item in a supply chain network. Ledger applications are often implemented using custom audit tables or audit trails created in relational databases. However, building audit functionality with relational databases is time-consuming and prone to human error. It requires custom development, and since relational databases are not inherently immutable, any unintended changes to the data are hard to track and verity. Alternatively, blockchain frameworks, such as Hyperledger Fabric and Ethereum, can also be used as a ledger. However, this adds complexity as you need to set-up an entire blockchain network with multiple nodes, manage its infrastructure, and require the nodes to validate each transaction before it can be added to the ledger.\\nAmazon QLDB Is a new class of database that eliminates the need to engage in the complex development effort of building your own ledger-like applications. With QLDB, your data's change nistory is immutable — it cannot be altered or deleted — and using cryptography, you can easily verify that there have been no unintended modifications to your application's data. QLDB uses an immutable transactional log, Known as a journal, that tracks eacn application data change and maintains a complete and verifiable history of changes over time. QLDB is easy to use because it provides developers with a familiar SQL-like API, a flexible document data model, and full support for transactions. QLDB Is also serverless, so it automatically scales to support the demands of your application. There are no servers to manage and no read or write limits to configure. With QLDB, you only pay for what you use.\"\n",
      "\n",
      "=== 194 ===\n",
      "chunk.text (316 tokens):\n",
      "'Amazon Timestream is a fast, scalable, Tully managed time series database service for lol and operational applications that makes it easy to store and analyze trillions of events per day at 1/10th the cost of relational databases. Driven by the rise of loT devices, IT systems, and smart industrial machines, time series data — data that measures how things change over time — is one of the fastest growing data types. Time-series data has specific characteristics such as typically arriving in time order form, data is append-only, and queries are always over a time interval. While relational databases can store this data, they are inefficient at processing this data as they lack optimizations such as storing and retrieving data by time intervals.\\nTimestream is a purpose-built time series database that efficiently stores and processes this data by time intervals. With Timestream, you can easily store and analyze log data for DevOps, sensor data for lol applications, and industrial telemetry data for equipment maintenance. As your data grows over time, the Timestream adaptive query processing engine understands its location and format, making your data simpler and faster to analyze. Timestream also automates rollups, retention, tiering, and compression of data, sO you can manage your data at the lowest possible cost. Timestream is serverless, so there are no servers to manage. It manages time-consuming tasks such as server provisioning, software patching, setup, configuration, or data retention and tiering, freeing you to focus on building your applications.'\n",
      "chunker.contextualize(chunk) (319 tokens):\n",
      "'Amazon Timestream\\nAmazon Timestream is a fast, scalable, Tully managed time series database service for lol and operational applications that makes it easy to store and analyze trillions of events per day at 1/10th the cost of relational databases. Driven by the rise of loT devices, IT systems, and smart industrial machines, time series data — data that measures how things change over time — is one of the fastest growing data types. Time-series data has specific characteristics such as typically arriving in time order form, data is append-only, and queries are always over a time interval. While relational databases can store this data, they are inefficient at processing this data as they lack optimizations such as storing and retrieving data by time intervals.\\nTimestream is a purpose-built time series database that efficiently stores and processes this data by time intervals. With Timestream, you can easily store and analyze log data for DevOps, sensor data for lol applications, and industrial telemetry data for equipment maintenance. As your data grows over time, the Timestream adaptive query processing engine understands its location and format, making your data simpler and faster to analyze. Timestream also automates rollups, retention, tiering, and compression of data, sO you can manage your data at the lowest possible cost. Timestream is serverless, so there are no servers to manage. It manages time-consuming tasks such as server provisioning, software patching, setup, configuration, or data retention and tiering, freeing you to focus on building your applications.'\n",
      "\n",
      "=== 195 ===\n",
      "chunk.text (138 tokens):\n",
      "'Amazon DocumentDB (with MongoDB compatibility) is a fast, scalable, highly available, and Tully managed document database service that supports MongoDB workloads.\\nAmazon DocumentDB Is designed from the ground-up to give you the performance, scalability, and availability you need when operating mission-critical MongoDB workloads at scale. Amazon DocumentDB implements the Apache 2.0 open source MongoDB 3.6 and 4.0 APIs by emulating the responses that a MongoDB client expects from a MongoDB server, allowing you to use your existing MongoDB drivers and tools with Amazon DocumentDB (with MongoDB compatibility).'\n",
      "chunker.contextualize(chunk) (148 tokens):\n",
      "'Amazon DocumentDB (with MongoDB compatibility)\\nAmazon DocumentDB (with MongoDB compatibility) is a fast, scalable, highly available, and Tully managed document database service that supports MongoDB workloads.\\nAmazon DocumentDB Is designed from the ground-up to give you the performance, scalability, and availability you need when operating mission-critical MongoDB workloads at scale. Amazon DocumentDB implements the Apache 2.0 open source MongoDB 3.6 and 4.0 APIs by emulating the responses that a MongoDB client expects from a MongoDB server, allowing you to use your existing MongoDB drivers and tools with Amazon DocumentDB (with MongoDB compatibility).'\n",
      "\n",
      "=== 196 ===\n",
      "chunk.text (141 tokens):\n",
      "'Amazon Lightsail managed databases are separate trom compute workloads, so you can build applications and websites on Lightsail instances without interruption. Lightsail supports MySQL and PostgreSQL databases , and you can configure them for standard availability for regular workloads or high availability Tor critical workloads. Lightsail-managed databases bundle the\\nAmazon |imestream\\nunderlying compute, SSD-based storage, and data transfer bandwidth into a fixed monthly price. You can manage your Lightsail-managed database by using the Lightsail console, the AWS Command Line Interface (AWS CLI), the Lightsail API, or an AWS SDK.'\n",
      "chunker.contextualize(chunk) (146 tokens):\n",
      "'Amazon Lightsail managed databases\\nAmazon Lightsail managed databases are separate trom compute workloads, so you can build applications and websites on Lightsail instances without interruption. Lightsail supports MySQL and PostgreSQL databases , and you can configure them for standard availability for regular workloads or high availability Tor critical workloads. Lightsail-managed databases bundle the\\nAmazon |imestream\\nunderlying compute, SSD-based storage, and data transfer bandwidth into a fixed monthly price. You can manage your Lightsail-managed database by using the Lightsail console, the AWS Command Line Interface (AWS CLI), the Lightsail API, or an AWS SDK.'\n",
      "\n",
      "=== 197 ===\n",
      "chunk.text (48 tokens):\n",
      "'e AWS Intrastructure Composer\\ne Amazon CodeCatalyst\\ne AWS CodeDeploy\\n¢ AWS CodePipeline\\ne Amazon Corretto\\ne AWS Fault Injection Service\\ne Amazon Q Developer\\ne AWS X-Ray'\n",
      "chunker.contextualize(chunk) (49 tokens):\n",
      "'Topics\\ne AWS Intrastructure Composer\\ne Amazon CodeCatalyst\\ne AWS CodeDeploy\\n¢ AWS CodePipeline\\ne Amazon Corretto\\ne AWS Fault Injection Service\\ne Amazon Q Developer\\ne AWS X-Ray'\n",
      "\n",
      "=== 198 ===\n",
      "chunk.text (457 tokens):\n",
      "\"AWS Infrastructure Composer helps you visually compose and configure serverless applications from AWS services backed by deployment-ready infrastructure as code (laC). Infrastructure Composer helps you drag and drop serverless resources onto a visual, browser-based canvas. You can connect them to quickly create your serverless application architecture. The canvas also Supports grouping of resources into larger architectural components to simplify editing and configuration. AWS Infrastructure Composer can generate deployment-ready configuration with default settings based on the services that make up your application architecture. Infrastructure\\nDeveloper tools\\nComposer supports generating both AWS CloudFormation and AWS Serverless Application Model (SAM) artifacts.\\nAWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. AWS Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don't need to install files or configure your development machine to start new projects. Since your AWS Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. AWS Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote running of serverless applications. With AWS Clougd9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time.\\nAWS CloudShell is a browser-based snell that makes it easy to securely manage, explore, and interact with your AWS resources. CloudShell is pre-authenticated with your console credentials. Common development and operations tools are pre-installed, So no local installation or configuration is required. With CloudShell, you can quickly run scripts with the AWS Command Line Interface (AWS CLI), experiment with AWS service APIs using the AWS SDKs, or use a range of other tools to be productive. You can use CloudShell right from your browser and at no additional cost.\"\n",
      "chunker.contextualize(chunk) (461 tokens):\n",
      "\"AWS Infrastructure Composer\\nAWS Infrastructure Composer helps you visually compose and configure serverless applications from AWS services backed by deployment-ready infrastructure as code (laC). Infrastructure Composer helps you drag and drop serverless resources onto a visual, browser-based canvas. You can connect them to quickly create your serverless application architecture. The canvas also Supports grouping of resources into larger architectural components to simplify editing and configuration. AWS Infrastructure Composer can generate deployment-ready configuration with default settings based on the services that make up your application architecture. Infrastructure\\nDeveloper tools\\nComposer supports generating both AWS CloudFormation and AWS Serverless Application Model (SAM) artifacts.\\nAWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. AWS Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don't need to install files or configure your development machine to start new projects. Since your AWS Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. AWS Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote running of serverless applications. With AWS Clougd9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time.\\nAWS CloudShell is a browser-based snell that makes it easy to securely manage, explore, and interact with your AWS resources. CloudShell is pre-authenticated with your console credentials. Common development and operations tools are pre-installed, So no local installation or configuration is required. With CloudShell, you can quickly run scripts with the AWS Command Line Interface (AWS CLI), experiment with AWS service APIs using the AWS SDKs, or use a range of other tools to be productive. You can use CloudShell right from your browser and at no additional cost.\"\n",
      "\n",
      "=== 199 ===\n",
      "chunk.text (228 tokens):\n",
      "\"AWS CodeArtifact is a fully managed artifact repository service that makes it easy for organizations of any size to securely store, publish, and share software packages used in their software development process. CodeArtifact can be configured to automatically fetch software packages and dependencies from public artifact repositories so developers have access to the latest versions. CodeArtifact works with commonly used package managers and build tools such as Apache Maven, Gradle, npm, yarn, twine, pip, and NuGet making It easy to integrate into existing development workTlows.\\nAWS CodeBuild Is a Tully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. With CodeBuild, you don't need to provision, manage,\\nAWS Cloud9\\nand scale your own build servers. CodeBuild scales continuously and processes multiple builds concurrently, so your builds are not left waiting in a queue. You can get started quickly by using prepackaged build environments, or you can create custom build environments that use your own Duita tools.\"\n",
      "chunker.contextualize(chunk) (234 tokens):\n",
      "\"AWS CodeArtifact\\nAWS CodeArtifact is a fully managed artifact repository service that makes it easy for organizations of any size to securely store, publish, and share software packages used in their software development process. CodeArtifact can be configured to automatically fetch software packages and dependencies from public artifact repositories so developers have access to the latest versions. CodeArtifact works with commonly used package managers and build tools such as Apache Maven, Gradle, npm, yarn, twine, pip, and NuGet making It easy to integrate into existing development workTlows.\\nAWS CodeBuild Is a Tully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. With CodeBuild, you don't need to provision, manage,\\nAWS Cloud9\\nand scale your own build servers. CodeBuild scales continuously and processes multiple builds concurrently, so your builds are not left waiting in a queue. You can get started quickly by using prepackaged build environments, or you can create custom build environments that use your own Duita tools.\"\n",
      "\n",
      "=== 200 ===\n",
      "chunk.text (207 tokens):\n",
      "'Amazon CodeCatalyst is an integrated service for software development teams adopting continuous integration/continuous deployment (CI/CD) practices into their software development process. CodeCatalyst is Tully managed by AWS and puts the tools you need all in one place. You can plan work, collaborate on code, and build, test, and deploy applications. You can also integrate AWS resources with your projects by connecting your AWS accounts to your CodeCatalyst space. By managing all of the stages and aspects of your application lifecycle in one tool, you can deliver software quickly and confidently.\\nAWS CodeCommit is a fully managed source control service that makes It easy for companies to nost secure and highly scalable private Git repositories. AWS CodeCommit eliminates the need to operate your own source control system or worry about scaling its infrastructure. You can use AWS CodeCommit to securely store anything from source code to binaries, and it works seamlessly with your existing Git tools.'\n",
      "chunker.contextualize(chunk) (212 tokens):\n",
      "'Amazon CodeCatalyst\\nAmazon CodeCatalyst is an integrated service for software development teams adopting continuous integration/continuous deployment (CI/CD) practices into their software development process. CodeCatalyst is Tully managed by AWS and puts the tools you need all in one place. You can plan work, collaborate on code, and build, test, and deploy applications. You can also integrate AWS resources with your projects by connecting your AWS accounts to your CodeCatalyst space. By managing all of the stages and aspects of your application lifecycle in one tool, you can deliver software quickly and confidently.\\nAWS CodeCommit is a fully managed source control service that makes It easy for companies to nost secure and highly scalable private Git repositories. AWS CodeCommit eliminates the need to operate your own source control system or worry about scaling its infrastructure. You can use AWS CodeCommit to securely store anything from source code to binaries, and it works seamlessly with your existing Git tools.'\n",
      "\n",
      "=== 201 ===\n",
      "chunk.text (104 tokens):\n",
      "'AWS CodeDeploy is a service that automates code deployments to any instance, including EC2 instances and instances running on premises. CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications. You can use CodeDeploy to automate software deployments, eliminating the need for error-prone manual operations. The service scales with your infrastructure so you can easily deploy to one instance or thousands.'\n",
      "chunker.contextualize(chunk) (110 tokens):\n",
      "'AWS CodeDeploy\\nAWS CodeDeploy is a service that automates code deployments to any instance, including EC2 instances and instances running on premises. CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during application deployment, and handles the complexity of updating your applications. You can use CodeDeploy to automate software deployments, eliminating the need for error-prone manual operations. The service scales with your infrastructure so you can easily deploy to one instance or thousands.'\n",
      "\n",
      "=== 202 ===\n",
      "chunk.text (135 tokens):\n",
      "'AWS CodePipetine is a Tully managed continuous delivery service that helps you automate your release pipelines for Tast and reliable application and infrastructure updates. CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change, based on the release model you define. This enables you to rapidly and reliably deliver features and updates. You can easily integrate CodePipeline with third-party services such as\\nAmazon CodeCatalyst\\nGitHub or with your own custom plugin. With AWS CodePipeline, you only pay for what you use. There are no upfront fees or long-term commitments.'\n",
      "chunker.contextualize(chunk) (140 tokens):\n",
      "'AWS CodePipetine\\nAWS CodePipetine is a Tully managed continuous delivery service that helps you automate your release pipelines for Tast and reliable application and infrastructure updates. CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change, based on the release model you define. This enables you to rapidly and reliably deliver features and updates. You can easily integrate CodePipeline with third-party services such as\\nAmazon CodeCatalyst\\nGitHub or with your own custom plugin. With AWS CodePipeline, you only pay for what you use. There are no upfront fees or long-term commitments.'\n",
      "\n",
      "=== 203 ===\n",
      "chunk.text (108 tokens):\n",
      "'Amazon Corretto is a no-cost, multiplatform, production-ready distribution of the Open Java Development Kit (OQpenJDK). Corretto comes with long-term support that will include performance enhancements and security fixes. Amazon runs Corretto internally on thousands of production services, and Corretto is certified as compatible with the Java SE standard. With Corretto, you can develop and run Java applications on popular operating systems, including Amazon Linux 2, Windows, and macOS.'\n",
      "chunker.contextualize(chunk) (112 tokens):\n",
      "'Amazon Corretto\\nAmazon Corretto is a no-cost, multiplatform, production-ready distribution of the Open Java Development Kit (OQpenJDK). Corretto comes with long-term support that will include performance enhancements and security fixes. Amazon runs Corretto internally on thousands of production services, and Corretto is certified as compatible with the Java SE standard. With Corretto, you can develop and run Java applications on popular operating systems, including Amazon Linux 2, Windows, and macOS.'\n",
      "\n",
      "=== 204 ===\n",
      "chunk.text (266 tokens):\n",
      "\"AWS Fault Injection Service is a Tully managed service for running fault injection experiments on AWS that makes it easier to improve an application's performance, observability, and resiliency. Fault injection experiments are used in chaos engineering, which is the practice of stressing an application in testing or production environments by creating disruptive events, such as sudden increase in CPU or memory consumption, observing how the system responds, and implementing improvements. Fault injection experiment helps teams create the real-world conditions needed to uncover the hidden bugs, monitoring blind spots, and performance bottlenecks that are dithicult to find in distributed systems.\\nAWS Fault Injection Service simplifies the process of setting up and running controlled fault injection experiments across a range of AWS services so teams can build confidence in their application behavior. With Fault Injection Simulator, teams can quickly set up experiments using pre-built templates that generate the desired disruptions. AWS Fault Injection Service provides the controls and guardrails that teams need to run experiments in production, such as automatically rolling back or stopping the experiment if specific conditions are met. With a Tew clicks in the console, teams can run complex scenarios with common distributed system failures happening in parallel or building sequentially over time, enabling them to create the real world conditions necessary to find hidden weaknesses.\"\n",
      "chunker.contextualize(chunk) (271 tokens):\n",
      "\"AWS Fault Injection Service\\nAWS Fault Injection Service is a Tully managed service for running fault injection experiments on AWS that makes it easier to improve an application's performance, observability, and resiliency. Fault injection experiments are used in chaos engineering, which is the practice of stressing an application in testing or production environments by creating disruptive events, such as sudden increase in CPU or memory consumption, observing how the system responds, and implementing improvements. Fault injection experiment helps teams create the real-world conditions needed to uncover the hidden bugs, monitoring blind spots, and performance bottlenecks that are dithicult to find in distributed systems.\\nAWS Fault Injection Service simplifies the process of setting up and running controlled fault injection experiments across a range of AWS services so teams can build confidence in their application behavior. With Fault Injection Simulator, teams can quickly set up experiments using pre-built templates that generate the desired disruptions. AWS Fault Injection Service provides the controls and guardrails that teams need to run experiments in production, such as automatically rolling back or stopping the experiment if specific conditions are met. With a Tew clicks in the console, teams can run complex scenarios with common distributed system failures happening in parallel or building sequentially over time, enabling them to create the real world conditions necessary to find hidden weaknesses.\"\n",
      "\n",
      "=== 205 ===\n",
      "chunk.text (91 tokens):\n",
      "'Amazon Q Developer (formerly Amazon CodeWhisperer) assists developers and IT professionals with their tasks—Trom coding, testing, and upgrading applications, to diagnosing errors, performing security scanning and fixes, and optimizing AWS resources. Amazon Q has advanced,\\nAmazon Corretto\\nmultistep planning and reasoning capabilities that can transform existing code (for example, perform Java version upgrades) and implement new features generated from developer requests.'\n",
      "chunker.contextualize(chunk) (94 tokens):\n",
      "'Amazon Q Developer\\nAmazon Q Developer (formerly Amazon CodeWhisperer) assists developers and IT professionals with their tasks—Trom coding, testing, and upgrading applications, to diagnosing errors, performing security scanning and fixes, and optimizing AWS resources. Amazon Q has advanced,\\nAmazon Corretto\\nmultistep planning and reasoning capabilities that can transform existing code (for example, perform Java version upgrades) and implement new features generated from developer requests.'\n",
      "\n",
      "=== 206 ===\n",
      "chunk.text (131 tokens):\n",
      "\"AWS X-Ray helps developers analyze and debug distributed applications in production or under development, such as those built using a microservices architecture. X-Ray, you can understand how your application and its underlying services are performing so you can identity and troubleshoot the root cause of performance issues and errors. X-Ray provides an end-to-end view of requests as they travel through your application, and shows a map of your application's underlying components. You can use X-Ray to analyze both applications in development and in production, from simple three-tier applications to complex microservices applications consisting of thousands of services.\"\n",
      "chunker.contextualize(chunk) (134 tokens):\n",
      "\"X-Ray\\nAWS X-Ray helps developers analyze and debug distributed applications in production or under development, such as those built using a microservices architecture. X-Ray, you can understand how your application and its underlying services are performing so you can identity and troubleshoot the root cause of performance issues and errors. X-Ray provides an end-to-end view of requests as they travel through your application, and shows a map of your application's underlying components. You can use X-Ray to analyze both applications in development and in production, from simple three-tier applications to complex microservices applications consisting of thousands of services.\"\n",
      "\n",
      "=== 207 ===\n",
      "chunk.text (396 tokens):\n",
      "'Amazon AppStream 2.0\\nAmazon AppStream 2.0 is a fully managed application streaming service. You centrally manage your desktop applications on AppStream 2.0 and securely deliver them to any computer. You can easily scale to any number of users across the globe without acquiring, provisioning, and operating hardware or infrastructure. AppStream 2.0 is built on AWS, so you benefit from a data center and network architecture designed for the most security-sensitive organizations. Each user has a fluid and responsive experience with your applications, including GPU-intensive 5D design and engineering ones, because your applications run on virtual machines (VMs) optimized for specific use cases and each streaming session automatically adjusts to network conaitions.\\nEnterprises can use AppStream 2.0 to simplify application delivery and complete their migration to the cloud. Educational institutions can provide every student access to the applications they need for class on any computer. Software vendors can use AppStream 2.0 to deliver trials, demos, and training for their applications with no downloads or installations. They can also develop a full software-as-a-service (SaaS) solution without rewriting their application.\\nAmazon WorkSpaces\\nAmazon WorkSpaces is a Tully managed, secure cloud desktop service. You can use WorkSpaces to provision either Windows or Linux desktops in just a few minutes and quickly scale to provide thousands of desktops to workers across the globe. You can pay either monthly or hourly, just\\nAWS X-Ray\\nfor the WorkSpaces you launch, which helps you save money when compared to traditional desktops and on-premises VDI solutions. WorkSpaces helps you eliminate the complexity in managing hardware inventory, OS versions and patches, and Virtual Desktop Infrastructure (VDI), which helps simplify your desktop delivery strategy. With WorkSpaces, your users get a fast, responsive desktop of their choice that they can access anywhere, anytime, from any Supported device.'\n",
      "chunker.contextualize(chunk) (399 tokens):\n",
      "'End user computing\\nAmazon AppStream 2.0\\nAmazon AppStream 2.0 is a fully managed application streaming service. You centrally manage your desktop applications on AppStream 2.0 and securely deliver them to any computer. You can easily scale to any number of users across the globe without acquiring, provisioning, and operating hardware or infrastructure. AppStream 2.0 is built on AWS, so you benefit from a data center and network architecture designed for the most security-sensitive organizations. Each user has a fluid and responsive experience with your applications, including GPU-intensive 5D design and engineering ones, because your applications run on virtual machines (VMs) optimized for specific use cases and each streaming session automatically adjusts to network conaitions.\\nEnterprises can use AppStream 2.0 to simplify application delivery and complete their migration to the cloud. Educational institutions can provide every student access to the applications they need for class on any computer. Software vendors can use AppStream 2.0 to deliver trials, demos, and training for their applications with no downloads or installations. They can also develop a full software-as-a-service (SaaS) solution without rewriting their application.\\nAmazon WorkSpaces\\nAmazon WorkSpaces is a Tully managed, secure cloud desktop service. You can use WorkSpaces to provision either Windows or Linux desktops in just a few minutes and quickly scale to provide thousands of desktops to workers across the globe. You can pay either monthly or hourly, just\\nAWS X-Ray\\nfor the WorkSpaces you launch, which helps you save money when compared to traditional desktops and on-premises VDI solutions. WorkSpaces helps you eliminate the complexity in managing hardware inventory, OS versions and patches, and Virtual Desktop Infrastructure (VDI), which helps simplify your desktop delivery strategy. With WorkSpaces, your users get a fast, responsive desktop of their choice that they can access anywhere, anytime, from any Supported device.'\n",
      "\n",
      "=== 208 ===\n",
      "chunk.text (113 tokens):\n",
      "'Amazon WorkSpaces Core provides cloud-based, fully managed virtual desktop infrastructure (VDI) accessible to third-party VDI management solutions.\\ne Simplify VDI migration and combine your current VDI software with the security ana reliability of AWS.\\ne Maximize productivity and business continuity with a financially backed 99.9% uptime SLA.\\ne Scale on demand with fixed-rate hourly billing, no overprovisioning, and no uptront costs.\\ne Improve user experience and performance with virtual desktops located closer to your global worktorce.'\n",
      "chunker.contextualize(chunk) (118 tokens):\n",
      "'Amazon WorkSpaces Core\\nAmazon WorkSpaces Core provides cloud-based, fully managed virtual desktop infrastructure (VDI) accessible to third-party VDI management solutions.\\ne Simplify VDI migration and combine your current VDI software with the security ana reliability of AWS.\\ne Maximize productivity and business continuity with a financially backed 99.9% uptime SLA.\\ne Scale on demand with fixed-rate hourly billing, no overprovisioning, and no uptront costs.\\ne Improve user experience and performance with virtual desktops located closer to your global worktorce.'\n",
      "\n",
      "=== 209 ===\n",
      "chunk.text (126 tokens):\n",
      "\"Amazon WorkSpaces Thin Client is a cost-effective thin client device that is built to work with AWS End User Computing (EUC) virtual desktops to provide users with a complete cloud desktop solution. WorkSpaces Thin Client is a compact device designed to connect two monitors and multiple USB devices such as a keyboard, mouse, headset, and webcam. To maximize endpoint security, WorkSpaces Thin Client devices do not allow local data storage or installation of unapproved applications. The WorkSpaces Thin Client device ships directly to end users or to your company's locations preloaded with device management software.\"\n",
      "chunker.contextualize(chunk) (132 tokens):\n",
      "\"Amazon WorkSpaces Thin Client\\nAmazon WorkSpaces Thin Client is a cost-effective thin client device that is built to work with AWS End User Computing (EUC) virtual desktops to provide users with a complete cloud desktop solution. WorkSpaces Thin Client is a compact device designed to connect two monitors and multiple USB devices such as a keyboard, mouse, headset, and webcam. To maximize endpoint security, WorkSpaces Thin Client devices do not allow local data storage or installation of unapproved applications. The WorkSpaces Thin Client device ships directly to end users or to your company's locations preloaded with device management software.\"\n",
      "\n",
      "=== 210 ===\n",
      "chunk.text (145 tokens):\n",
      "'Amazon WorkSpaces Web is a low-cost, fully managed workspace built specifically to facilitate secure access to internal websites and software-as-a-service (SaaS) applications from existing web browsers, without the administrative burden of appliances or specialized client software. Protect internal content with enterprise controls, while providing access to all the web-based productivity tools users need from any browser.\\nWorkSpaces Web makes it easy Tor customers to safely provide their employees with access to internal websites and SaaS web applications without the administrative burden of appliances\\nEnd user computing\\nor specialized client software. WorkSpaces Web provides simple policy tools tailored for user interactions, while offloading common tasks like capacity management, scaling, and maintaining browser images.'\n",
      "chunker.contextualize(chunk) (150 tokens):\n",
      "'Amazon Workspaces Web\\nAmazon WorkSpaces Web is a low-cost, fully managed workspace built specifically to facilitate secure access to internal websites and software-as-a-service (SaaS) applications from existing web browsers, without the administrative burden of appliances or specialized client software. Protect internal content with enterprise controls, while providing access to all the web-based productivity tools users need from any browser.\\nWorkSpaces Web makes it easy Tor customers to safely provide their employees with access to internal websites and SaaS web applications without the administrative burden of appliances\\nEnd user computing\\nor specialized client software. WorkSpaces Web provides simple policy tools tailored for user interactions, while offloading common tasks like capacity management, scaling, and maintaining browser images.'\n",
      "\n",
      "=== 211 ===\n",
      "chunk.text (108 tokens):\n",
      "'AWS offers a broad set of tools and services to support development workflows for native iOS, Android, React Native, and JavaScript developers. Discover now easy it is to develop, deploy, and operate your app, even if you are new to AWS.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing AWS frontend web and mobile services. For general information, see Frontend\\n,  = . ,  = . ,  = . ,  = . ,  = . ,  = '\n",
      "chunker.contextualize(chunk) (114 tokens):\n",
      "'Frontend web and mobile services\\nAWS offers a broad set of tools and services to support development workflows for native iOS, Android, React Native, and JavaScript developers. Discover now easy it is to develop, deploy, and operate your app, even if you are new to AWS.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing AWS frontend web and mobile services. For general information, see Frontend\\n,  = . ,  = . ,  = . ,  = . ,  = . ,  = '\n",
      "\n",
      "=== 212 ===\n",
      "chunk.text (16 tokens):\n",
      "'e AWS Amplity\\ne AWS Appsync\\ne AWS Device Farm'\n",
      "chunker.contextualize(chunk) (17 tokens):\n",
      "'Services\\ne AWS Amplity\\ne AWS Appsync\\ne AWS Device Farm'\n",
      "\n",
      "=== 213 ===\n",
      "chunk.text (269 tokens):\n",
      "\"AWS Amplify makes it easy to create, configure, and implement scalable mobile applications powered by AWS. Amplify seamlessly provisions and manages your mobile backend and provides a simple framework to easily integrate your backend with your iOS, Android, Web, and React Native frontends. Amplify also automates the application release process of both your front-end and back-end allowing you to deliver features faster.\\nMobile applications require cloud services for actions that can't be done directly on the device, such as offline data synchronization, storage, or data sharing across multiple users. You often have to configure, set up, and manage multiple services to power the backend. You also have to integrate each of those services into your application by writing multiple lines of code. However, as the number of application features grow, your code and release process becomes more complex and managing the backend requires more time.\\nAmplify provisions and manages backends for your mobile applications. You just select the Capabilities you need such as authentication, analytics, or offline data sync, and Amplify will automatically provision and manage the AWS service that powers each of the capabilities. You can then integrate those capabilities into your application through the Amplify libraries and UI components.\"\n",
      "chunker.contextualize(chunk) (274 tokens):\n",
      "\"AWS Amplify\\nAWS Amplify makes it easy to create, configure, and implement scalable mobile applications powered by AWS. Amplify seamlessly provisions and manages your mobile backend and provides a simple framework to easily integrate your backend with your iOS, Android, Web, and React Native frontends. Amplify also automates the application release process of both your front-end and back-end allowing you to deliver features faster.\\nMobile applications require cloud services for actions that can't be done directly on the device, such as offline data synchronization, storage, or data sharing across multiple users. You often have to configure, set up, and manage multiple services to power the backend. You also have to integrate each of those services into your application by writing multiple lines of code. However, as the number of application features grow, your code and release process becomes more complex and managing the backend requires more time.\\nAmplify provisions and manages backends for your mobile applications. You just select the Capabilities you need such as authentication, analytics, or offline data sync, and Amplify will automatically provision and manage the AWS service that powers each of the capabilities. You can then integrate those capabilities into your application through the Amplify libraries and UI components.\"\n",
      "\n",
      "=== 214 ===\n",
      "chunk.text (169 tokens):\n",
      "'AWS AppSync is a serverless back-end for mobile, web, and enterprise applications.\\nAWS AppSync makes it easy to build data driven mobile and web applications by handling securely all the application data management tasks such as online and offline data access, data synchronization, and data manipulation across multiple data sources. AWS AppSync uses GraphQL, an API query language designed to build client applications by providing an intuitive and flexible syntax for describing their data requirement.\\nAWS Device Farm is an app testing service that lets you test and interact with your Android, iOS, and web apps on many devices at once, or reproduce issues on a device in real time. View video, screensnots, logs, and performance data to pinpoint and fix issues before shipping your app.\\nAWS Amplify'\n",
      "chunker.contextualize(chunk) (174 tokens):\n",
      "'AWS AppSync\\nAWS AppSync is a serverless back-end for mobile, web, and enterprise applications.\\nAWS AppSync makes it easy to build data driven mobile and web applications by handling securely all the application data management tasks such as online and offline data access, data synchronization, and data manipulation across multiple data sources. AWS AppSync uses GraphQL, an API query language designed to build client applications by providing an intuitive and flexible syntax for describing their data requirement.\\nAWS Device Farm is an app testing service that lets you test and interact with your Android, iOS, and web apps on many devices at once, or reproduce issues on a device in real time. View video, screensnots, logs, and performance data to pinpoint and fix issues before shipping your app.\\nAWS Amplify'\n",
      "\n",
      "=== 215 ===\n",
      "chunk.text (174 tokens):\n",
      "\"Amazon Location Service makes it easy for developers to add location functionality to applications without compromising data security and user privacy.\\nLocation data is a vital ingredient in today's applications, enabling capabilities ranging trom asset tracking to location-based marketing. However, developers face significant barriers when integrating location functionality into their applications. This includes cost, privacy and security compromises, and tedious and stow integration work.\\nAmazon Location Service provides affordable data, tracking and geofencing capabilities, and native integrations with AWS services, so you can create sophisticated location-enabled applications quickly, without the high cost of custom development. You retain control of your location data with Amazon Location, and you can combine proprietary data with data from the service. Amazon Location provides cost-effective location-based services (LBS) using high-quality data from global, trusted providers Esri and HERE.\"\n",
      "chunker.contextualize(chunk) (177 tokens):\n",
      "\"Amazon Location Service\\nAmazon Location Service makes it easy for developers to add location functionality to applications without compromising data security and user privacy.\\nLocation data is a vital ingredient in today's applications, enabling capabilities ranging trom asset tracking to location-based marketing. However, developers face significant barriers when integrating location functionality into their applications. This includes cost, privacy and security compromises, and tedious and stow integration work.\\nAmazon Location Service provides affordable data, tracking and geofencing capabilities, and native integrations with AWS services, so you can create sophisticated location-enabled applications quickly, without the high cost of custom development. You retain control of your location data with Amazon Location, and you can combine proprietary data with data from the service. Amazon Location provides cost-effective location-based services (LBS) using high-quality data from global, trusted providers Esri and HERE.\"\n",
      "\n",
      "=== 216 ===\n",
      "chunk.text (89 tokens):\n",
      "'Amazon GameLitt Servers is a managed service for deploying, operating, and scaling dedicated game servers Tor session-based multiplayer games. Amazon GameLift Servers makes it easy to manage server infrastructure, scale capacity to lower latency and cost, match players into available game sessions, and defend from distributed denial-of-service (DDoS) attacks. You pay for the compute resources and bandwidth your games actually use, without monthly or annual contracts.'\n",
      "chunker.contextualize(chunk) (93 tokens):\n",
      "'Amazon Game Lift Servers\\nAmazon GameLitt Servers is a managed service for deploying, operating, and scaling dedicated game servers Tor session-based multiplayer games. Amazon GameLift Servers makes it easy to manage server infrastructure, scale capacity to lower latency and cost, match players into available game sessions, and defend from distributed denial-of-service (DDoS) attacks. You pay for the compute resources and bandwidth your games actually use, without monthly or annual contracts.'\n",
      "\n",
      "=== 217 ===\n",
      "chunk.text (80 tokens):\n",
      "'Amazon Location Service\\nAWS offers Internet of Things (loT) services and solutions to connect and manage billions of devices. Collect, store, and analyze loT data for industrial, consumer, commercial, and automotive workloads.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS loT service. For general information, see AWS loT.'\n",
      "chunker.contextualize(chunk) (86 tokens):\n",
      "'Internet of Things (loT)\\nAmazon Location Service\\nAWS offers Internet of Things (loT) services and solutions to connect and manage billions of devices. Collect, store, and analyze loT data for industrial, consumer, commercial, and automotive workloads.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS loT service. For general information, see AWS loT.'\n",
      "\n",
      "=== 218 ===\n",
      "chunk.text (55 tokens):\n",
      "'e AWS lol Analytics\\ne AWS\\n\\nlo! Button\\ne AWS loT Device Defender\\ne AWS lol Device Management\\ne AWS lol ExpressLink\\ne AWS lol Greengrass\\n» AWS lol TwinMaker\\ne AWS Partner Device Catalog\\nFreeRTOS'\n",
      "chunker.contextualize(chunk) (56 tokens):\n",
      "'Services\\ne AWS lol Analytics\\ne AWS\\n\\nlo! Button\\ne AWS loT Device Defender\\ne AWS lol Device Management\\ne AWS lol ExpressLink\\ne AWS lol Greengrass\\n» AWS lol TwinMaker\\ne AWS Partner Device Catalog\\nFreeRTOS'\n",
      "\n",
      "=== 219 ===\n",
      "chunk.text (495 tokens):\n",
      "'AWS loT Analytics is a fully managed service that makes it easy to run and operationalize sophisticated analytics on massive volumes of loT data without having to worry about the cost and complexity typically required to build an loT analytics platform. It is the easiest way to run analytics on loT data and get insights to make better and more accurate decisions for loT applications and machine learning use cases.\\nloT data is highly unstructured which makes it difficult to analyze with traditional analytics and business intelligence tools that are designed to process structured data. lol data comes from devices that often record fairly noisy processes (such as temperature, motion, or sound). The data from these devices can frequently have significant gaps, corrupted messages, and false readings that must be cleaned up before analysis can occur. Also, loT data is often only meaningful in the context of additional, third party data inputs. For example, to help farmers determine when to water their crops, vineyard irrigation systems often enrich moisture sensor data with rainfall data from the vineyard, allowing for more efficient water usage while maximizing harvest yield.\\nAWS loT Analytics automates each of the dificult steps that are required to analyze data from lol devices. AWS loT Analytics filters, transforms, and enriches loT data before storing it in a time series data store for analysis. You can setup the service to collect only the data you need trom your devices, apply mathematical transforms to process the data, and enrich the data with devicespecific metadata such as device type and location before storing the processed data. Then, you can analyze your data by running ad hoc or scheduled queries using the built-in SQL query engine, or perform more complex analytics and machine learning inference. AWS loT Analytics makes it easy to get started with machine learning by including pre-built models for common IoT use cases.\\nYou can also use your own custom analysis, packaged in a container, to run AWS loT Analytics. AWS lol Analytics automates the running of your custom analyses created in Jupyter Notebook or your own tools (such as Matlab, Octave, and so on) to be run on your schedule.\\nAWS loT Analytics is a Tully managed service that operationalizes analyses and scales automatically to support up to petabytes of loT data. With AWS loT Analytics, you can analyze data from millions of devices and build fast, responsive loT applications without managing nardware or infrastructure.\\nAWS loT Analytics'\n",
      "chunker.contextualize(chunk) (500 tokens):\n",
      "'AWS IoT Analytics\\nAWS loT Analytics is a fully managed service that makes it easy to run and operationalize sophisticated analytics on massive volumes of loT data without having to worry about the cost and complexity typically required to build an loT analytics platform. It is the easiest way to run analytics on loT data and get insights to make better and more accurate decisions for loT applications and machine learning use cases.\\nloT data is highly unstructured which makes it difficult to analyze with traditional analytics and business intelligence tools that are designed to process structured data. lol data comes from devices that often record fairly noisy processes (such as temperature, motion, or sound). The data from these devices can frequently have significant gaps, corrupted messages, and false readings that must be cleaned up before analysis can occur. Also, loT data is often only meaningful in the context of additional, third party data inputs. For example, to help farmers determine when to water their crops, vineyard irrigation systems often enrich moisture sensor data with rainfall data from the vineyard, allowing for more efficient water usage while maximizing harvest yield.\\nAWS loT Analytics automates each of the dificult steps that are required to analyze data from lol devices. AWS loT Analytics filters, transforms, and enriches loT data before storing it in a time series data store for analysis. You can setup the service to collect only the data you need trom your devices, apply mathematical transforms to process the data, and enrich the data with devicespecific metadata such as device type and location before storing the processed data. Then, you can analyze your data by running ad hoc or scheduled queries using the built-in SQL query engine, or perform more complex analytics and machine learning inference. AWS loT Analytics makes it easy to get started with machine learning by including pre-built models for common IoT use cases.\\nYou can also use your own custom analysis, packaged in a container, to run AWS loT Analytics. AWS lol Analytics automates the running of your custom analyses created in Jupyter Notebook or your own tools (such as Matlab, Octave, and so on) to be run on your schedule.\\nAWS loT Analytics is a Tully managed service that operationalizes analyses and scales automatically to support up to petabytes of loT data. With AWS loT Analytics, you can analyze data from millions of devices and build fast, responsive loT applications without managing nardware or infrastructure.\\nAWS loT Analytics'\n",
      "\n",
      "=== 220 ===\n",
      "chunk.text (430 tokens):\n",
      "\"The AWS loT Button is a programmable button based on the Amazon Dash Button hardware. This simple Wi-Fi device is easy to configure, and it's designed for developers to get started with AWS lol Core, AWS Lambda, Amazon DynamoDB, Amazon SNS, and many other Amazon Web Services without writing device-specific code.\\nYou can code the button's logic in the cloud to configure button clicks to count or track items, call or alert someone, start or stop something, order services, or even provide feedback. For example, you can click the button to unlock or start a Car, open your garage door, call a cab, call your spouse or a customer service representative, track the use of common household chores, medications or products, or remotely control your home appliances.\\nThe button can be used as a remote control for Netflix, a switch for your Philips Hue light bulb, a check-in/check-out device for Airbnb guests, or a way to order your favorite pizza for delivery. You can integrate it with third-party APIs such as Twitter, Facebook, Twilio, Slack or even your own company's applications. Connect it to things we haven't even thought of yet.\\nAWS loT Core is a managed cloud service that lets connected devices easily and securely interact with cloud applications and other devices. AWS loT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS endpoints and to other devices reliably and securely. With AWS IoT Core, your applications can keep track of and communicate with all your devices, all the time, even when they aren't connected.\\nAWS loT Core makes it easy to use AWS services such as AWS Lambda, Amazon Kinesis, Amazon S53, Amazon SageMaker Al, Amazon DynamoDB, Amazon CloudWatcn, AWS CloudTrail, and Amazon QuickSight to build Internet of loT applications that gather, process, analyze and act on data generated by connected devices, without having to manage any infrastructure.\"\n",
      "chunker.contextualize(chunk) (435 tokens):\n",
      "\"AWS IoT Analytics\\nThe AWS loT Button is a programmable button based on the Amazon Dash Button hardware. This simple Wi-Fi device is easy to configure, and it's designed for developers to get started with AWS lol Core, AWS Lambda, Amazon DynamoDB, Amazon SNS, and many other Amazon Web Services without writing device-specific code.\\nYou can code the button's logic in the cloud to configure button clicks to count or track items, call or alert someone, start or stop something, order services, or even provide feedback. For example, you can click the button to unlock or start a Car, open your garage door, call a cab, call your spouse or a customer service representative, track the use of common household chores, medications or products, or remotely control your home appliances.\\nThe button can be used as a remote control for Netflix, a switch for your Philips Hue light bulb, a check-in/check-out device for Airbnb guests, or a way to order your favorite pizza for delivery. You can integrate it with third-party APIs such as Twitter, Facebook, Twilio, Slack or even your own company's applications. Connect it to things we haven't even thought of yet.\\nAWS loT Core is a managed cloud service that lets connected devices easily and securely interact with cloud applications and other devices. AWS loT Core can support billions of devices and trillions of messages, and can process and route those messages to AWS endpoints and to other devices reliably and securely. With AWS IoT Core, your applications can keep track of and communicate with all your devices, all the time, even when they aren't connected.\\nAWS loT Core makes it easy to use AWS services such as AWS Lambda, Amazon Kinesis, Amazon S53, Amazon SageMaker Al, Amazon DynamoDB, Amazon CloudWatcn, AWS CloudTrail, and Amazon QuickSight to build Internet of loT applications that gather, process, analyze and act on data generated by connected devices, without having to manage any infrastructure.\"\n",
      "\n",
      "=== 221 ===\n",
      "chunk.text (368 tokens):\n",
      "\"AWS loT Device Defender is a Tully managed service that helps you secure your fleet of loT devices. AWS loT Device Defender continuously audits your lol configurations to make sure that they aren't deviating from security best practices. A configuration is a set of technical controls you set to nelp Keep information secure when devices are communicating with each other and the cloud. AWS lol Device Defender makes it easy to maintain and enforce lol configurations, such as ensuring device identity, authenticating and authorizing devices, and encrypting device data. AWS loT Device\\nDefender continuously audits the lol configurations on your devices against a set of predefined security best practices. AWS loT Device Defender sends an alert if there are any gaps in your loT configuration that might create a security risk, such as identity certificates being shared across multiple devices or a device with a revoked identity certificate trying to connect to AWS lIoT Core.\\nAWS loT Device Defender also lets you continuously monitor security metrics from devices and AWS loT Core for deviations from what you have defined as appropriate behavior for each device. lf something doesn't look right, AWS loT Device Defender sends out an alert so you can take action to remediate the issue. For example, traffic spikes in outbound traffic might indicate that a device is participating in a DDoS attack. AWS lol Greengrass and FreeRTOS automatically integrate with AWS loT Device Defender to provide security metrics from the devices for evaluation.\\nAWS loT Device Defender can send alerts to the AWS loT Console, Amazon CloudWatch, and Amazon SNS. If you determine that you need to take an action based on an alert, you can use AWS lol Device Management to take mitigating actions such as pushing security fixes.\"\n",
      "chunker.contextualize(chunk) (373 tokens):\n",
      "\"AWS loT Device Defender\\nAWS loT Device Defender is a Tully managed service that helps you secure your fleet of loT devices. AWS loT Device Defender continuously audits your lol configurations to make sure that they aren't deviating from security best practices. A configuration is a set of technical controls you set to nelp Keep information secure when devices are communicating with each other and the cloud. AWS lol Device Defender makes it easy to maintain and enforce lol configurations, such as ensuring device identity, authenticating and authorizing devices, and encrypting device data. AWS loT Device\\nDefender continuously audits the lol configurations on your devices against a set of predefined security best practices. AWS loT Device Defender sends an alert if there are any gaps in your loT configuration that might create a security risk, such as identity certificates being shared across multiple devices or a device with a revoked identity certificate trying to connect to AWS lIoT Core.\\nAWS loT Device Defender also lets you continuously monitor security metrics from devices and AWS loT Core for deviations from what you have defined as appropriate behavior for each device. lf something doesn't look right, AWS loT Device Defender sends out an alert so you can take action to remediate the issue. For example, traffic spikes in outbound traffic might indicate that a device is participating in a DDoS attack. AWS lol Greengrass and FreeRTOS automatically integrate with AWS loT Device Defender to provide security metrics from the devices for evaluation.\\nAWS loT Device Defender can send alerts to the AWS loT Console, Amazon CloudWatch, and Amazon SNS. If you determine that you need to take an action based on an alert, you can use AWS lol Device Management to take mitigating actions such as pushing security fixes.\"\n",
      "\n",
      "=== 222 ===\n",
      "chunk.text (286 tokens):\n",
      "'As many loT deployments consist of hundreds of thousands to millions of devices, it is essential to track, monitor, and manage connected device fleets. You need to ensure your loT devices work properly and securely after they have been deployed. You also need to secure access to your devices, monitor health, detect and remotely troubleshoot problems, and manage software and firmware updates.\\nAWS loT Device Management makes it easy to securely onboard, organize, monitor, and remotely manage loT devices at scale. With AWS loT Device Management, you can register your connected devices individually or in bulk, and easily manage permissions so that devices remain secure. You can also organize your devices, monitor and troubleshoot device functionality, query the state of any loT device in your fleet, and send firmware updates over-the-air (OTA). AWS loT Device Management is agnostic to device type and OS, so you can manage devices from constrained microcontrollers to connected cars all with the same service. AWS loT Device Management allows you to scale your fleets and reduce the cost and effort of managing large and diverse loT device deployments.\\nAWS loT Events is a Tully managed IoT service that makes it easy to detect and respond to events from loT sensors and applications. Events are patterns of data identifying more complicated circumstances than expected, such as changes in equipment when a belt is stuck or connected\\nAWS tol Device Management'\n",
      "chunker.contextualize(chunk) (291 tokens):\n",
      "'AWS loT Device Management\\nAs many loT deployments consist of hundreds of thousands to millions of devices, it is essential to track, monitor, and manage connected device fleets. You need to ensure your loT devices work properly and securely after they have been deployed. You also need to secure access to your devices, monitor health, detect and remotely troubleshoot problems, and manage software and firmware updates.\\nAWS loT Device Management makes it easy to securely onboard, organize, monitor, and remotely manage loT devices at scale. With AWS loT Device Management, you can register your connected devices individually or in bulk, and easily manage permissions so that devices remain secure. You can also organize your devices, monitor and troubleshoot device functionality, query the state of any loT device in your fleet, and send firmware updates over-the-air (OTA). AWS loT Device Management is agnostic to device type and OS, so you can manage devices from constrained microcontrollers to connected cars all with the same service. AWS loT Device Management allows you to scale your fleets and reduce the cost and effort of managing large and diverse loT device deployments.\\nAWS loT Events is a Tully managed IoT service that makes it easy to detect and respond to events from loT sensors and applications. Events are patterns of data identifying more complicated circumstances than expected, such as changes in equipment when a belt is stuck or connected\\nAWS tol Device Management'\n",
      "\n",
      "=== 223 ===\n",
      "chunk.text (227 tokens):\n",
      "\"motion detectors using movement signals to activate lights and security cameras. To detect events before AWS loT Events, you had to build costly, custom applications to collect data, apply decision Logic to detect an event, and then start another application to react to the event. Using AWS loT Events, it's simple to detect events across thousands of loT sensors sending different telemetry data, such as temperature from a freezer, humidity from respiratory equipment, and belt speed ona motor, and hundreds of equipment management applications. You simply select the relevant data sources to ingest, define the logic for each event using simple 'if-then-else' statements, and select the alert or custom action to run when an event occurs. AWS loT Events continuously monitors data from multiple loT sensors and applications, and it integrates with other services, such as AWS loT Core and AWS loT Analytics, to enable early detection and unique insights into events. AWS loT Events automatically initiates alerts and actions in response to events based on the logic you define. This helps resolve issues quickly, reduce maintenance costs, and increase operational efficiency.\"\n",
      "chunker.contextualize(chunk) (232 tokens):\n",
      "\"AWS loT Device Management\\nmotion detectors using movement signals to activate lights and security cameras. To detect events before AWS loT Events, you had to build costly, custom applications to collect data, apply decision Logic to detect an event, and then start another application to react to the event. Using AWS loT Events, it's simple to detect events across thousands of loT sensors sending different telemetry data, such as temperature from a freezer, humidity from respiratory equipment, and belt speed ona motor, and hundreds of equipment management applications. You simply select the relevant data sources to ingest, define the logic for each event using simple 'if-then-else' statements, and select the alert or custom action to run when an event occurs. AWS loT Events continuously monitors data from multiple loT sensors and applications, and it integrates with other services, such as AWS loT Core and AWS loT Analytics, to enable early detection and unique insights into events. AWS loT Events automatically initiates alerts and actions in response to events based on the logic you define. This helps resolve issues quickly, reduce maintenance costs, and increase operational efficiency.\"\n",
      "\n",
      "=== 224 ===\n",
      "chunk.text (302 tokens):\n",
      "\"AWS loT ExpressLink powers a range of hardware modules developed and offered by AWS Partners, such as Espressif, Infineon, Realtek, and u-blox. Connectivity modules available from the AWS Partner Device Catalog include sottware implementing AWS mandated security requirements, making it Taster and easier for you to securely connect devices to the cloud and seamlessly integrate with a range of AWS services. AWS loT ExpressLink modules come pre-provisioned with security credentials set by qualined AWS Partners. This enables you to offload the complex work of integrating the networking and cryptography layers to the hardware modules, and develop secure lol products in a fraction of the time.\\nDevices with AWS loT ExpressLink establish a two-way connection with AWS loT Core through native support of the MQTT (publish/subscribe) communication mechanism, and can create and update AWS loT Device Shadow documents. With AWS loT ExpressLink, It's easy to make over-theair (OTA) updates to both the module and host processor from the AWS loT Device Management console. You can then remotely deploy security updates, bug fixes, and new firmware updates to add features and keep your device fleet always up to date. Moreover, partner modules with AWS lol ExpressLink can also connect to the AWS loT Device Defender to report a number of device metrics that can nelp detect anomalies and generate alerts.\"\n",
      "chunker.contextualize(chunk) (307 tokens):\n",
      "\"AWS loT ExpressLink\\nAWS loT ExpressLink powers a range of hardware modules developed and offered by AWS Partners, such as Espressif, Infineon, Realtek, and u-blox. Connectivity modules available from the AWS Partner Device Catalog include sottware implementing AWS mandated security requirements, making it Taster and easier for you to securely connect devices to the cloud and seamlessly integrate with a range of AWS services. AWS loT ExpressLink modules come pre-provisioned with security credentials set by qualined AWS Partners. This enables you to offload the complex work of integrating the networking and cryptography layers to the hardware modules, and develop secure lol products in a fraction of the time.\\nDevices with AWS loT ExpressLink establish a two-way connection with AWS loT Core through native support of the MQTT (publish/subscribe) communication mechanism, and can create and update AWS loT Device Shadow documents. With AWS loT ExpressLink, It's easy to make over-theair (OTA) updates to both the module and host processor from the AWS loT Device Management console. You can then remotely deploy security updates, bug fixes, and new firmware updates to add features and keep your device fleet always up to date. Moreover, partner modules with AWS lol ExpressLink can also connect to the AWS loT Device Defender to report a number of device metrics that can nelp detect anomalies and generate alerts.\"\n",
      "\n",
      "=== 225 ===\n",
      "chunk.text (174 tokens):\n",
      "'With AWS loT FleetWise, you can collect and organize vehicle data and store that data ina standardized way for data analysis in the cloud. AWS loT FleetWise helps you efficiently transfer\\nAWS loT ExpressLink\\ndata to the cloud in near real time using intelligent data collection capabilities. These capabilities allow you to reduce the amount of data transferred by defining rules for when to collect and transfer data based on configurable parameters (for instance, vehicle temperature, speed, or make and model). Once the data is in the cloud, you can use It for applications that analyze vehicle fleet health. This analysis can help you to more quickly identify potential maintenance issues or make in-vehicle infotainment systems smarter. You can also feed the data into machine learning (ML) models that improve advanced technologies, such as autonomous driving and advanced driver assistance systems (ADAS).'\n",
      "chunker.contextualize(chunk) (179 tokens):\n",
      "'AWS loT FleetWise\\nWith AWS loT FleetWise, you can collect and organize vehicle data and store that data ina standardized way for data analysis in the cloud. AWS loT FleetWise helps you efficiently transfer\\nAWS loT ExpressLink\\ndata to the cloud in near real time using intelligent data collection capabilities. These capabilities allow you to reduce the amount of data transferred by defining rules for when to collect and transfer data based on configurable parameters (for instance, vehicle temperature, speed, or make and model). Once the data is in the cloud, you can use It for applications that analyze vehicle fleet health. This analysis can help you to more quickly identify potential maintenance issues or make in-vehicle infotainment systems smarter. You can also feed the data into machine learning (ML) models that improve advanced technologies, such as autonomous driving and advanced driver assistance systems (ADAS).'\n",
      "\n",
      "=== 226 ===\n",
      "chunk.text (205 tokens):\n",
      "'AWS loT Greengrass seamlessly extends AWS to devices so they can act locally on the data they generate, while still using the cloud for management, analytics, and durable storage. With AWS loT Greengrass, connected devices can run AWS Lambda functions, run predictions based on machine learning models, keep device data in sync, and communicate with other devices securely — even when not connected to the internet.\\nWith AWS loT Greengrass, you can use familiar languages and programming models to create and test your device software in the cloud, and then deploy it to your devices. AWS loT Greengrass can be programmed to filter device data and only transmit necessary information back to the cloud. You can also connect to third-party applications, on-premises software, and AWS services out-ofthe-box with AWS loT Greengrass Connectors. Connectors also jumpstart device onboarding with pre-built protocol adapter integrations and allow you to streamline authentication via integration with AWS Secrets Manager.'\n",
      "chunker.contextualize(chunk) (210 tokens):\n",
      "'AWS loT Greengrass\\nAWS loT Greengrass seamlessly extends AWS to devices so they can act locally on the data they generate, while still using the cloud for management, analytics, and durable storage. With AWS loT Greengrass, connected devices can run AWS Lambda functions, run predictions based on machine learning models, keep device data in sync, and communicate with other devices securely — even when not connected to the internet.\\nWith AWS loT Greengrass, you can use familiar languages and programming models to create and test your device software in the cloud, and then deploy it to your devices. AWS loT Greengrass can be programmed to filter device data and only transmit necessary information back to the cloud. You can also connect to third-party applications, on-premises software, and AWS services out-ofthe-box with AWS loT Greengrass Connectors. Connectors also jumpstart device onboarding with pre-built protocol adapter integrations and allow you to streamline authentication via integration with AWS Secrets Manager.'\n",
      "\n",
      "=== 227 ===\n",
      "chunk.text (317 tokens):\n",
      "'AWS loT SiteWise is a managed service that makes it easy to collect, store, organize and monitor data from industrial equipment at scale to help you make better, data-driven decisions. You can use AWS loT SiteWise to monitor operations across facilities, quickly compute common industrial performance metrics, and create applications that analyze industrial equipment data to prevent costly equipment issues and reduce gaps in production. This allows you to collect data consistently across devices, identify issues with remote monitoring more quickly, and improve multi-site processes with centralized data.\\nToday, getting performance metrics from industrial equipment is challenging because data is often locked into proprietary on-premises data stores and typically requires specialized expertise to retrieve and place in a format that is useful for analysis. AWS loT SiteWise simplines this process by\\nAWS to! Greengrass\\nproviding software running on a gateway that resides in your facilities and automates the process of collecting and organizing industrial equipment data. This gateway securely connects to your on-premises data servers, collects data, and sends the data to the AWS Cloud. AWS loT SiteWise also provides interfaces for collecting data from modern industrial applications through MQTT messages or APIS.\\nYou can use AWS loT SiteWise to model your physical assets, processes and facilities, quickly compute common industrial performance metrics, and create fully managed web applications to nelp analyze industrial equipment data, reduce costs and make faster decisions. With AWS loT SiteWise, you can focus on understanding and optimizing your operations, rather than building costly in-house data collection and management applications.'\n",
      "chunker.contextualize(chunk) (323 tokens):\n",
      "'AWS loT SiteWlise\\nAWS loT SiteWise is a managed service that makes it easy to collect, store, organize and monitor data from industrial equipment at scale to help you make better, data-driven decisions. You can use AWS loT SiteWise to monitor operations across facilities, quickly compute common industrial performance metrics, and create applications that analyze industrial equipment data to prevent costly equipment issues and reduce gaps in production. This allows you to collect data consistently across devices, identify issues with remote monitoring more quickly, and improve multi-site processes with centralized data.\\nToday, getting performance metrics from industrial equipment is challenging because data is often locked into proprietary on-premises data stores and typically requires specialized expertise to retrieve and place in a format that is useful for analysis. AWS loT SiteWise simplines this process by\\nAWS to! Greengrass\\nproviding software running on a gateway that resides in your facilities and automates the process of collecting and organizing industrial equipment data. This gateway securely connects to your on-premises data servers, collects data, and sends the data to the AWS Cloud. AWS loT SiteWise also provides interfaces for collecting data from modern industrial applications through MQTT messages or APIS.\\nYou can use AWS loT SiteWise to model your physical assets, processes and facilities, quickly compute common industrial performance metrics, and create fully managed web applications to nelp analyze industrial equipment data, reduce costs and make faster decisions. With AWS loT SiteWise, you can focus on understanding and optimizing your operations, rather than building costly in-house data collection and management applications.'\n",
      "\n",
      "=== 228 ===\n",
      "chunk.text (117 tokens):\n",
      "'AWS loT TwinMaker makes it easier for developers to create digital twins of real-world systems such as buildings, factories, industrial equipment, and production lines. AWS loT TwinMaker provides the tools you need to build digital twins to help you optimize building operations, increase production output, and improve equipment performance. With the ability to use existing data from multiple sources, create virtual representations of any physical environment, and combine existing 3D models with real-world data, you can now Narness digital twins to create a nolistic view of your operations faster and with less effort.'\n",
      "chunker.contextualize(chunk) (122 tokens):\n",
      "'AWS loT TwinMaker\\nAWS loT TwinMaker makes it easier for developers to create digital twins of real-world systems such as buildings, factories, industrial equipment, and production lines. AWS loT TwinMaker provides the tools you need to build digital twins to help you optimize building operations, increase production output, and improve equipment performance. With the ability to use existing data from multiple sources, create virtual representations of any physical environment, and combine existing 3D models with real-world data, you can now Narness digital twins to create a nolistic view of your operations faster and with less effort.'\n",
      "\n",
      "=== 229 ===\n",
      "chunk.text (132 tokens):\n",
      "'The AWS Partner Device Catalog helps you find devices and hardware to help you explore, build, and go to market with your loT solutions. Search for and find hardware that works with AWS, including development kits and embedded systems to build new devices, as well as off-theshelf-devices such as gateways, edge servers, sensors, and cameras for immediate loT project integration. The choice of AWS enabled hardware from our curated catalog of devices from APN partners can help make the rollout of your loT projects easier. All devices listed in the AWS Partner Device Catalog are also available for purchase from our partners to get you started quickly.'\n",
      "chunker.contextualize(chunk) (137 tokens):\n",
      "'AWS Partner Device Catalog\\nThe AWS Partner Device Catalog helps you find devices and hardware to help you explore, build, and go to market with your loT solutions. Search for and find hardware that works with AWS, including development kits and embedded systems to build new devices, as well as off-theshelf-devices such as gateways, edge servers, sensors, and cameras for immediate loT project integration. The choice of AWS enabled hardware from our curated catalog of devices from APN partners can help make the rollout of your loT projects easier. All devices listed in the AWS Partner Device Catalog are also available for purchase from our partners to get you started quickly.'\n",
      "\n",
      "=== 230 ===\n",
      "chunk.text (309 tokens):\n",
      "'FreeRTOS is an operating system for microcontrollers that makes small, low-power edge devices easy to program, deploy, secure, connect, and manage. FreeRTOS extends the FreeRTOS Kernel, a popular open source operating system for microcontrollers, with software libraries that make it easy to securely connect your small, low-power devices to AWS Cloud services such as AWS loT Core or to more powerTul edge devices running AWS loT Greengrass.\\nAWS loT TwinMaker\\nA microcontroller (MCU) is a single chip containing a simple processor that can be found in many devices, including appliances, sensors, fitness trackers, industrial automation, and automobiles. Many of these small devices could benefit from connecting to the cloud or locally to other devices. For example, smart electricity meters need to connect to the cloud to report on usage, and building security systems need to communicate locally so that a door will unlock wnen you badge In. Microcontrollers have limited compute power and memory capacity and typically perform simple, functional tasks. Microcontrollers frequently run operating systems that do not have built-in functionality to connect to local networks or the cloud, making loT applications a challenge. FreeRTOS helps solve this problem by providing both the core operating system (to run the edge device) as well as software libraries that make it easy to securely connect to the cloud (or other edge devices) so you can collect data from them for loT applications and take action.'\n",
      "chunker.contextualize(chunk) (312 tokens):\n",
      "'FreeRTOS\\nFreeRTOS is an operating system for microcontrollers that makes small, low-power edge devices easy to program, deploy, secure, connect, and manage. FreeRTOS extends the FreeRTOS Kernel, a popular open source operating system for microcontrollers, with software libraries that make it easy to securely connect your small, low-power devices to AWS Cloud services such as AWS loT Core or to more powerTul edge devices running AWS loT Greengrass.\\nAWS loT TwinMaker\\nA microcontroller (MCU) is a single chip containing a simple processor that can be found in many devices, including appliances, sensors, fitness trackers, industrial automation, and automobiles. Many of these small devices could benefit from connecting to the cloud or locally to other devices. For example, smart electricity meters need to connect to the cloud to report on usage, and building security systems need to communicate locally so that a door will unlock wnen you badge In. Microcontrollers have limited compute power and memory capacity and typically perform simple, functional tasks. Microcontrollers frequently run operating systems that do not have built-in functionality to connect to local networks or the cloud, making loT applications a challenge. FreeRTOS helps solve this problem by providing both the core operating system (to run the edge device) as well as software libraries that make it easy to securely connect to the cloud (or other edge devices) so you can collect data from them for loT applications and take action.'\n",
      "\n",
      "=== 231 ===\n",
      "chunk.text (108 tokens):\n",
      "'AWS helps you at every stage of your ML adoption journey with the most comprehensive set ML services and purpose-built infrastructure. Our pretrained Al services provide ready-made intelligence for your applications and workflows.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS machine learning service, Choosing a generative Al service, ana Amazon Bedrock or Amazon SageMaker Al?. For general information, see Build and scale the next wave otf Al innovation on AWS.'\n",
      "chunker.contextualize(chunk) (119 tokens):\n",
      "'Machine Learning (ML) and Artificial Intelligence (Al)\\nAWS helps you at every stage of your ML adoption journey with the most comprehensive set ML services and purpose-built infrastructure. Our pretrained Al services provide ready-made intelligence for your applications and workflows.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS machine learning service, Choosing a generative Al service, ana Amazon Bedrock or Amazon SageMaker Al?. For general information, see Build and scale the next wave otf Al innovation on AWS.'\n",
      "\n",
      "=== 232 ===\n",
      "chunk.text (111 tokens):\n",
      "'e Amazon Augmented Al\\nAmazon\\nAmazon\\nAmazon Comprenencd\\nAmazon YevOps Guru\\nAmazon -orecast\\nAmazon Frauia Detector\\nAmazon Comprenend Medical\\nAmazon enara\\nAmazon\\nAmazon Lookout tor Equipment\\nAmazon | ookout for Metrics\\nAmazon | ookout tor Vision\\nAmazon Monitron\\ne Amazon PartyRock\\ne Amazon Personalize\\ne Amazon Polly\\nAmazon Q\\ne Amazon Rekognition\\ne Amazon SageMaker Al\\ne Amazon /extract\\ne Amazon Transcribe\\ne Amazon Translate\\ne AWS DeepComposer\\ne AWS DeepRacer\\ne AWS Panorama'\n",
      "chunker.contextualize(chunk) (112 tokens):\n",
      "'Services\\ne Amazon Augmented Al\\nAmazon\\nAmazon\\nAmazon Comprenencd\\nAmazon YevOps Guru\\nAmazon -orecast\\nAmazon Frauia Detector\\nAmazon Comprenend Medical\\nAmazon enara\\nAmazon\\nAmazon Lookout tor Equipment\\nAmazon | ookout for Metrics\\nAmazon | ookout tor Vision\\nAmazon Monitron\\ne Amazon PartyRock\\ne Amazon Personalize\\ne Amazon Polly\\nAmazon Q\\ne Amazon Rekognition\\ne Amazon SageMaker Al\\ne Amazon /extract\\ne Amazon Transcribe\\ne Amazon Translate\\ne AWS DeepComposer\\ne AWS DeepRacer\\ne AWS Panorama'\n",
      "\n",
      "=== 233 ===\n",
      "chunk.text (69 tokens):\n",
      "'Amazon Augmented Al (Amazon A2I) is a ML service which makes it easy to build the workflows required for human review. Amazon A2I brings human review to all developers, removing the undifferentiated heavy lifting associated with building human review systems or managing large numbers of human reviewers, whether it runs on AWS or not.'\n",
      "chunker.contextualize(chunk) (72 tokens):\n",
      "'Amazon Augmented Al\\nAmazon Augmented Al (Amazon A2I) is a ML service which makes it easy to build the workflows required for human review. Amazon A2I brings human review to all developers, removing the undifferentiated heavy lifting associated with building human review systems or managing large numbers of human reviewers, whether it runs on AWS or not.'\n",
      "\n",
      "=== 234 ===\n",
      "chunk.text (129 tokens):\n",
      "'Amazon Bedrock is a fully managed service that makes foundational models (FMs) from Amazon and leading Al companies available through an API. With the Amazon Bedrock serverless experience, you can quickly get started, experiment with FMs, privately customize them with your own data, and seamlessly integrate and deploy FMs into your AWS applications.\\nYou can choose from a variety of foundation models from leading Al companies, such as Al21 Labs, Antnropic, Conere, DeepSeek, Luma, Meta, Mistral Al, and Stability Al. Or you can use the Amazon Nova foundation models available exclusively in Amazon Bedrock.'\n",
      "chunker.contextualize(chunk) (131 tokens):\n",
      "'Amazon Bedrock\\nAmazon Bedrock is a fully managed service that makes foundational models (FMs) from Amazon and leading Al companies available through an API. With the Amazon Bedrock serverless experience, you can quickly get started, experiment with FMs, privately customize them with your own data, and seamlessly integrate and deploy FMs into your AWS applications.\\nYou can choose from a variety of foundation models from leading Al companies, such as Al21 Labs, Antnropic, Conere, DeepSeek, Luma, Meta, Mistral Al, and Stability Al. Or you can use the Amazon Nova foundation models available exclusively in Amazon Bedrock.'\n",
      "\n",
      "=== 235 ===\n",
      "chunk.text (168 tokens):\n",
      "\"Amazon CodeGuru Is a developer tool that provides intelligent recommendations to improve code quality and identify an application's most expensive lines of code. Integrate CodeGuru into your existing software development workTlow to automate code reviews during application development and continuously monitor application's performance in production and provide recommendations and visual clues on how to improve code quality, application performance, and reduce overall cost.\\nAmazon CodeGuru Reviewer uses ML and automated reasoning to identify critical issues, security vulnerabilities, and hard-to-find bugs during application development and provides recommendations to improve code quality.\\nAmazon CodeGuru Profiler helps developers find an application's most expensive lines of code by nelping them understand the runtime behavior of their applications, identify and remove code inefficiencies, improve performance, and significantly decrease compute costs.\"\n",
      "chunker.contextualize(chunk) (172 tokens):\n",
      "\"Amazon CodeGuru\\nAmazon CodeGuru Is a developer tool that provides intelligent recommendations to improve code quality and identify an application's most expensive lines of code. Integrate CodeGuru into your existing software development workTlow to automate code reviews during application development and continuously monitor application's performance in production and provide recommendations and visual clues on how to improve code quality, application performance, and reduce overall cost.\\nAmazon CodeGuru Reviewer uses ML and automated reasoning to identify critical issues, security vulnerabilities, and hard-to-find bugs during application development and provides recommendations to improve code quality.\\nAmazon CodeGuru Profiler helps developers find an application's most expensive lines of code by nelping them understand the runtime behavior of their applications, identify and remove code inefficiencies, improve performance, and significantly decrease compute costs.\"\n",
      "\n",
      "=== 236 ===\n",
      "chunk.text (221 tokens):\n",
      "\"Amazon Comprehend uses ML and natural language processing (NLP) to help you uncover the insights and relationships in your unstructured data. The service identifies the language of the text; extracts key phrases, places, people, brands, or events; understands how positive or negative the text is; analyzes text using tokenization and parts of speech; and automatically organizes a collection of text files by topic. You can also use AUtoML capabilities in Amazon Comprehend to build a custom set of entities or text classification models that are tailored uniquely to your organization's needs.\\nFor extracting complex medical information from unstructured text, you can use Amazon Comprehend Medical. The service can identify medical information, such as medical conditions, medications, dosages, strengths, and frequencies from a variety of sources like doctor's notes, clinical trial reports, and patient health records. Amazon Comprehend Medical also identifies the relationship among the extracted medication and test, treatment and procedure information for easier analysis. For example, the service identifies a particular dosage, strength, and frequency related to a specific medication from unstructured clinical notes.\"\n",
      "chunker.contextualize(chunk) (223 tokens):\n",
      "\"Amazon Comprehend\\nAmazon Comprehend uses ML and natural language processing (NLP) to help you uncover the insights and relationships in your unstructured data. The service identifies the language of the text; extracts key phrases, places, people, brands, or events; understands how positive or negative the text is; analyzes text using tokenization and parts of speech; and automatically organizes a collection of text files by topic. You can also use AUtoML capabilities in Amazon Comprehend to build a custom set of entities or text classification models that are tailored uniquely to your organization's needs.\\nFor extracting complex medical information from unstructured text, you can use Amazon Comprehend Medical. The service can identify medical information, such as medical conditions, medications, dosages, strengths, and frequencies from a variety of sources like doctor's notes, clinical trial reports, and patient health records. Amazon Comprehend Medical also identifies the relationship among the extracted medication and test, treatment and procedure information for easier analysis. For example, the service identifies a particular dosage, strength, and frequency related to a specific medication from unstructured clinical notes.\"\n",
      "\n",
      "=== 237 ===\n",
      "chunk.text (250 tokens):\n",
      "\"Amazon DevOps Guru is an ML-powered service that makes it easy to improve an application's operational performance and availability. Amazon DevOps Guru detects benaviors that deviate\\nAmazon CodeGuru\\nfrom normal operating patterns so you can identify operational issues long before they impact your customers.\\nAmazon DevOps Guru uses ML models informed by years of Amazon.com and AWS operational excellence to identify anomalous application behavior (such as increased latency, error rates, resource constraints, etc.) and surface critical issues that could cause potential outages or service disruptions. When Amazon DevOps Guru identifies a critical issue, it automatically sends an alert and provides a summary of related anomalies, the likely root cause, and context about when and where the issue occurred. When possible, Amazon DevOps Guru also provides recommendations on how to remediate the issue.\\nAmazon DevOps Guru automatically ingests operational data from your AWS applications and provides a single dashboard to visualize issues in your operational data. You can get started by enabling Amazon DevOps Guru for all resources in your AWS account, resources in your AWS CloudFormation Stacks, or resources grouped together by AWS tags, with no manual setup or ML expertise required.\"\n",
      "chunker.contextualize(chunk) (254 tokens):\n",
      "\"Amazon DevOps Guru\\nAmazon DevOps Guru is an ML-powered service that makes it easy to improve an application's operational performance and availability. Amazon DevOps Guru detects benaviors that deviate\\nAmazon CodeGuru\\nfrom normal operating patterns so you can identify operational issues long before they impact your customers.\\nAmazon DevOps Guru uses ML models informed by years of Amazon.com and AWS operational excellence to identify anomalous application behavior (such as increased latency, error rates, resource constraints, etc.) and surface critical issues that could cause potential outages or service disruptions. When Amazon DevOps Guru identifies a critical issue, it automatically sends an alert and provides a summary of related anomalies, the likely root cause, and context about when and where the issue occurred. When possible, Amazon DevOps Guru also provides recommendations on how to remediate the issue.\\nAmazon DevOps Guru automatically ingests operational data from your AWS applications and provides a single dashboard to visualize issues in your operational data. You can get started by enabling Amazon DevOps Guru for all resources in your AWS account, resources in your AWS CloudFormation Stacks, or resources grouped together by AWS tags, with no manual setup or ML expertise required.\"\n",
      "\n",
      "=== 238 ===\n",
      "chunk.text (363 tokens):\n",
      "'Amazon Forecast is a fully managed service that uses ML to deliver highly accurate forecasts.\\nCompanies today use everything from simple spreadsheets to complex financial planning software to attempt to accurately forecast future business outcomes such as product demand, resource needs, or financial performance. These tools build forecasts by looking at a historical series of data, which is called time series data. For example, such tools may try to predict the future sales of a raincoat by looking only at its previous sales data with the underlying assumption that the future is determined by the past. This approach can struggle to produce accurate forecasts for large sets of data that have irregular trends. Also, it fails to easily combine data series that change over time (such as price, discounts, web traffic, and number of employees) with relevant independent variables such as product features and store locations.\\nBased on the same technology used at Amazon.com, Amazon Forecast uses ML to combine time series data with additional variables to build forecasts. Amazon Forecast requires no ML experience to get started. You only need to provide historical data, plus any additional data that you believe may impact your forecasts. For example, the demand for a particular color of a shirt may change with the seasons and store location. This complex relationship is hard to determine on its own, but ML is ideally suited to recognize it. Once you provide your data, Amazon Forecast will automatically examine it, identify what is meaningful, and produce a forecasting model capable of making predictions that are up to 50% more accurate than looking at time Series data alone.\\nAmazon Forecast\\nAmazon Forecast is a fully managed service, so there are no servers to provision, and no ML models to build, train, or deploy. You pay only for what you use, and there are no minimum fees and no upfront commitments.'\n",
      "chunker.contextualize(chunk) (365 tokens):\n",
      "'Amazon Forecast\\nAmazon Forecast is a fully managed service that uses ML to deliver highly accurate forecasts.\\nCompanies today use everything from simple spreadsheets to complex financial planning software to attempt to accurately forecast future business outcomes such as product demand, resource needs, or financial performance. These tools build forecasts by looking at a historical series of data, which is called time series data. For example, such tools may try to predict the future sales of a raincoat by looking only at its previous sales data with the underlying assumption that the future is determined by the past. This approach can struggle to produce accurate forecasts for large sets of data that have irregular trends. Also, it fails to easily combine data series that change over time (such as price, discounts, web traffic, and number of employees) with relevant independent variables such as product features and store locations.\\nBased on the same technology used at Amazon.com, Amazon Forecast uses ML to combine time series data with additional variables to build forecasts. Amazon Forecast requires no ML experience to get started. You only need to provide historical data, plus any additional data that you believe may impact your forecasts. For example, the demand for a particular color of a shirt may change with the seasons and store location. This complex relationship is hard to determine on its own, but ML is ideally suited to recognize it. Once you provide your data, Amazon Forecast will automatically examine it, identify what is meaningful, and produce a forecasting model capable of making predictions that are up to 50% more accurate than looking at time Series data alone.\\nAmazon Forecast\\nAmazon Forecast is a fully managed service, so there are no servers to provision, and no ML models to build, train, or deploy. You pay only for what you use, and there are no minimum fees and no upfront commitments.'\n",
      "\n",
      "=== 239 ===\n",
      "chunk.text (127 tokens):\n",
      "\"Amazon Fraud Detector is a Tully managed service that uses ML and more than 20 years of fraud detection expertise from Amazon, to identify potentially fraudulent activity so customers can catch more online Traud faster. Amazon Fraud Detector automates the time consuming and expensive steps to build, train, and deploy an ML model for fraud detection, making it easier Tor customers to leverage the technology. Amazon Fraud Detector customizes each model it creates to a customer's own dataset, making the accuracy of models higher than current one-size fits all ML solutions. And, because you pay only Tor what you use, you avoid large uptfront expenses.\"\n",
      "chunker.contextualize(chunk) (130 tokens):\n",
      "\"Amazon Fraud Detector\\nAmazon Fraud Detector is a Tully managed service that uses ML and more than 20 years of fraud detection expertise from Amazon, to identify potentially fraudulent activity so customers can catch more online Traud faster. Amazon Fraud Detector automates the time consuming and expensive steps to build, train, and deploy an ML model for fraud detection, making it easier Tor customers to leverage the technology. Amazon Fraud Detector customizes each model it creates to a customer's own dataset, making the accuracy of models higher than current one-size fits all ML solutions. And, because you pay only Tor what you use, you avoid large uptfront expenses.\"\n",
      "\n",
      "=== 240 ===\n",
      "chunk.text (160 tokens):\n",
      "'Over the past decade, AWS has witnessed a digital transformation in health, with organizations capturing huge volumes of patient information every day. But this data is often unstructured and the process to extract this information is labor-intensive and error-prone. Amazon Comprehend Medical is a HIPAA-eligible natural language processing (NLP) service that uses machine learning that has been pre-trained to understand and extract health data from medical text, such as prescriptions, procedures, or dlagnoses. Amazon Comprehend Medical can help you extract information from unstructured medical text accurately and quickly with medical ontologies like ICD-10-CM, RxNorm, and SNOMED CT and in turn accelerate insurance claim processing, improve population health, and accelerate pharmacovigilance.'\n",
      "chunker.contextualize(chunk) (163 tokens):\n",
      "'Amazon Comprehend Medical\\nOver the past decade, AWS has witnessed a digital transformation in health, with organizations capturing huge volumes of patient information every day. But this data is often unstructured and the process to extract this information is labor-intensive and error-prone. Amazon Comprehend Medical is a HIPAA-eligible natural language processing (NLP) service that uses machine learning that has been pre-trained to understand and extract health data from medical text, such as prescriptions, procedures, or dlagnoses. Amazon Comprehend Medical can help you extract information from unstructured medical text accurately and quickly with medical ontologies like ICD-10-CM, RxNorm, and SNOMED CT and in turn accelerate insurance claim processing, improve population health, and accelerate pharmacovigilance.'\n",
      "\n",
      "=== 241 ===\n",
      "chunk.text (120 tokens):\n",
      "\"Amazon Kendra Is an intelligent search service powered by ML. Amazon Kendra reimagines enterprise search for your websites and applications so your employees and customers can easily find the content they are looking for, even when it's scattered across multiple locations and content repositories within your organization.\\nUsing Amazon Kendra, you can stop searching through troves of unstructured data and discover the right answers to your questions, when you need them. Amazon Kendra is a Tully managed service, so there are no servers to provision, and no ML models to build, train, or deploy.\\nAmazon Fraud Detector\"\n",
      "chunker.contextualize(chunk) (122 tokens):\n",
      "\"Amazon Kendra\\nAmazon Kendra Is an intelligent search service powered by ML. Amazon Kendra reimagines enterprise search for your websites and applications so your employees and customers can easily find the content they are looking for, even when it's scattered across multiple locations and content repositories within your organization.\\nUsing Amazon Kendra, you can stop searching through troves of unstructured data and discover the right answers to your questions, when you need them. Amazon Kendra is a Tully managed service, so there are no servers to provision, and no ML models to build, train, or deploy.\\nAmazon Fraud Detector\"\n",
      "\n",
      "=== 242 ===\n",
      "chunk.text (330 tokens):\n",
      "'Amazon Lex is a fully managed artificial intelligence (Al) service to design, build, test, and deploy conversational interfaces into any application using voice and text. Lex provides the advanced deep learning functionalities of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, to enable you to build applications with highly engaging user experiences and lifelike conversational interactions, and create new categories of products. With Amazon Lex, the same deep learning technologies that power Amazon Alexa are now available to any developer, enabling you to quickly and easily build sophisticated, natural language, conversational bots (\"chatbots\") and voice enabled interactive voice response (IVR) systems.\\nAmazon Lex enables developers to build conversational chatbots quickly. With Amazon Lex, no deep learning expertise is necessary—to create a bot, you just specify the basic conversation flow in the Amazon Lex console. Amazon Lex manages the dialogue and dynamically adjusts the responses in the conversation. Using the console, you can build, test, and publish your text or voice chatbot. You can then add the conversational interfaces to bots on mobile devices, web applications, and chat platforms (for example, Facebook Messenger). There are no uptront costs or minimum fees to use Amazon Lex - you are charged only for the text or speech requests that are made. The pay-as-you-go pricing and the low cost per request make the service a cost-effective way to build conversational interfaces. With the Amazon Lex Tree tier, you can easily try Amazon Lex without any initial investment.'\n",
      "chunker.contextualize(chunk) (332 tokens):\n",
      "'Amazon Lex\\nAmazon Lex is a fully managed artificial intelligence (Al) service to design, build, test, and deploy conversational interfaces into any application using voice and text. Lex provides the advanced deep learning functionalities of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, to enable you to build applications with highly engaging user experiences and lifelike conversational interactions, and create new categories of products. With Amazon Lex, the same deep learning technologies that power Amazon Alexa are now available to any developer, enabling you to quickly and easily build sophisticated, natural language, conversational bots (\"chatbots\") and voice enabled interactive voice response (IVR) systems.\\nAmazon Lex enables developers to build conversational chatbots quickly. With Amazon Lex, no deep learning expertise is necessary—to create a bot, you just specify the basic conversation flow in the Amazon Lex console. Amazon Lex manages the dialogue and dynamically adjusts the responses in the conversation. Using the console, you can build, test, and publish your text or voice chatbot. You can then add the conversational interfaces to bots on mobile devices, web applications, and chat platforms (for example, Facebook Messenger). There are no uptront costs or minimum fees to use Amazon Lex - you are charged only for the text or speech requests that are made. The pay-as-you-go pricing and the low cost per request make the service a cost-effective way to build conversational interfaces. With the Amazon Lex Tree tier, you can easily try Amazon Lex without any initial investment.'\n",
      "\n",
      "=== 243 ===\n",
      "chunk.text (121 tokens):\n",
      "'Amazon Lookout for Equipment analyzes the data from the sensors on your equipment (such as pressure in a generator, flow rate of a compressor, revolutions per minute of fans), to automatically train an ML model based on just your data, for your equipment — with no ML expertise required. Lookout for Equipment uses your unique ML model to analyze incoming sensor data in real-time and accurately identify early warning signs that could lead to machine failures. This means you can detect equipment abnormalities with speed and precision, quickly diagnose issues, take action to reduce expensive downtime, and reduce false alerts.\\nAmazon Lex'\n",
      "chunker.contextualize(chunk) (125 tokens):\n",
      "'Amazon Lookout for Equipment\\nAmazon Lookout for Equipment analyzes the data from the sensors on your equipment (such as pressure in a generator, flow rate of a compressor, revolutions per minute of fans), to automatically train an ML model based on just your data, for your equipment — with no ML expertise required. Lookout for Equipment uses your unique ML model to analyze incoming sensor data in real-time and accurately identify early warning signs that could lead to machine failures. This means you can detect equipment abnormalities with speed and precision, quickly diagnose issues, take action to reduce expensive downtime, and reduce false alerts.\\nAmazon Lex'\n",
      "\n",
      "=== 244 ===\n",
      "chunk.text (286 tokens):\n",
      "'On October 10, 2025, AWS will discontinue support Tor Amazon Lookout for Metrics. For more information, see Transitioning off Amazon Lookout for Metrics.\\nAmazon Lookout for Metrics uses ML to automatically detect and diagnose anomalies (outliers from the norm) in business and operational data, such as a sudden dip in sales revenue or customer acquisition rates. In a couple of clicks, you can connect Amazon Lookout for Metrics to popular data stores such as Amazon $3, Amazon Redshift, and Amazon Relational Database Service (Amazon RDS), as well as third-party Software as a Service (SaaS) applications, such as Salesforce, Servicenow, Zendesk, and Marketo, and start monitoring metrics that are important to your business. Lookout for Metrics automatically inspects and prepares the data from these sources to detect anomalies with greater speed and accuracy than traditional methods used Tor anomaly detection. You can also provide feedback on detected anomalies to tune the results and improve accuracy over time. Lookout for Metrics makes it easy to diagnose detected anomalies by grouping together anomalies that are related to the same event and sending an alert that includes a summary of the potential root cause. It also ranks anomalies in order of severity so that you can prioritize your attention to what matters the most to your business.'\n",
      "chunker.contextualize(chunk) (287 tokens):\n",
      "'Note\\nOn October 10, 2025, AWS will discontinue support Tor Amazon Lookout for Metrics. For more information, see Transitioning off Amazon Lookout for Metrics.\\nAmazon Lookout for Metrics uses ML to automatically detect and diagnose anomalies (outliers from the norm) in business and operational data, such as a sudden dip in sales revenue or customer acquisition rates. In a couple of clicks, you can connect Amazon Lookout for Metrics to popular data stores such as Amazon $3, Amazon Redshift, and Amazon Relational Database Service (Amazon RDS), as well as third-party Software as a Service (SaaS) applications, such as Salesforce, Servicenow, Zendesk, and Marketo, and start monitoring metrics that are important to your business. Lookout for Metrics automatically inspects and prepares the data from these sources to detect anomalies with greater speed and accuracy than traditional methods used Tor anomaly detection. You can also provide feedback on detected anomalies to tune the results and improve accuracy over time. Lookout for Metrics makes it easy to diagnose detected anomalies by grouping together anomalies that are related to the same event and sending an alert that includes a summary of the potential root cause. It also ranks anomalies in order of severity so that you can prioritize your attention to what matters the most to your business.'\n",
      "\n",
      "=== 245 ===\n",
      "chunk.text (185 tokens):\n",
      "'Amazon Lookout for Vision is an ML service that spots defects and anomalies in visual representations using computer vision (CV). With Amazon Lookout for Vision, manufacturing companies can increase quality and reduce operational costs by quickly identifying differences in images of objects at scale. For example, Lookout for Vision can be used to identify missing components in products, damage to vehicles or structures, irregularities In production lines, miniscule defects in silicon wafers, and other similar problems. Amazon Lookout for Vision uses ML to see and understand images from any camera as a person would, but with an even higher degree of accuracy and at a much larger scale. Lookout for Vision allows customers to eliminate the need for costly and inconsistent manual inspection, while improving quality control, defect and damage assessment, and compliance. In minutes, you can begin using Lookout for Vision to automate inspection of images and objects — with no ML expertise required.\\nAmazon Lookout for Metrics'\n",
      "chunker.contextualize(chunk) (189 tokens):\n",
      "'Amazon Lookout for Vision\\nAmazon Lookout for Vision is an ML service that spots defects and anomalies in visual representations using computer vision (CV). With Amazon Lookout for Vision, manufacturing companies can increase quality and reduce operational costs by quickly identifying differences in images of objects at scale. For example, Lookout for Vision can be used to identify missing components in products, damage to vehicles or structures, irregularities In production lines, miniscule defects in silicon wafers, and other similar problems. Amazon Lookout for Vision uses ML to see and understand images from any camera as a person would, but with an even higher degree of accuracy and at a much larger scale. Lookout for Vision allows customers to eliminate the need for costly and inconsistent manual inspection, while improving quality control, defect and damage assessment, and compliance. In minutes, you can begin using Lookout for Vision to automate inspection of images and objects — with no ML expertise required.\\nAmazon Lookout for Metrics'\n",
      "\n",
      "=== 246 ===\n",
      "chunk.text (252 tokens):\n",
      "'Amazon Monitron ts an end-to-end system that uses ML to detect abnormal benavior in industrial macninery, enabling you to implement predictive maintenance and reduce unplanned downtime.\\nInstalling sensors and the necessary infrastructure for data connectivity, storage, analytics, and alerting are foundational elements for enabling predictive maintenance. However, to make it work, companies Nave historically needed skilled technicians and data scientists to piece together a complex solution from scratch. This included identifying and procuring the right type of sensors for their use cases and connecting them together with an loT gateway (a device that aggregates and transmits data). As a result, few companies Nave been able to successfully implement predictive maintenance.\\nAmazon Monitron includes sensors to capture vibration and temperature data from equipment, a gateway device to securely transfer data to AWS, the Amazon Monitron service that analyzes the data for abnormal machine patterns using ML, and a companion mobile app to set up the devices and receive reports on operating behavior and alerts to potential failures in your machinery. You can start monitoring equipment health in minutes without any development work or ML experience required, and enable predictive maintenance with the same technology used to monitor equipment in Amazon Fulfillment Centers.'\n",
      "chunker.contextualize(chunk) (256 tokens):\n",
      "'Amazon Monitron\\nAmazon Monitron ts an end-to-end system that uses ML to detect abnormal benavior in industrial macninery, enabling you to implement predictive maintenance and reduce unplanned downtime.\\nInstalling sensors and the necessary infrastructure for data connectivity, storage, analytics, and alerting are foundational elements for enabling predictive maintenance. However, to make it work, companies Nave historically needed skilled technicians and data scientists to piece together a complex solution from scratch. This included identifying and procuring the right type of sensors for their use cases and connecting them together with an loT gateway (a device that aggregates and transmits data). As a result, few companies Nave been able to successfully implement predictive maintenance.\\nAmazon Monitron includes sensors to capture vibration and temperature data from equipment, a gateway device to securely transfer data to AWS, the Amazon Monitron service that analyzes the data for abnormal machine patterns using ML, and a companion mobile app to set up the devices and receive reports on operating behavior and alerts to potential failures in your machinery. You can start monitoring equipment health in minutes without any development work or ML experience required, and enable predictive maintenance with the same technology used to monitor equipment in Amazon Fulfillment Centers.'\n",
      "\n",
      "=== 247 ===\n",
      "chunk.text (72 tokens):\n",
      "'Amazon PartyRock makes learning generative Al easy with a hands-on, code-tree app builder. Experiment with prompt engineering techniques, review generated responses, and develop intuition for generative Al while creating and exploring Tun apps. PartyRock provides access to foundation models (FMs) from Amazon and leading Al companies through Amazon Bedrock, a Tully managed serviced service.'\n",
      "chunker.contextualize(chunk) (75 tokens):\n",
      "'Amazon PartyRock\\nAmazon PartyRock makes learning generative Al easy with a hands-on, code-tree app builder. Experiment with prompt engineering techniques, review generated responses, and develop intuition for generative Al while creating and exploring Tun apps. PartyRock provides access to foundation models (FMs) from Amazon and leading Al companies through Amazon Bedrock, a Tully managed serviced service.'\n",
      "\n",
      "=== 248 ===\n",
      "chunk.text (408 tokens):\n",
      "'Amazon Personalize is an ML service that makes it easy for developers to create individualized recommendations for customers using their applications.\\nML is increasingly used to improve customer engagement by powering personalized product and content recommendations, tailored search results, and targeted marketing promotions. However, developing the ML capabilities necessary to produce these sophisticated recommendation systems nas been beyond the reach of most organizations today due to the complexity of developing ML\\nAmazon Monitron\\nfunctionality. Amazon Personalize allows developers with no prior ML experience to easily build sophisticated personalization capabilities into their applications, using ML technology perfected from years of use on Amazon.com.\\nWith Amazon Personalize, you provide an activity stream from your application — page views, Signups, purchases, and so forth — as well as an inventory of the items you want to recommend, such as articles, products, videos, or music. You can also choose to provide Amazon Personalize with additional demographic information from your users such as age, or geographic location. Amazon Personalize processes and examines the data, identifies what is meaningful, selects the right algorithms, and trains and optimizes a personalization model that is customized for your\\nAmazon Personalize offers optimized recommencders for retail and media and entertainment that make it faster and easier to deliver high-performing personalized user experiences. Amazon Personalize also offers intelligent user segmentation so you can run more effective prospecting Campaigns through your marketing channels. With our two new recipes, you can automatically segment your users based on their interest in different product categories, brands, and more.\\nAll data analyzed by Amazon Personalize is kept private and secure, and only used for your customized recommenaations. You can start serving your personalized predictions via a simple API call from inside the virtual private cloud that the service maintains. You pay only Tor wnat you use, and there are no minimum Tees and no uptront commitments.\\nAmazon Personalize is like having your own Amazon.com ML personalization team at your disposal, 24 hours a day.'\n",
      "chunker.contextualize(chunk) (411 tokens):\n",
      "'Amazon Personalize\\nAmazon Personalize is an ML service that makes it easy for developers to create individualized recommendations for customers using their applications.\\nML is increasingly used to improve customer engagement by powering personalized product and content recommendations, tailored search results, and targeted marketing promotions. However, developing the ML capabilities necessary to produce these sophisticated recommendation systems nas been beyond the reach of most organizations today due to the complexity of developing ML\\nAmazon Monitron\\nfunctionality. Amazon Personalize allows developers with no prior ML experience to easily build sophisticated personalization capabilities into their applications, using ML technology perfected from years of use on Amazon.com.\\nWith Amazon Personalize, you provide an activity stream from your application — page views, Signups, purchases, and so forth — as well as an inventory of the items you want to recommend, such as articles, products, videos, or music. You can also choose to provide Amazon Personalize with additional demographic information from your users such as age, or geographic location. Amazon Personalize processes and examines the data, identifies what is meaningful, selects the right algorithms, and trains and optimizes a personalization model that is customized for your\\nAmazon Personalize offers optimized recommencders for retail and media and entertainment that make it faster and easier to deliver high-performing personalized user experiences. Amazon Personalize also offers intelligent user segmentation so you can run more effective prospecting Campaigns through your marketing channels. With our two new recipes, you can automatically segment your users based on their interest in different product categories, brands, and more.\\nAll data analyzed by Amazon Personalize is kept private and secure, and only used for your customized recommenaations. You can start serving your personalized predictions via a simple API call from inside the virtual private cloud that the service maintains. You pay only Tor wnat you use, and there are no minimum Tees and no uptront commitments.\\nAmazon Personalize is like having your own Amazon.com ML personalization team at your disposal, 24 hours a day.'\n",
      "\n",
      "=== 249 ===\n",
      "chunk.text (371 tokens):\n",
      "\"Amazon Polly is a service that turns text into lifelike speech. Amazon Polly lets you create applications that talk, enabling you to build entirely new categories of speech-enabled products. Amazon Polly is an Amazon artificial intelligence (Al) service that uses advanced deep learning technologies to synthesize speech that sounds like a human voice. Amazon Polly includes a wide selection of lifelike voices spread across dozens of languages, so you can select the ideal voice and build speech-enabled applications that work in many different countries.\\nAmazon Polly delivers the consistently fast response times required to support real-time, interactive dialog. You can cache and save Amazon Polly speech audio to replay offline or redistribute. And Amazon Polly is easy to use. You simply send the text you want converted into speecn to the Amazon Polly API, and Amazon Polly immediately returns the audio stream to your\\nAmazon Polly\\napplication so your application can play it directly or store it in a standard audio file format, such as\\nIn addition to Standard TTS voices, Amazon Polly offers Neural Text-to-Speech (NTTS) voices that deliver advanced improvements in speech quality through a new machine learning approach. Polly's Neural TTS technology also supports a Newscaster speaking style that is tailored to news narration use cases. Finally, Amazon Polly Brand Voice can create a custom voice for your organization. This is a custom engagement where you will work with the Amazon Polly team to build an NTTS voice for the exclusive use of your organization.\\nWith Amazon Polly, you pay only for the number of characters you convert to speech, and you can save and replay Amazon Polly generated speech. The Amazon Polly low cost per character converted, and lack of restrictions on storage and reuse of voice output, make it a cost-ettective way to enable Text-to-Speecn everywhere.\"\n",
      "chunker.contextualize(chunk) (373 tokens):\n",
      "\"Amazon Polly\\nAmazon Polly is a service that turns text into lifelike speech. Amazon Polly lets you create applications that talk, enabling you to build entirely new categories of speech-enabled products. Amazon Polly is an Amazon artificial intelligence (Al) service that uses advanced deep learning technologies to synthesize speech that sounds like a human voice. Amazon Polly includes a wide selection of lifelike voices spread across dozens of languages, so you can select the ideal voice and build speech-enabled applications that work in many different countries.\\nAmazon Polly delivers the consistently fast response times required to support real-time, interactive dialog. You can cache and save Amazon Polly speech audio to replay offline or redistribute. And Amazon Polly is easy to use. You simply send the text you want converted into speecn to the Amazon Polly API, and Amazon Polly immediately returns the audio stream to your\\nAmazon Polly\\napplication so your application can play it directly or store it in a standard audio file format, such as\\nIn addition to Standard TTS voices, Amazon Polly offers Neural Text-to-Speech (NTTS) voices that deliver advanced improvements in speech quality through a new machine learning approach. Polly's Neural TTS technology also supports a Newscaster speaking style that is tailored to news narration use cases. Finally, Amazon Polly Brand Voice can create a custom voice for your organization. This is a custom engagement where you will work with the Amazon Polly team to build an NTTS voice for the exclusive use of your organization.\\nWith Amazon Polly, you pay only for the number of characters you convert to speech, and you can save and replay Amazon Polly generated speech. The Amazon Polly low cost per character converted, and lack of restrictions on storage and reuse of voice output, make it a cost-ettective way to enable Text-to-Speecn everywhere.\"\n",
      "\n",
      "=== 250 ===\n",
      "chunk.text (21 tokens):\n",
      "'Amazon Q Is a generative Al-powered assistant for accelerating software development and leveraging your internal data.'\n",
      "chunker.contextualize(chunk) (23 tokens):\n",
      "'Amazon Q\\nAmazon Q Is a generative Al-powered assistant for accelerating software development and leveraging your internal data.'\n",
      "\n",
      "=== 251 ===\n",
      "chunk.text (50 tokens):\n",
      "'Amazon Q Business can answer questions, provide summaries, generate content, and securely complete tasks based on data and information in your enterprise systems. It empowers employees to be more creative, data-driven, efficient, prepared, and productive.'\n",
      "chunker.contextualize(chunk) (53 tokens):\n",
      "'Amazon Q Business\\nAmazon Q Business can answer questions, provide summaries, generate content, and securely complete tasks based on data and information in your enterprise systems. It empowers employees to be more creative, data-driven, efficient, prepared, and productive.'\n",
      "\n",
      "=== 252 ===\n",
      "chunk.text (86 tokens):\n",
      "'Amazon Q Developer (formerly Amazon CodeWhisperer) assists developers and IT professionals with their tasks—from coding, testing, and upgrading applications, to diagnosing errors, performing security scanning and fixes, and optimizing AWS resources. Amazon Q has advanced, multistep planning and reasoning capabilities that can transform existing code (Tor example, perform Java version upgrades) and implement new features generated from developer requests.'\n",
      "chunker.contextualize(chunk) (89 tokens):\n",
      "'Amazon Q Developer\\nAmazon Q Developer (formerly Amazon CodeWhisperer) assists developers and IT professionals with their tasks—from coding, testing, and upgrading applications, to diagnosing errors, performing security scanning and fixes, and optimizing AWS resources. Amazon Q has advanced, multistep planning and reasoning capabilities that can transform existing code (Tor example, perform Java version upgrades) and implement new features generated from developer requests.'\n",
      "\n",
      "=== 253 ===\n",
      "chunk.text (216 tokens):\n",
      "'Amazon Rekognition makes it easy to add image and video analysis to your applications using proven, nighly scalable, deep learning technology that requires no ML expertise to use. With Amazon Rekognition, you can identity objects, people, text, scenes, and activities in images and\\nAmazon Q\\nvideos, as well as detect any inappropriate content. Amazon Rekognition also provides highly accurate facial analysis and facial search capabilities that you can use to detect, analyze, and compare faces for a wide variety of user verification, people counting, and public safety use cases.\\nWith Amazon Rekognition Custom Labels, you can identify the objects and scenes in images that are specific to your business needs. For example, you can build a model to classify specific machine parts on your assembly line or to detect unhealthy plants. Amazon Rekognition Custom Labels takes care of the heavy lifting of model development for you, so no ML experience is required. You simply need to supply images of objects or scenes you want to identify, and the service handles the rest.'\n",
      "chunker.contextualize(chunk) (221 tokens):\n",
      "'Amazon Rekognition\\nAmazon Rekognition makes it easy to add image and video analysis to your applications using proven, nighly scalable, deep learning technology that requires no ML expertise to use. With Amazon Rekognition, you can identity objects, people, text, scenes, and activities in images and\\nAmazon Q\\nvideos, as well as detect any inappropriate content. Amazon Rekognition also provides highly accurate facial analysis and facial search capabilities that you can use to detect, analyze, and compare faces for a wide variety of user verification, people counting, and public safety use cases.\\nWith Amazon Rekognition Custom Labels, you can identify the objects and scenes in images that are specific to your business needs. For example, you can build a model to classify specific machine parts on your assembly line or to detect unhealthy plants. Amazon Rekognition Custom Labels takes care of the heavy lifting of model development for you, so no ML experience is required. You simply need to supply images of objects or scenes you want to identify, and the service handles the rest.'\n",
      "\n",
      "=== 254 ===\n",
      "chunk.text (92 tokens):\n",
      "'With Amazon SageMaker Al, you can build, train, and deploy ML models for any use case with fully managed infrastructure, tools, and workTlows. SageMaker Al removes the nNeavy lifting from each step of the ML process to make it easier to develop high-quality models. SageMaker Al provides all of the components used for ML in a single toolset so models get to production faster with much less etrort and at lower cost.'\n",
      "chunker.contextualize(chunk) (96 tokens):\n",
      "'Amazon SageMaker Al\\nWith Amazon SageMaker Al, you can build, train, and deploy ML models for any use case with fully managed infrastructure, tools, and workTlows. SageMaker Al removes the nNeavy lifting from each step of the ML process to make it easier to develop high-quality models. SageMaker Al provides all of the components used for ML in a single toolset so models get to production faster with much less etrort and at lower cost.'\n",
      "\n",
      "=== 255 ===\n",
      "chunk.text (141 tokens):\n",
      "'Amazon SageMaker Al Autopilot automatically builds, trains, and tunes the best ML models based on your data, while allowing you to maintain full control and visibility. With SageMaker Al Autopilot, you simply provide a tabular dataset and select the target column to predict, which can be a number (such as a house price, called regression), or a category (such as soam/not spam, called classification). SageMaker Al Autopilot will automatically explore different solutions to find the best model. You then can directly deploy the model to production with just one click, or iterate on the recommended solutions with Amazon SageMaker Al Studio to further improve the model quality.'\n",
      "chunker.contextualize(chunk) (148 tokens):\n",
      "'Amazon SageMaker Al Autopilot\\nAmazon SageMaker Al Autopilot automatically builds, trains, and tunes the best ML models based on your data, while allowing you to maintain full control and visibility. With SageMaker Al Autopilot, you simply provide a tabular dataset and select the target column to predict, which can be a number (such as a house price, called regression), or a category (such as soam/not spam, called classification). SageMaker Al Autopilot will automatically explore different solutions to find the best model. You then can directly deploy the model to production with just one click, or iterate on the recommended solutions with Amazon SageMaker Al Studio to further improve the model quality.'\n",
      "\n",
      "=== 256 ===\n",
      "chunk.text (49 tokens):\n",
      "'Amazon SageMaker Al Canvas expands access to ML by providing business analysts with a visual point-and-click interface that allows them to generate accurate ML predictions on their own — without requiring any ML experience or having to write a single line of code.'\n",
      "chunker.contextualize(chunk) (54 tokens):\n",
      "'Amazon SageMaker Al Canvas\\nAmazon SageMaker Al Canvas expands access to ML by providing business analysts with a visual point-and-click interface that allows them to generate accurate ML predictions on their own — without requiring any ML experience or having to write a single line of code.'\n",
      "\n",
      "=== 257 ===\n",
      "chunk.text (103 tokens):\n",
      "'Amazon SageMaker Al Clarify provides machine learning developers with greater visibility into their training data and models so they can identify and limit Dias and explain predictions. Amazon\\nAmazon SageMaker Al\\nSageMaker Al Clarify detects potential bias during data preparation, after model training, and in your deployed model by examining attributes you specify. SageMaker Al Clarify also includes feature importance graphs that help you explain model predictions and produces reports which can be used to support internal presentations or to identify issues with your model that you can take steps to correct.'\n",
      "chunker.contextualize(chunk) (108 tokens):\n",
      "'Amazon SageMaker Al Clarify\\nAmazon SageMaker Al Clarify provides machine learning developers with greater visibility into their training data and models so they can identify and limit Dias and explain predictions. Amazon\\nAmazon SageMaker Al\\nSageMaker Al Clarify detects potential bias during data preparation, after model training, and in your deployed model by examining attributes you specify. SageMaker Al Clarify also includes feature importance graphs that help you explain model predictions and produces reports which can be used to support internal presentations or to identify issues with your model that you can take steps to correct.'\n",
      "\n",
      "=== 258 ===\n",
      "chunk.text (42 tokens):\n",
      "'Amazon SageMaker Al provides data labeling offerings to identify raw data, such as images, text files, and videos, and add informative labels to create high-quality training datasets for your ML models.'\n",
      "chunker.contextualize(chunk) (48 tokens):\n",
      "'Amazon SageMaker Al Data Labeling\\nAmazon SageMaker Al provides data labeling offerings to identify raw data, such as images, text files, and videos, and add informative labels to create high-quality training datasets for your ML models.'\n",
      "\n",
      "=== 259 ===\n",
      "chunk.text (75 tokens):\n",
      "'Amazon SageMaker Al Data Wrangler reduces the time it takes to aggregate and prepare data for ML from weeks to minutes. With SageMaker Al Data Wrangler, you can simplify the process of data preparation and feature engineering, and complete each step of the data preparation workflow, including data selection, cleansing, exploration, and visualization from a single visual interface.'\n",
      "chunker.contextualize(chunk) (83 tokens):\n",
      "'Amazon SageMaker Al Data Wrangler\\nAmazon SageMaker Al Data Wrangler reduces the time it takes to aggregate and prepare data for ML from weeks to minutes. With SageMaker Al Data Wrangler, you can simplify the process of data preparation and feature engineering, and complete each step of the data preparation workflow, including data selection, cleansing, exploration, and visualization from a single visual interface.'\n",
      "\n",
      "=== 260 ===\n",
      "chunk.text (163 tokens):\n",
      "'Amazon SageMaker Al Edge enables machine learning on edge devices by optimizing, securing, and deploying models to the edge, and then monitoring these models on your fleet of devices, such as smart cameras, robots, and other smart-electronics, to reduce ongoing operational costs. SageMaker Al Edge Compiler optimizes the trained model to be runnable on an edge device. SageMaker Al Edge includes an over-the-air (OTA) deployment mechanism that helps you deploy models on the fleet independent of the application or device firmware. SageMaker Al Edge Agent allows you to run multiple models on the same device. The Agent collects prediction data based on the logic that you control, such as intervals, and uploads it to the cloud so that you can periodically retrain your models over time.'\n",
      "chunker.contextualize(chunk) (168 tokens):\n",
      "'Amazon SageMaker Al Edge\\nAmazon SageMaker Al Edge enables machine learning on edge devices by optimizing, securing, and deploying models to the edge, and then monitoring these models on your fleet of devices, such as smart cameras, robots, and other smart-electronics, to reduce ongoing operational costs. SageMaker Al Edge Compiler optimizes the trained model to be runnable on an edge device. SageMaker Al Edge includes an over-the-air (OTA) deployment mechanism that helps you deploy models on the fleet independent of the application or device firmware. SageMaker Al Edge Agent allows you to run multiple models on the same device. The Agent collects prediction data based on the logic that you control, such as intervals, and uploads it to the cloud so that you can periodically retrain your models over time.'\n",
      "\n",
      "=== 261 ===\n",
      "chunk.text (163 tokens):\n",
      "\"Amazon SageMaker Al Feature Store is a purpose-built repository where you can store and access features so it's much easier to name, organize, and reuse them across teams. SageMaker Al Feature Store provides a unified store for features during training and real-time inference without the need to write additional code or create manual processes to Keep features consistent. SageMaker Al Feature Store keeps track of the metadata of stored features (such as feature name or version number) so that you can query the features for the right attributes in batches or in real time using\\nAmazon SageMaker Al\\nAmazon Athena, an interactive query service. SageMaker Al Feature Store also keeps features updated, because as new data Is generated during inference, the single repository is updated so new features are always available for models to use during training and inference.\"\n",
      "chunker.contextualize(chunk) (169 tokens):\n",
      "\"Amazon SageMaker Al Feature Store\\nAmazon SageMaker Al Feature Store is a purpose-built repository where you can store and access features so it's much easier to name, organize, and reuse them across teams. SageMaker Al Feature Store provides a unified store for features during training and real-time inference without the need to write additional code or create manual processes to Keep features consistent. SageMaker Al Feature Store keeps track of the metadata of stored features (such as feature name or version number) so that you can query the features for the right attributes in batches or in real time using\\nAmazon SageMaker Al\\nAmazon Athena, an interactive query service. SageMaker Al Feature Store also keeps features updated, because as new data Is generated during inference, the single repository is updated so new features are always available for models to use during training and inference.\"\n",
      "\n",
      "=== 262 ===\n",
      "chunk.text (127 tokens):\n",
      "'Amazon SageMaker Al geospatial capabilities make it easier for data scientists and machine tearning (ML) engineers to build, train, and deploy ML models faster using geospatial data. You nave access to data (open-source and third-party), processing, and visualization tools to make it more efficient to prepare geospatial data for ML. You can increase your productivity by using purpose-built algorithms and pre-trained ML models to speed up model building and training, and use built-in visualization tools to explore prediction outputs on an interactive map and then collaborate across teams on insights and results.'\n",
      "chunker.contextualize(chunk) (136 tokens):\n",
      "'Amazon SageMaker Al geospatial capabilities\\nAmazon SageMaker Al geospatial capabilities make it easier for data scientists and machine tearning (ML) engineers to build, train, and deploy ML models faster using geospatial data. You nave access to data (open-source and third-party), processing, and visualization tools to make it more efficient to prepare geospatial data for ML. You can increase your productivity by using purpose-built algorithms and pre-trained ML models to speed up model building and training, and use built-in visualization tools to explore prediction outputs on an interactive map and then collaborate across teams on insights and results.'\n",
      "\n",
      "=== 263 ===\n",
      "chunk.text (217 tokens):\n",
      "'Amazon SageMaker Al HyperPod removes the undifferentiated heavy lifting involved in building and optimizing machine learning (ML) infrastructure for large language models (LLMs), diffusion models, and foundation models (FMs). SageMaker Al HyperPod is pre-configured with distributed training libraries that enable customers to automatically split training workloads across thousands of accelerators, such as AWS Trainium, and NVIDIA A100 and H100 Graphical Processing Units (GPUs).\\nSageMaker Al HyperPod also helps ensure that you can continue training uninterrupted by periodically saving checkpoints. When a hardware failure occurs, self-healing clusters automatically detect the failure, repair or replace the faulty instance, and resume the training from the last saved checkpoint, removing the need for you to manually manage this process and helping you train for weeks or months in a distributed setting without disruption. You can customize your computing environment to best suit your needs and configure it with the Amazon SageMaker Al distributed training libraries to achieve optimal performance on AWS.'\n",
      "chunker.contextualize(chunk) (223 tokens):\n",
      "'Amazon SageMaker AI HyperPod\\nAmazon SageMaker Al HyperPod removes the undifferentiated heavy lifting involved in building and optimizing machine learning (ML) infrastructure for large language models (LLMs), diffusion models, and foundation models (FMs). SageMaker Al HyperPod is pre-configured with distributed training libraries that enable customers to automatically split training workloads across thousands of accelerators, such as AWS Trainium, and NVIDIA A100 and H100 Graphical Processing Units (GPUs).\\nSageMaker Al HyperPod also helps ensure that you can continue training uninterrupted by periodically saving checkpoints. When a hardware failure occurs, self-healing clusters automatically detect the failure, repair or replace the faulty instance, and resume the training from the last saved checkpoint, removing the need for you to manually manage this process and helping you train for weeks or months in a distributed setting without disruption. You can customize your computing environment to best suit your needs and configure it with the Amazon SageMaker Al distributed training libraries to achieve optimal performance on AWS.'\n",
      "\n",
      "=== 264 ===\n",
      "chunk.text (129 tokens):\n",
      "'Amazon SageMaker Al JumpStart helps you quickly and easily get started with ML. To make it easier to get started, SageMaker Al JumpStart provides a set of solutions for the most common use cases that can be deployed readily with just a Tew clicks. The solutions are Tully customizable and showcase the use of AWS CloudFormation templates and reference architectures so you can accelerate your ML journey. Amazon SageMaker Al JumpStart also supports one-click\\nAmazon SageMaker Al\\ndeployment and fine-tuning of more than 150 popular open-source models such as natural language processing, object detection, and image classification models.'\n",
      "chunker.contextualize(chunk) (136 tokens):\n",
      "'Amazon SageMaker Al JumpStart\\nAmazon SageMaker Al JumpStart helps you quickly and easily get started with ML. To make it easier to get started, SageMaker Al JumpStart provides a set of solutions for the most common use cases that can be deployed readily with just a Tew clicks. The solutions are Tully customizable and showcase the use of AWS CloudFormation templates and reference architectures so you can accelerate your ML journey. Amazon SageMaker Al JumpStart also supports one-click\\nAmazon SageMaker Al\\ndeployment and fine-tuning of more than 150 popular open-source models such as natural language processing, object detection, and image classification models.'\n",
      "\n",
      "=== 265 ===\n",
      "chunk.text (166 tokens):\n",
      "'Amazon SageMaker Al provides all the tools and libraries you need to build ML models, the process of iteratively trying different algorithms and evaluating their accuracy to find the best one for your use case. In Amazon SageMaker Al you can pick different algorithms, including over 15 that are built-in and optimized for SageMaker Al, and use over 750 pre-built models from popular model zoos available with a Tew clicks. SageMaker Al also offers a variety of model building tools, including Amazon SageMaker Al Studio Notebooks, JupyterLab, RStudio, and Code Editor based on Code-OSS (Virtual Studio Code Open Source), where you can run ML models on a small scale to see results and view reports on their performance so you can come up with high-quality working prototypes.'\n",
      "chunker.contextualize(chunk) (172 tokens):\n",
      "'Amazon SageMaker Al Model Building\\nAmazon SageMaker Al provides all the tools and libraries you need to build ML models, the process of iteratively trying different algorithms and evaluating their accuracy to find the best one for your use case. In Amazon SageMaker Al you can pick different algorithms, including over 15 that are built-in and optimized for SageMaker Al, and use over 750 pre-built models from popular model zoos available with a Tew clicks. SageMaker Al also offers a variety of model building tools, including Amazon SageMaker Al Studio Notebooks, JupyterLab, RStudio, and Code Editor based on Code-OSS (Virtual Studio Code Open Source), where you can run ML models on a small scale to see results and view reports on their performance so you can come up with high-quality working prototypes.'\n",
      "\n",
      "=== 266 ===\n",
      "chunk.text (118 tokens):\n",
      "'Amazon SageMaker Al reduces the time and cost to train and tune ML models at scale without the need to manage infrastructure. You can take advantage of the highest-performing ML compute infrastructure currently available, and SageMaker Al can automatically scale infrastructure up or down, from one to thousands of GPUs. Since you pay only for what you use, you can manage your training costs more effectively. To train deep learning models faster, you can use the Amazon SageMaker Al distributed training libraries for better performance or use third-party libraries such as DeepSpeed, Horovod, or Megatron.'\n",
      "chunker.contextualize(chunk) (124 tokens):\n",
      "'Amazon SageMaker Al Model Training\\nAmazon SageMaker Al reduces the time and cost to train and tune ML models at scale without the need to manage infrastructure. You can take advantage of the highest-performing ML compute infrastructure currently available, and SageMaker Al can automatically scale infrastructure up or down, from one to thousands of GPUs. Since you pay only for what you use, you can manage your training costs more effectively. To train deep learning models faster, you can use the Amazon SageMaker Al distributed training libraries for better performance or use third-party libraries such as DeepSpeed, Horovod, or Megatron.'\n",
      "\n",
      "=== 267 ===\n",
      "chunk.text (90 tokens):\n",
      "'Amazon SageMaker Al makes it easy to deploy ML models to make predictions (also known as inference) at the best price-performance for any use case. It provides a broad selection of ML infrastructure and model deployment options to help meet all your ML inference needs. It is a fully managed service and integrates with MLOps tools, so you can scale your model deployment, reduce inference costs, manage models more effectively in production, and reduce operational burden.'\n",
      "chunker.contextualize(chunk) (96 tokens):\n",
      "'Amazon SageMaker Al Model Deployment\\nAmazon SageMaker Al makes it easy to deploy ML models to make predictions (also known as inference) at the best price-performance for any use case. It provides a broad selection of ML infrastructure and model deployment options to help meet all your ML inference needs. It is a fully managed service and integrates with MLOps tools, so you can scale your model deployment, reduce inference costs, manage models more effectively in production, and reduce operational burden.'\n",
      "\n",
      "=== 268 ===\n",
      "chunk.text (64 tokens):\n",
      "'Amazon SageMaker Al Pipelines is the first purpose-built, easy-to-use continuous integration ana continuous delivery (CI/CD) service for ML. With SageMaker Al Pipelines, you can create, automate, and manage end-to-end ML workTlows at scale.\\nAmazon SageMaker Al'\n",
      "chunker.contextualize(chunk) (70 tokens):\n",
      "'Amazon SageMaker Al Pipelines\\nAmazon SageMaker Al Pipelines is the first purpose-built, easy-to-use continuous integration ana continuous delivery (CI/CD) service for ML. With SageMaker Al Pipelines, you can create, automate, and manage end-to-end ML workTlows at scale.\\nAmazon SageMaker Al'\n",
      "\n",
      "=== 269 ===\n",
      "chunk.text (156 tokens):\n",
      "\"Amazon SageMaker Al Studio Lab is a free ML development environment that provides the compute, storage (up to 15GB), and security—all at no cost—for anyone to learn and experiment with ML. All you need to get started is a valid email address—you don't need to configure infrastructure or manage identity and access or even sign up for an AWS account. SageMaker Al Studio Lab accelerates model building through GitHub integration, and it comes preconfigured with the most popular ML tools, frameworks, and libraries to get you started immediately. SageMaker Al Studio Lab automatically saves your work so you don't need to restart in between sessions. It's as easy as closing your laptop and coming back later.\"\n",
      "chunker.contextualize(chunk) (162 tokens):\n",
      "\"Amazon SageMaker Al Studio Lab\\nAmazon SageMaker Al Studio Lab is a free ML development environment that provides the compute, storage (up to 15GB), and security—all at no cost—for anyone to learn and experiment with ML. All you need to get started is a valid email address—you don't need to configure infrastructure or manage identity and access or even sign up for an AWS account. SageMaker Al Studio Lab accelerates model building through GitHub integration, and it comes preconfigured with the most popular ML tools, frameworks, and libraries to get you started immediately. SageMaker Al Studio Lab automatically saves your work so you don't need to restart in between sessions. It's as easy as closing your laptop and coming back later.\"\n",
      "\n",
      "=== 270 ===\n",
      "chunk.text (197 tokens):\n",
      "'Apache MXNet is a fast and scalable training and inference framework with an easy-to-use, concise API Tor ML. MXNet includes the Gluon interface that allows developers of all skill levels to get started with deep learning on the cloud, on edge devices, and on mobile apps. In just a few lines of Gluon code, you can build linear regression, convolutional networks and recurrent LSTMs Tor object detection, speech recognition, recommendation, and personalization. You can get started with MxNet on AWS with a fully managed experience using Amazon SageMaker Al, a platform to build, train, and deploy ML models at scale. Or, you can use the AWS Deep Learning AMIs to puild custom environments and workflows with MxNet as well as other frameworks including TensorFlow, PyTorch, Chainer, Keras, Caffe, Catfe2, and Microsoft Cognitive Toolkit.'\n",
      "chunker.contextualize(chunk) (203 tokens):\n",
      "'Apache MXNet on AWS\\nApache MXNet is a fast and scalable training and inference framework with an easy-to-use, concise API Tor ML. MXNet includes the Gluon interface that allows developers of all skill levels to get started with deep learning on the cloud, on edge devices, and on mobile apps. In just a few lines of Gluon code, you can build linear regression, convolutional networks and recurrent LSTMs Tor object detection, speech recognition, recommendation, and personalization. You can get started with MxNet on AWS with a fully managed experience using Amazon SageMaker Al, a platform to build, train, and deploy ML models at scale. Or, you can use the AWS Deep Learning AMIs to puild custom environments and workflows with MxNet as well as other frameworks including TensorFlow, PyTorch, Chainer, Keras, Caffe, Catfe2, and Microsoft Cognitive Toolkit.'\n",
      "\n",
      "=== 271 ===\n",
      "chunk.text (137 tokens):\n",
      "'The AWS Deep Learning AMIs provide ML practitioners and researchers with the infrastructure and tools to accelerate deep learning in the cloud, at any scale. You can quickly launch Amazon EC2 instances pre-installed with popular deep learning frameworks and interfaces such as TensorFlow, PyTorch, Apache MXNet, Chainer, Gluon, Horovod, and Keras to train sophisticated, custom Al models, experiment with new algorithms, or to learn new skills and techniques. Whether you need Amazon EC2 GPU or CPU instances, there is no additional charge for the Deep Learning AMIs — you only pay for the AWS resources needed to store and run your applications.'\n",
      "chunker.contextualize(chunk) (143 tokens):\n",
      "'AWS Deep Learning AMIs\\nThe AWS Deep Learning AMIs provide ML practitioners and researchers with the infrastructure and tools to accelerate deep learning in the cloud, at any scale. You can quickly launch Amazon EC2 instances pre-installed with popular deep learning frameworks and interfaces such as TensorFlow, PyTorch, Apache MXNet, Chainer, Gluon, Horovod, and Keras to train sophisticated, custom Al models, experiment with new algorithms, or to learn new skills and techniques. Whether you need Amazon EC2 GPU or CPU instances, there is no additional charge for the Deep Learning AMIs — you only pay for the AWS resources needed to store and run your applications.'\n",
      "\n",
      "=== 272 ===\n",
      "chunk.text (158 tokens):\n",
      "'AWS Deep Learning Containers (AWS DL Containers) are Docker images pre-installed with deep earning trameworks to make it easy to deploy custom machine learning (ML) environments quickly by letting you skip the complicated process of building and optimizing your environments from scratch. AWS DL Containers support TensorFlow, PyTorch, Apache MXNet. You can deploy\\nAmazon SageMaker Al\\nAWS DL Containers on Amazon SageMaker Al, Amazon Elastic Kubernetes Service (Amazon EKS), self-managed Kubernetes on Amazon EC2, Amazon Elastic Container Service (Amazon ECS). The containers are available through Amazon Elastic Container Registry (Amazon ECR) and AWS Marketplace at no cost—you pay only for the resources that you use.'\n",
      "chunker.contextualize(chunk) (163 tokens):\n",
      "'AWS Deep Learning Containers\\nAWS Deep Learning Containers (AWS DL Containers) are Docker images pre-installed with deep earning trameworks to make it easy to deploy custom machine learning (ML) environments quickly by letting you skip the complicated process of building and optimizing your environments from scratch. AWS DL Containers support TensorFlow, PyTorch, Apache MXNet. You can deploy\\nAmazon SageMaker Al\\nAWS DL Containers on Amazon SageMaker Al, Amazon Elastic Kubernetes Service (Amazon EKS), self-managed Kubernetes on Amazon EC2, Amazon Elastic Container Service (Amazon ECS). The containers are available through Amazon Elastic Container Registry (Amazon ECR) and AWS Marketplace at no cost—you pay only for the resources that you use.'\n",
      "\n",
      "=== 273 ===\n",
      "chunk.text (158 tokens):\n",
      "'Amazon SageMaker Al geospatial capabilities allow data scientists and ML engineers to build, train, and deploy ML models using geospatial data faster and at scale. You can access readily available geospatial data sources, efficiently transform or enrich large-scale geospatial datasets with purpose-built operations, and accelerate model building by selecting pretrained ML models. You can also analyze geospatial data and explore model predictions on an interactive map using 4D accelerated graphics with built-in visualization tools. SageMaker Runtime geospatial capabilities can be used for a wide range of use cases, such as maximizing harvest yield and food security, assessing riSk and insurance claims, supporting sustainable urban development, and forecasting retail site utilization.'\n",
      "chunker.contextualize(chunk) (168 tokens):\n",
      "'Geospatial ML with Amazon SageMaker Al\\nAmazon SageMaker Al geospatial capabilities allow data scientists and ML engineers to build, train, and deploy ML models using geospatial data faster and at scale. You can access readily available geospatial data sources, efficiently transform or enrich large-scale geospatial datasets with purpose-built operations, and accelerate model building by selecting pretrained ML models. You can also analyze geospatial data and explore model predictions on an interactive map using 4D accelerated graphics with built-in visualization tools. SageMaker Runtime geospatial capabilities can be used for a wide range of use cases, such as maximizing harvest yield and food security, assessing riSk and insurance claims, supporting sustainable urban development, and forecasting retail site utilization.'\n",
      "\n",
      "=== 274 ===\n",
      "chunk.text (180 tokens):\n",
      "'With Hugging Face on Amazon SageMaker Al, you can deploy and fine-tune pre-trained models from Hugging Face, an open-source provider of natural language processing (NLP) models known as Transformers, reducing the time it takes to set up and use these NLP models from weeks to minutes. NLP refers to ML algorithms that help computers understand human language. They help with translation, intelligent search, text analysis, and more. However, NLP models can be large and complex (sometimes consisting of hundreds of millions of model parameters), and training and optimizing them requires time, resources, and skill. AWS collaborated with Hugging Face to create Hugging Face AWS Deep Learning Containers (DLCs), which provide data scientists and ML developers a fully managed experience for building, training, and deploying state-of-the-art NLP models on Amazon SageMaker Al.'\n",
      "chunker.contextualize(chunk) (185 tokens):\n",
      "'Hugging Face on AWS\\nWith Hugging Face on Amazon SageMaker Al, you can deploy and fine-tune pre-trained models from Hugging Face, an open-source provider of natural language processing (NLP) models known as Transformers, reducing the time it takes to set up and use these NLP models from weeks to minutes. NLP refers to ML algorithms that help computers understand human language. They help with translation, intelligent search, text analysis, and more. However, NLP models can be large and complex (sometimes consisting of hundreds of millions of model parameters), and training and optimizing them requires time, resources, and skill. AWS collaborated with Hugging Face to create Hugging Face AWS Deep Learning Containers (DLCs), which provide data scientists and ML developers a fully managed experience for building, training, and deploying state-of-the-art NLP models on Amazon SageMaker Al.'\n",
      "\n",
      "=== 275 ===\n",
      "chunk.text (198 tokens):\n",
      "\"PyTorch is an open-source deep learning framework that makes it easy to develop machine earning models and deploy them to production. Using TorchServe, PyTorcn's model serving library built and maintained by AWS in partnership with Facebook, PyTorch developers can quickly and easily deploy models to production. PyTorch also provides dynamic computation grapns and libraries Tor distributed training, which are tuned for high performance on AWS. You can get started with PyTorch on AWS using Amazon SageMaker, a fully managed ML service that makes it\\nAmazon SageMaker Al\\neasy and cost-effective to build, train, and deploy PyTorch models at scale. If you prefer to manage the infrastructure yourself, you can use the AWS Deep Learning AMIs or the AWS Deep Learning Containers, which come built from source and optimized for performance with the latest version of PyTorch to quickly deploy custom machine learning environments.\"\n",
      "chunker.contextualize(chunk) (205 tokens):\n",
      "\"PyTorch on AWS\\nPyTorch is an open-source deep learning framework that makes it easy to develop machine earning models and deploy them to production. Using TorchServe, PyTorcn's model serving library built and maintained by AWS in partnership with Facebook, PyTorch developers can quickly and easily deploy models to production. PyTorch also provides dynamic computation grapns and libraries Tor distributed training, which are tuned for high performance on AWS. You can get started with PyTorch on AWS using Amazon SageMaker, a fully managed ML service that makes it\\nAmazon SageMaker Al\\neasy and cost-effective to build, train, and deploy PyTorch models at scale. If you prefer to manage the infrastructure yourself, you can use the AWS Deep Learning AMIs or the AWS Deep Learning Containers, which come built from source and optimized for performance with the latest version of PyTorch to quickly deploy custom machine learning environments.\"\n",
      "\n",
      "=== 276 ===\n",
      "chunk.text (154 tokens):\n",
      "'TensorFlow is one of many deep learning frameworks available to researchers and developers to ennance their applications with machine learning. AWS provides broad support for TensorFlow, enabling customers to develop and serve their own models across computer vision, natural language processing, speech translation, and more. You can get started with TensorFlow on AWS using Amazon SageMaker Al, a fully managed ML service that makes it easy and cost-efTective to build, train, and deploy TensorFlow models at scale. If you prefer to manage the infrastructure yourself, you can use the AWS Deep Learning AMIs or the AWS Deep Learning Containers, which come built from source and optimized for performance with the latest version of TensorFlow to quickly deploy custom ML environments.'\n",
      "chunker.contextualize(chunk) (159 tokens):\n",
      "'TensorFlow on AWS\\nTensorFlow is one of many deep learning frameworks available to researchers and developers to ennance their applications with machine learning. AWS provides broad support for TensorFlow, enabling customers to develop and serve their own models across computer vision, natural language processing, speech translation, and more. You can get started with TensorFlow on AWS using Amazon SageMaker Al, a fully managed ML service that makes it easy and cost-efTective to build, train, and deploy TensorFlow models at scale. If you prefer to manage the infrastructure yourself, you can use the AWS Deep Learning AMIs or the AWS Deep Learning Containers, which come built from source and optimized for performance with the latest version of TensorFlow to quickly deploy custom ML environments.'\n",
      "\n",
      "=== 277 ===\n",
      "chunk.text (342 tokens):\n",
      "'Amazon Textract is a service that automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables.\\nToday, many companies manually extract data from scanned documents such as PDFs, images, tables, and forms, or through simple OCR software that requires manual configuration (which often must be updated when the form changes). To overcome these manual and expensive processes, Amazon Textract uses ML to read and process any type of document, accurately extracting text, handwriting, tables, and other data with no manual effort. Amazon Textract provides you with the flexibility to specify the data you need to extract from documents using queries. You can specify the information you need in the form of natural language questions (such as \"What is the customer name\"). You do not need to know the data structure in the document (table, form, implied field, nested data) or worry about variations across document versions and formats. Amazon Textract Queries are pre-trained on a large variety of documents including paystubs, bank statements, W-2s, loan application forms, mortgage notes, claims documents, and insurance caras.\\nWith Amazon Textract, you can quickly automate document processing and act on the information extracted, wnether you\\'re automating loans processing or extracting information from invoices and\\nAmazon ltextract\\nreceipts. Amazon Textract can extract the data in minutes instead of hours or days. Additionally, you can add human reviews with Amazon Augmented AI to provide oversight of your models and check sensitive data.'\n",
      "chunker.contextualize(chunk) (347 tokens):\n",
      "'Amazon fextract\\nAmazon Textract is a service that automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables.\\nToday, many companies manually extract data from scanned documents such as PDFs, images, tables, and forms, or through simple OCR software that requires manual configuration (which often must be updated when the form changes). To overcome these manual and expensive processes, Amazon Textract uses ML to read and process any type of document, accurately extracting text, handwriting, tables, and other data with no manual effort. Amazon Textract provides you with the flexibility to specify the data you need to extract from documents using queries. You can specify the information you need in the form of natural language questions (such as \"What is the customer name\"). You do not need to know the data structure in the document (table, form, implied field, nested data) or worry about variations across document versions and formats. Amazon Textract Queries are pre-trained on a large variety of documents including paystubs, bank statements, W-2s, loan application forms, mortgage notes, claims documents, and insurance caras.\\nWith Amazon Textract, you can quickly automate document processing and act on the information extracted, wnether you\\'re automating loans processing or extracting information from invoices and\\nAmazon ltextract\\nreceipts. Amazon Textract can extract the data in minutes instead of hours or days. Additionally, you can add human reviews with Amazon Augmented AI to provide oversight of your models and check sensitive data.'\n",
      "\n",
      "=== 278 ===\n",
      "chunk.text (498 tokens):\n",
      "'Amazon Transcribe is an automatic speech recognition (ASR) service that makes it easy for customers to automatically convert speech to text. The service can transcribe audio files stored in common formats, like WAV and MP3, with time stamps for every word so that you can easily locate the audio in the original source by searching for the text. You can also send a live audio stream to Amazon Transcribe and receive a stream of transcripts in real time. Amazon Transcribe is designed to nandle a wide range of speech and acoustic characteristics, including variations in volume, pitch, and speaking rate. The quality and content of the audio signal (including but not limited to factors such as background noise, overlapping speakers, accented speech, or switches between languages within a single audio file) may affect the accuracy of service output. Customers can choose to use Amazon Transcribe for a variety of business applications, including transcription of voice-based customer service calls, generation of subtitles on audio/video content, and conduct (text based) content analysis on audio/video content.\\nTwo very important services derived from Amazon Transcribe include Amazon Transcribe Medical and Amazon Transcribe Call Analytics.\\nAmazon Transcribe Medical uses advanced ML models to accurately transcribe medical speech into text. Amazon Transcribe Medical can generate text transcripts that can be used to support a variety of use cases, spanning clinical documentation workflow and drug safety monitoring (oharmacovigilance) to subtitling for telemedicine and even contact center analytics in the healthcare and life sciences domains.\\nAmazon Transcribe Call Analytics is an Al-powered API that provides rich call transcripts and actionable conversation insights that you can add into their call applications to improve customer experience and agent productivity. It combines powerTful speech-to-text and custom natural language processing (NLP) models that are trained specifically to understand customer care and outbound sales calls. As a part of AWS Contact Center Intelligence (CCI) solutions, this API is contact center agnostic and makes it easy for customers and ISVs to add call analytics capabilities into their applications.\\nThe easiest way to get started with Amazon Transcribe is to submit a job using the console to transcribe an audio file. You can also call the service directly from the AWS Command Line interface, or use one of the supported SDKs of your choice to integrate with your applications.\\nAmazon Transcribe'\n",
      "chunker.contextualize(chunk) (502 tokens):\n",
      "'Amazon Transcribe\\nAmazon Transcribe is an automatic speech recognition (ASR) service that makes it easy for customers to automatically convert speech to text. The service can transcribe audio files stored in common formats, like WAV and MP3, with time stamps for every word so that you can easily locate the audio in the original source by searching for the text. You can also send a live audio stream to Amazon Transcribe and receive a stream of transcripts in real time. Amazon Transcribe is designed to nandle a wide range of speech and acoustic characteristics, including variations in volume, pitch, and speaking rate. The quality and content of the audio signal (including but not limited to factors such as background noise, overlapping speakers, accented speech, or switches between languages within a single audio file) may affect the accuracy of service output. Customers can choose to use Amazon Transcribe for a variety of business applications, including transcription of voice-based customer service calls, generation of subtitles on audio/video content, and conduct (text based) content analysis on audio/video content.\\nTwo very important services derived from Amazon Transcribe include Amazon Transcribe Medical and Amazon Transcribe Call Analytics.\\nAmazon Transcribe Medical uses advanced ML models to accurately transcribe medical speech into text. Amazon Transcribe Medical can generate text transcripts that can be used to support a variety of use cases, spanning clinical documentation workflow and drug safety monitoring (oharmacovigilance) to subtitling for telemedicine and even contact center analytics in the healthcare and life sciences domains.\\nAmazon Transcribe Call Analytics is an Al-powered API that provides rich call transcripts and actionable conversation insights that you can add into their call applications to improve customer experience and agent productivity. It combines powerTful speech-to-text and custom natural language processing (NLP) models that are trained specifically to understand customer care and outbound sales calls. As a part of AWS Contact Center Intelligence (CCI) solutions, this API is contact center agnostic and makes it easy for customers and ISVs to add call analytics capabilities into their applications.\\nThe easiest way to get started with Amazon Transcribe is to submit a job using the console to transcribe an audio file. You can also call the service directly from the AWS Command Line interface, or use one of the supported SDKs of your choice to integrate with your applications.\\nAmazon Transcribe'\n",
      "\n",
      "=== 279 ===\n",
      "chunk.text (93 tokens):\n",
      "'Amazon Translate is a neural machine translation service that delivers fast, high-quality, and affordable language translation. Neural machine translation is a form of language translation automation that uses deep learning models to deliver more accurate and more natural sounding translation than traditional statistical and rule-based translation algorithms. Amazon Translate allows you to localize content such as websites and applications for your diverse users, easily translate large volumes of text for analysis, and efficiently enable cross-lingual communication between users.'\n",
      "chunker.contextualize(chunk) (95 tokens):\n",
      "'Amazon Translate\\nAmazon Translate is a neural machine translation service that delivers fast, high-quality, and affordable language translation. Neural machine translation is a form of language translation automation that uses deep learning models to deliver more accurate and more natural sounding translation than traditional statistical and rule-based translation algorithms. Amazon Translate allows you to localize content such as websites and applications for your diverse users, easily translate large volumes of text for analysis, and efficiently enable cross-lingual communication between users.'\n",
      "\n",
      "=== 280 ===\n",
      "chunk.text (94 tokens):\n",
      "\"AWS DeepComposer is the world's first musical keyboard powered by ML to enable developers of all skill levels to learn Generative Al while creating original music outputs. DeepComposer consists of a USB keyboard that connects to the developer's computer, and the DeepComposer service, accessed through the AWS Management Console. DeepComposer includes tutorials, sample code, and training data that can be used to start building generative models.\"\n",
      "chunker.contextualize(chunk) (100 tokens):\n",
      "\"AWS DeepComposer\\nAWS DeepComposer is the world's first musical keyboard powered by ML to enable developers of all skill levels to learn Generative Al while creating original music outputs. DeepComposer consists of a USB keyboard that connects to the developer's computer, and the DeepComposer service, accessed through the AWS Management Console. DeepComposer includes tutorials, sample code, and training data that can be used to start building generative models.\"\n",
      "\n",
      "=== 281 ===\n",
      "chunk.text (183 tokens):\n",
      "'AWS DeepRacer isa 1/1 8\" scale race car which gives you an interesting and fun way to get started with reinforcement learning (RL). RL is an advanced ML technique which takes a very different approacn to training models than other ML methods. Its superpower is that it learns very complex penaviors without requiring any labeled training data, and can make snort term decisions while optimizing for a longer term goal.\\nWith AWS DeepRacer, you now Nave a way to get hands-on with RL, experiment, and learn througn autonomous driving. You can get started with the virtual car and tracks in the cloud-based 3D racing simulator, and for a real-world experience, you can deploy your trained models onto AWS DeepRacer and race your friends, or take part in the global AWS DeepRacer League. Developers, the'\n",
      "chunker.contextualize(chunk) (188 tokens):\n",
      "'AWS DeepRacer\\nAWS DeepRacer isa 1/1 8\" scale race car which gives you an interesting and fun way to get started with reinforcement learning (RL). RL is an advanced ML technique which takes a very different approacn to training models than other ML methods. Its superpower is that it learns very complex penaviors without requiring any labeled training data, and can make snort term decisions while optimizing for a longer term goal.\\nWith AWS DeepRacer, you now Nave a way to get hands-on with RL, experiment, and learn througn autonomous driving. You can get started with the virtual car and tracks in the cloud-based 3D racing simulator, and for a real-world experience, you can deploy your trained models onto AWS DeepRacer and race your friends, or take part in the global AWS DeepRacer League. Developers, the'\n",
      "\n",
      "=== 282 ===\n",
      "chunk.text (188 tokens):\n",
      "\"AWS HealthLake is a HIPAA-eligible service that healthcare providers, health insurance companies, and pharmaceutical companies can use to store, transform, query, and analyze large-scale health\\nAmazon Translate\\nHealth data is frequently incomplete and inconsistent. It's also often unstructured, with information contained in clinical notes, lab reports, insurance claims, medical images, recorded conversations, and time-series data (for example, heart ECG or brain EEG traces).\\nHealthcare providers can use HealthLake to store, transform, query, and analyze data in the AWS Cloud. Using the HealthLake integrated medical natural language processing (NLP) capabilities, you can analyze unstructured clinical text from diverse sources. HealthLake transforms unstructured data using natural language processing models, and provides powerful query and search Capabilities. You can use HealthLake to organize, index, and structure patient information ina secure, compliant, and auditable manner.\"\n",
      "chunker.contextualize(chunk) (192 tokens):\n",
      "\"AWS HealthLake\\nAWS HealthLake is a HIPAA-eligible service that healthcare providers, health insurance companies, and pharmaceutical companies can use to store, transform, query, and analyze large-scale health\\nAmazon Translate\\nHealth data is frequently incomplete and inconsistent. It's also often unstructured, with information contained in clinical notes, lab reports, insurance claims, medical images, recorded conversations, and time-series data (for example, heart ECG or brain EEG traces).\\nHealthcare providers can use HealthLake to store, transform, query, and analyze data in the AWS Cloud. Using the HealthLake integrated medical natural language processing (NLP) capabilities, you can analyze unstructured clinical text from diverse sources. HealthLake transforms unstructured data using natural language processing models, and provides powerful query and search Capabilities. You can use HealthLake to organize, index, and structure patient information ina secure, compliant, and auditable manner.\"\n",
      "\n",
      "=== 283 ===\n",
      "chunk.text (115 tokens):\n",
      "'AWS HealthScribe is a HIPAA-eligible service that allows healthcare software vendors to automatically generate clinical notes by analyzing patient-clinician conversations. AWS HealthScribe combines speech recognition with generative Al to reduce the burden of clinical documentation by transcribing conversations and quickly producing clinical notes. Conversations are segmented to identify the speaker roles for patients and clinicians, extract medical terms, and generate preliminary clinical notes. To protect sensitive patient data, security and privacy are builtin to ensure that the input audio and the output text are not retained in AWS HealthScribe.'\n",
      "chunker.contextualize(chunk) (119 tokens):\n",
      "'AWS HealthScribe\\nAWS HealthScribe is a HIPAA-eligible service that allows healthcare software vendors to automatically generate clinical notes by analyzing patient-clinician conversations. AWS HealthScribe combines speech recognition with generative Al to reduce the burden of clinical documentation by transcribing conversations and quickly producing clinical notes. Conversations are segmented to identify the speaker roles for patients and clinicians, extract medical terms, and generate preliminary clinical notes. To protect sensitive patient data, security and privacy are builtin to ensure that the input audio and the output text are not retained in AWS HealthScribe.'\n",
      "\n",
      "=== 284 ===\n",
      "chunk.text (333 tokens):\n",
      "'AWS Panorama is a collection of ML devices and software development kit (SDK) that brings computer vision (CV) to on-premises internet protocol (IP) cameras. With AWS Panorama, you can automate tasks that have traditionally required human inspection to improve visibility into potential issues.\\nComputer vision can automate visual inspection for tasks such as tracking assets to optimize Supply chain operations, monitoring traffic lanes to optimize trafic management, or detecting anomalies to evaluate manufacturing quality. In environments with limited network bandwidth nowever, or Tor companies with data governance rules that require on-premises processing and storage of video, computer vision in the cloud can be difficult or impossible to implement. AWS Panorama is an ML service that allows organizations to bring computer vision to on-premises cameras to make predictions locally with high accuracy and low latency.\\nThe AWS Panorama Appliance is a hardware device that adds computer vision to your existing IP Cameras and analyzes the video feeds of multiple cameras from a single management interface.\\nAWS HealtnScribe\\nit generates predictions at the edge in milliseconds, meaning you can be notified about potential issues such as when damaged products are detected on a fast-moving production line, or when a vehicle has strayed into a dangerous off-limits zone in a warehouse. And, third-party manufacturers are building new AWS Panorama-enabled cameras and devices to provide even more form factors for your unique use cases. With AWS Panorama you can use ML models from AWS to build your own computer vision applications, or work with a partner from the AWS Partner Network to build CV applications quickly.'\n",
      "chunker.contextualize(chunk) (336 tokens):\n",
      "'AWS Panorama\\nAWS Panorama is a collection of ML devices and software development kit (SDK) that brings computer vision (CV) to on-premises internet protocol (IP) cameras. With AWS Panorama, you can automate tasks that have traditionally required human inspection to improve visibility into potential issues.\\nComputer vision can automate visual inspection for tasks such as tracking assets to optimize Supply chain operations, monitoring traffic lanes to optimize trafic management, or detecting anomalies to evaluate manufacturing quality. In environments with limited network bandwidth nowever, or Tor companies with data governance rules that require on-premises processing and storage of video, computer vision in the cloud can be difficult or impossible to implement. AWS Panorama is an ML service that allows organizations to bring computer vision to on-premises cameras to make predictions locally with high accuracy and low latency.\\nThe AWS Panorama Appliance is a hardware device that adds computer vision to your existing IP Cameras and analyzes the video feeds of multiple cameras from a single management interface.\\nAWS HealtnScribe\\nit generates predictions at the edge in milliseconds, meaning you can be notified about potential issues such as when damaged products are detected on a fast-moving production line, or when a vehicle has strayed into a dangerous off-limits zone in a warehouse. And, third-party manufacturers are building new AWS Panorama-enabled cameras and devices to provide even more form factors for your unique use cases. With AWS Panorama you can use ML models from AWS to build your own computer vision applications, or work with a partner from the AWS Partner Network to build CV applications quickly.'\n",
      "\n",
      "=== 285 ===\n",
      "chunk.text (48 tokens):\n",
      "\"With AWS Management and Governance services, you don't nave to choose between innovating faster and maintaining control over cost, compliance, and security—you can do both.\\nFor general information, see Management and Governance on AWS.\"\n",
      "chunker.contextualize(chunk) (51 tokens):\n",
      "\"Management and governance\\nWith AWS Management and Governance services, you don't nave to choose between innovating faster and maintaining control over cost, compliance, and security—you can do both.\\nFor general information, see Management and Governance on AWS.\"\n",
      "\n",
      "=== 286 ===\n",
      "chunk.text (87 tokens):\n",
      "'¢ AWS Auto Scaling\\ne Amazon Q Developer in chat applications\\nCloud Trail\\ne Amazon CloudWatch\\ne AWS Compute Optimizer\\ne AWS Console Mobile Application\\ne AWS Config\\ne AWS Health Dasnboara\\ne AWS License Manager\\ne Amazon Managed Grafana\\ne Amazon Managed Service for Prometheus\\nManagement and governance\\ne AWS Organizations\\ne AWS OpsWorks\\ne AWS Proton\\ne Service Catalog\\ne AWS Systems Manager'\n",
      "chunker.contextualize(chunk) (88 tokens):\n",
      "'Services\\n¢ AWS Auto Scaling\\ne Amazon Q Developer in chat applications\\nCloud Trail\\ne Amazon CloudWatch\\ne AWS Compute Optimizer\\ne AWS Console Mobile Application\\ne AWS Config\\ne AWS Health Dasnboara\\ne AWS License Manager\\ne Amazon Managed Grafana\\ne Amazon Managed Service for Prometheus\\nManagement and governance\\ne AWS Organizations\\ne AWS OpsWorks\\ne AWS Proton\\ne Service Catalog\\ne AWS Systems Manager'\n",
      "\n",
      "=== 287 ===\n",
      "chunk.text (178 tokens):\n",
      "\"AWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. Using AWS Auto Scaling, it's easy to setup application scaling for multiple resources across multiple services in minutes. The service provides a simple, powertTul user interface that lets you build scaling plans Tor resources including Amazon EC2 instances and Spot Fleets, Amazon ECS tasks, Amazon DynamoDB tables and indexes, and Amazon Aurora Replicas. AWS Auto Scaling makes scaling simple with recommendations that allow you to optimize performance, costs, or balance between them. If you're already using Amazon EC2 Auto Scaling to dynamically scale your Amazon EC2 instances, you can now combine it with AWS Auto Scaling to scale additional resources for other AWS services. With AWS Auto Scaling, your applications always have the right resources at the right time.\"\n",
      "chunker.contextualize(chunk) (182 tokens):\n",
      "\"AWS Auto Scaling\\nAWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. Using AWS Auto Scaling, it's easy to setup application scaling for multiple resources across multiple services in minutes. The service provides a simple, powertTul user interface that lets you build scaling plans Tor resources including Amazon EC2 instances and Spot Fleets, Amazon ECS tasks, Amazon DynamoDB tables and indexes, and Amazon Aurora Replicas. AWS Auto Scaling makes scaling simple with recommendations that allow you to optimize performance, costs, or balance between them. If you're already using Amazon EC2 Auto Scaling to dynamically scale your Amazon EC2 instances, you can now combine it with AWS Auto Scaling to scale additional resources for other AWS services. With AWS Auto Scaling, your applications always have the right resources at the right time.\"\n",
      "\n",
      "=== 288 ===\n",
      "chunk.text (195 tokens):\n",
      "\"Amazon Q Developer in chat applications Is an interactive agent that makes it easy to monitor and interact with your AWS resources in your Slack channels and Amazon Chime chat rooms. With Amazon Q Developer in chat applications you can receive alerts, run commands to return diagnostic information, invoke AWS Lambda Tunctions, and create AWS support cases.\\nAmazon Q Developer in chat applications manages the integration between AWS services and your Slack channels or Amazon Chime cnat rooms helping you to get started with ChatOps fast. With just a Tew clicks you can start receiving notifications and issuing commands in your chosen channels or chat rooms, so your team doesn't Nave to switch contexts to collaborate. Amazon Q Developer in chat applications makes it easier for your team to stay updated, collaborate, and respond Taster to operational events, security findings, Cl/CD workflows, budget, and other alerts for applications running in your AWS accounts.\\nAWS Auto Scaling\"\n",
      "chunker.contextualize(chunk) (201 tokens):\n",
      "\"Amazon Q Developer in chat applications\\nAmazon Q Developer in chat applications Is an interactive agent that makes it easy to monitor and interact with your AWS resources in your Slack channels and Amazon Chime chat rooms. With Amazon Q Developer in chat applications you can receive alerts, run commands to return diagnostic information, invoke AWS Lambda Tunctions, and create AWS support cases.\\nAmazon Q Developer in chat applications manages the integration between AWS services and your Slack channels or Amazon Chime cnat rooms helping you to get started with ChatOps fast. With just a Tew clicks you can start receiving notifications and issuing commands in your chosen channels or chat rooms, so your team doesn't Nave to switch contexts to collaborate. Amazon Q Developer in chat applications makes it easier for your team to stay updated, collaborate, and respond Taster to operational events, security findings, Cl/CD workflows, budget, and other alerts for applications running in your AWS accounts.\\nAWS Auto Scaling\"\n",
      "\n",
      "=== 289 ===\n",
      "chunk.text (491 tokens):\n",
      "\"AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\\nYou can use the AWS CloudFormation sample templates or create your own templates to describe your AWS resources, and any associated dependencies or runtime parameters, required to run your application. You don't need to figure out the order for provisioning AWS services or the subtleties of making those dependencies work. CloudFormation takes care of this for you. After the AWS resources are deployed, you can modify and update them in a controlled and predictable way, in effect applying version control to your AWS infrastructure the same way you do with your software. You can also visualize your templates as diagrams and edit them using a drag-and-drop interface with AWS Infrastructure Composer.\\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by\\nWith CloudTrail, you can get a history of AWS API calls for your account, including API calls made using the AWS Management Console, AWS SDKs, command line tools, and higher-level AWS services (Such as AWS CloudFormation). The AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing.\\nAmazon CloudWatch is a monitoring and management service built for developers, system operators, site reliability engineers (SRE), and IT managers. CloudWatch provides you with data and actionable insights to monitor your applications, understand and respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. CloudWatcnh collects monitoring and operational data in the form of logs, metrics, and events, providing you with a unified view of AWS resources, applications and services that run on AWS, and on-premises servers. You can use CloudWatch to set high resolution alarms, visualize logs and metrics side by side, take automated actions, troubleshoot issues, and discover insights to optimize your applications, and ensure they are running smoothly.\\nAWS CloudFormation\"\n",
      "chunker.contextualize(chunk) (496 tokens):\n",
      "\"AWS CloudFormation\\nAWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.\\nYou can use the AWS CloudFormation sample templates or create your own templates to describe your AWS resources, and any associated dependencies or runtime parameters, required to run your application. You don't need to figure out the order for provisioning AWS services or the subtleties of making those dependencies work. CloudFormation takes care of this for you. After the AWS resources are deployed, you can modify and update them in a controlled and predictable way, in effect applying version control to your AWS infrastructure the same way you do with your software. You can also visualize your templates as diagrams and edit them using a drag-and-drop interface with AWS Infrastructure Composer.\\nAWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The recorded information includes the identity of the API caller, the time of the API call, the source IP address of the API caller, the request parameters, and the response elements returned by\\nWith CloudTrail, you can get a history of AWS API calls for your account, including API calls made using the AWS Management Console, AWS SDKs, command line tools, and higher-level AWS services (Such as AWS CloudFormation). The AWS API call history produced by CloudTrail enables security analysis, resource change tracking, and compliance auditing.\\nAmazon CloudWatch is a monitoring and management service built for developers, system operators, site reliability engineers (SRE), and IT managers. CloudWatch provides you with data and actionable insights to monitor your applications, understand and respond to system-wide performance changes, optimize resource utilization, and get a unified view of operational health. CloudWatcnh collects monitoring and operational data in the form of logs, metrics, and events, providing you with a unified view of AWS resources, applications and services that run on AWS, and on-premises servers. You can use CloudWatch to set high resolution alarms, visualize logs and metrics side by side, take automated actions, troubleshoot issues, and discover insights to optimize your applications, and ensure they are running smoothly.\\nAWS CloudFormation\"\n",
      "\n",
      "=== 290 ===\n",
      "chunk.text (287 tokens):\n",
      "\"AWS Compute Optimizer recommends optimal AWS resources for your workloads to reduce costs and improve performance by using machine learning to analyze historical utilization metrics. Over-provisioning resources can lead to unnecessary infrastructure cost, and under-provisioning resources can lead to poor application performance. Compute Optimizer helps you choose optimal configurations for three types of AWS resources: Amazon EC2 instances, Amazon EBS volumes, and AWS Lambda functions, based on your utilization data.\\nBy applying the knowledge drawn from Amazon's own experience running diverse workloads in the cloud, Compute Optimizer identifies workload patterns and recommends optimal AWS resources. Compute Optimizer analyzes the configuration and resource utilization of your workload to identify dozens of defining characteristics, for example, if a workload is CPU-intensive, If it exhibits a daily pattern, or if a workload accesses local storage frequently. The service processes these characteristics and identifies the hardware resource required by the workload. Compute Optimizer infers how the workload would have performed on various hardware platforms (such as Amazon EC2 instances types) or using different configurations (such as Amazon EBS volume IOPS settings, and AWS Lambda function memory sizes) to offer recommendations.\\nCompute Optimizer is available to you at no additional charge. To get started, you can opt in to the service in the AWS Compute Optimizer Console.\"\n",
      "chunker.contextualize(chunk) (293 tokens):\n",
      "\"AWS Compute Optimizer\\nAWS Compute Optimizer recommends optimal AWS resources for your workloads to reduce costs and improve performance by using machine learning to analyze historical utilization metrics. Over-provisioning resources can lead to unnecessary infrastructure cost, and under-provisioning resources can lead to poor application performance. Compute Optimizer helps you choose optimal configurations for three types of AWS resources: Amazon EC2 instances, Amazon EBS volumes, and AWS Lambda functions, based on your utilization data.\\nBy applying the knowledge drawn from Amazon's own experience running diverse workloads in the cloud, Compute Optimizer identifies workload patterns and recommends optimal AWS resources. Compute Optimizer analyzes the configuration and resource utilization of your workload to identify dozens of defining characteristics, for example, if a workload is CPU-intensive, If it exhibits a daily pattern, or if a workload accesses local storage frequently. The service processes these characteristics and identifies the hardware resource required by the workload. Compute Optimizer infers how the workload would have performed on various hardware platforms (such as Amazon EC2 instances types) or using different configurations (such as Amazon EBS volume IOPS settings, and AWS Lambda function memory sizes) to offer recommendations.\\nCompute Optimizer is available to you at no additional charge. To get started, you can opt in to the service in the AWS Compute Optimizer Console.\"\n",
      "\n",
      "=== 291 ===\n",
      "chunk.text (460 tokens):\n",
      "\"The AWS Console Mobile Application lets customers view and manage a select set of resources to Support Incident response while on-the-go.\\nThe AWS Console Mobile Application allows AWS customers to monitor resources through a dedicated dashboard and view configuration details, metrics, and alarms for select AWS services. The Dashboard provides permitted users with a single view a resource's status, with real-time data on Amazon CloudWatch, AWS Health Dashboard, and AWS Billing and Cost Management. Customers can view ongoing issues and follow through to the relevant CloudWatch alarm screen for a detailed view with graphs and configuration options. In addition, customers can check on the status of specific AWS services, view detailed resource screens, and perform select actions.\\nAWS Control Tower automates the set-up of a baseline environment, or landing zone, that is a secure, well-architected multi-account AWS environment. The configuration of the landing zone\\nAWS Compute Optimizer\\nis based on best practices that have been established by working with thousands of enterprise customers to create a secure environment that makes it easier to govern AWS workloads with rules for security, operations, and compliance.\\nAs enterprises migrate to AWS, they typically have a large number of applications and distributed teams. They often want to create multiple accounts to allow their teams to work independently, while still maintaining a consistent level of security and compliance. In addition, they use AWS management and security services, such as AWS Organizations, Service Catalog and AWS Config, that provide very granular controls over their workloads. They want to maintain this control, Dut they also want a way to centrally govern and enforce the best use of AWS services across all the accounts in their environment.\\nAWS Control Tower automates the set-up of their landing zone and configures AWS management and security services based on established best practices in a secure, compliant, multi-account environment. Distributed teams are able to provision new AWS accounts quickly, while central teams Nave the peace of mind Knowing that new accounts are aligned with centrally establisned, company-wide compliance policies. This gives you control over your environment, without Sacrificing the speed and agility AWS provides your development teams.\"\n",
      "chunker.contextualize(chunk) (465 tokens):\n",
      "\"AWS Console Mobile Application\\nThe AWS Console Mobile Application lets customers view and manage a select set of resources to Support Incident response while on-the-go.\\nThe AWS Console Mobile Application allows AWS customers to monitor resources through a dedicated dashboard and view configuration details, metrics, and alarms for select AWS services. The Dashboard provides permitted users with a single view a resource's status, with real-time data on Amazon CloudWatch, AWS Health Dashboard, and AWS Billing and Cost Management. Customers can view ongoing issues and follow through to the relevant CloudWatch alarm screen for a detailed view with graphs and configuration options. In addition, customers can check on the status of specific AWS services, view detailed resource screens, and perform select actions.\\nAWS Control Tower automates the set-up of a baseline environment, or landing zone, that is a secure, well-architected multi-account AWS environment. The configuration of the landing zone\\nAWS Compute Optimizer\\nis based on best practices that have been established by working with thousands of enterprise customers to create a secure environment that makes it easier to govern AWS workloads with rules for security, operations, and compliance.\\nAs enterprises migrate to AWS, they typically have a large number of applications and distributed teams. They often want to create multiple accounts to allow their teams to work independently, while still maintaining a consistent level of security and compliance. In addition, they use AWS management and security services, such as AWS Organizations, Service Catalog and AWS Config, that provide very granular controls over their workloads. They want to maintain this control, Dut they also want a way to centrally govern and enforce the best use of AWS services across all the accounts in their environment.\\nAWS Control Tower automates the set-up of their landing zone and configures AWS management and security services based on established best practices in a secure, compliant, multi-account environment. Distributed teams are able to provision new AWS accounts quickly, while central teams Nave the peace of mind Knowing that new accounts are aligned with centrally establisned, company-wide compliance policies. This gives you control over your environment, without Sacrificing the speed and agility AWS provides your development teams.\"\n",
      "\n",
      "=== 292 ===\n",
      "chunk.text (257 tokens):\n",
      "'AWS Config is a fully managed service that provides you with an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. The AWS Config Rules feature enables you to create rules that automatically check the configuration of AWS resources recorded by AWS Config.\\nWith AWS Config, you can discover existing and deleted AWS resources, determine your overall compliance against rules, and dive into configuration details of a resource at any point in time. These capabilities enable compliance auditing, security analysis, resource change tracking, and troubleshooting.\\nAWS Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that might affect you. While the Service Health Dashboard displays the general status of AWS services, AWS Health Dashboard gives you a personalized view into the performance and availability of the AWS services underlying your AWS resources. The dasnboard displays relevant and timely information to help you manage events in progress, and provides proactive notification to help you plan Tor scheduled activities. With AWS Health Dashboard, alerts are automatically\\nAWS Config\\nInitiated by changes in the health of AWS resources, giving you event visibility and guidance to help quickly diagnose and resolve issues.'\n",
      "chunker.contextualize(chunk) (262 tokens):\n",
      "'AWS Config\\nAWS Config is a fully managed service that provides you with an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. The AWS Config Rules feature enables you to create rules that automatically check the configuration of AWS resources recorded by AWS Config.\\nWith AWS Config, you can discover existing and deleted AWS resources, determine your overall compliance against rules, and dive into configuration details of a resource at any point in time. These capabilities enable compliance auditing, security analysis, resource change tracking, and troubleshooting.\\nAWS Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that might affect you. While the Service Health Dashboard displays the general status of AWS services, AWS Health Dashboard gives you a personalized view into the performance and availability of the AWS services underlying your AWS resources. The dasnboard displays relevant and timely information to help you manage events in progress, and provides proactive notification to help you plan Tor scheduled activities. With AWS Health Dashboard, alerts are automatically\\nAWS Config\\nInitiated by changes in the health of AWS resources, giving you event visibility and guidance to help quickly diagnose and resolve issues.'\n",
      "\n",
      "=== 293 ===\n",
      "chunk.text (209 tokens):\n",
      "'AWS Launch Wizard offers a guided way of sizing, configuring, and deploying AWS resources for third party applications, such as Microsoft SQL Server Always On and HANA based SAP systems, without the need to manually identify and provision individual AWS resources. To start, you input your application requirements, including performance, number of nodes, and connectivity on the service console. Launch Wizard then identifies the right AWS resources, such as EC2 instances and EBS volumes, to deploy and run your application. Launch Wizard provides an estimated cost of deployment, and lets you modify your resources to instantly view an updated cost assessment. Once you approve the AWS resources, Launch Wizard automatically provisions and configures the selected resources to create a Tully functioning, production-ready application.\\nAWS Launch Wizard also creates CloudFormation templates that can serve as a baseline to accelerate subsequent deployments. Launch Wizard is available to you at no additional charge. You only pay for the AWS resources that are provisioned for running your solution.'\n",
      "chunker.contextualize(chunk) (213 tokens):\n",
      "'AWS Launch Wizard\\nAWS Launch Wizard offers a guided way of sizing, configuring, and deploying AWS resources for third party applications, such as Microsoft SQL Server Always On and HANA based SAP systems, without the need to manually identify and provision individual AWS resources. To start, you input your application requirements, including performance, number of nodes, and connectivity on the service console. Launch Wizard then identifies the right AWS resources, such as EC2 instances and EBS volumes, to deploy and run your application. Launch Wizard provides an estimated cost of deployment, and lets you modify your resources to instantly view an updated cost assessment. Once you approve the AWS resources, Launch Wizard automatically provisions and configures the selected resources to create a Tully functioning, production-ready application.\\nAWS Launch Wizard also creates CloudFormation templates that can serve as a baseline to accelerate subsequent deployments. Launch Wizard is available to you at no additional charge. You only pay for the AWS resources that are provisioned for running your solution.'\n",
      "\n",
      "=== 294 ===\n",
      "chunk.text (321 tokens):\n",
      "'AWS License Manager makes it easier to manage licenses in AWS and on-premises servers from software vendors such as Microsoft, SAP, Oracle, and IBM. AWS License Manager lets administrators create customized licensing rules that emulate the terms of their licensing agreements, and then enforces these rules when an instance of Amazon EC2 gets launched. Administrators can use these rules to limit licensing violations, such as using more licenses than an agreement stipulates or reassigning licenses to different servers on a short-term basis. The rules in AWS License Manager enable you to limit a licensing breach by physically stopping the instance from launching or by notifying administrators about the infringement. Administrators gain control and visibility of all their licenses with the AWS License Manager dashboard and reduce the risk of non-compliance, misreporting, and additional costs due to licensing overages.\\nAWS License Manager integrates with AWS services to simplify the management of licenses across multiple AWS accounts, IT catalogs, and on-premises, through a single AWS account. License administrators can add rules in Service Catalog, which allows them to create and manage catalogs of IT services that are approved Tor use on all their AWS accounts. Through seamless integration with AWS Systems Manager and AWS Organizations, administrators can manage licenses across all the AWS accounts in an organization and on-premises environments. AWS Marketplace buyers can\\nAWS Launch Wizara\\nalso use AWS License Manager to track bring your own license (BYOL) software obtained from the Marketplace and keep a consolidated view of all their licenses.'\n",
      "chunker.contextualize(chunk) (325 tokens):\n",
      "'AWS License Manager\\nAWS License Manager makes it easier to manage licenses in AWS and on-premises servers from software vendors such as Microsoft, SAP, Oracle, and IBM. AWS License Manager lets administrators create customized licensing rules that emulate the terms of their licensing agreements, and then enforces these rules when an instance of Amazon EC2 gets launched. Administrators can use these rules to limit licensing violations, such as using more licenses than an agreement stipulates or reassigning licenses to different servers on a short-term basis. The rules in AWS License Manager enable you to limit a licensing breach by physically stopping the instance from launching or by notifying administrators about the infringement. Administrators gain control and visibility of all their licenses with the AWS License Manager dashboard and reduce the risk of non-compliance, misreporting, and additional costs due to licensing overages.\\nAWS License Manager integrates with AWS services to simplify the management of licenses across multiple AWS accounts, IT catalogs, and on-premises, through a single AWS account. License administrators can add rules in Service Catalog, which allows them to create and manage catalogs of IT services that are approved Tor use on all their AWS accounts. Through seamless integration with AWS Systems Manager and AWS Organizations, administrators can manage licenses across all the AWS accounts in an organization and on-premises environments. AWS Marketplace buyers can\\nAWS Launch Wizara\\nalso use AWS License Manager to track bring your own license (BYOL) software obtained from the Marketplace and keep a consolidated view of all their licenses.'\n",
      "\n",
      "=== 295 ===\n",
      "chunk.text (181 tokens):\n",
      "'Amazon Managed Gratana is a fully managed and secure data visualization service that you can use to instantly query, correlate, and visualize operational metrics, logs, and traces from multiple sources. Amazon Managed Grafana makes it easy to deploy, operate, and scale Grafana, a widely deployed open-source data visualization tool that is popular for its extensible data support.\\nAmazon Managed Grafana provides built-in security features for compliance with corporate governance requirements, including single sign-on, data access control, and audit reporting. Amazon Managed Grafana integrates with AWS data sources, such as Amazon CloudWatch, Amazon OpenSearch Service, AWS X-Ray, AWS loT SiteWise, Amazon Timestream, and Amazon Managed Service for Prometheus. Amazon Managed Grafana also supports many popular opensource, third party, and other cloud data sources.'\n",
      "chunker.contextualize(chunk) (185 tokens):\n",
      "'Amazon Managed Grafana\\nAmazon Managed Gratana is a fully managed and secure data visualization service that you can use to instantly query, correlate, and visualize operational metrics, logs, and traces from multiple sources. Amazon Managed Grafana makes it easy to deploy, operate, and scale Grafana, a widely deployed open-source data visualization tool that is popular for its extensible data support.\\nAmazon Managed Grafana provides built-in security features for compliance with corporate governance requirements, including single sign-on, data access control, and audit reporting. Amazon Managed Grafana integrates with AWS data sources, such as Amazon CloudWatch, Amazon OpenSearch Service, AWS X-Ray, AWS loT SiteWise, Amazon Timestream, and Amazon Managed Service for Prometheus. Amazon Managed Grafana also supports many popular opensource, third party, and other cloud data sources.'\n",
      "\n",
      "=== 296 ===\n",
      "chunk.text (173 tokens):\n",
      "'Amazon Managed Service for Prometheus Is a serverless, Prometheus-compatible monitoring service Tor container metrics that makes it easier to securely monitor container environments at scale. With Amazon Managed Service for Prometheus, you can use the same open-source Prometheus data model and query language that you use today to monitor the performance otf your containerized workloads, and also enjoy improved scalability, availability, and security without naving to manage the underlying infrastructure.\\nAmazon Managed Service for Prometheus automatically scales the ingestion, storage, and querying of operational metrics as workloads scale up and down. It integrates with AWS security services to enable fast and secure access to data. Designed to be highly available, data ingested into a workspace is replicated across three Availability Zones in the same AWS Region.'\n",
      "chunker.contextualize(chunk) (180 tokens):\n",
      "'Amazon Managed Service for Prometheus\\nAmazon Managed Service for Prometheus Is a serverless, Prometheus-compatible monitoring service Tor container metrics that makes it easier to securely monitor container environments at scale. With Amazon Managed Service for Prometheus, you can use the same open-source Prometheus data model and query language that you use today to monitor the performance otf your containerized workloads, and also enjoy improved scalability, availability, and security without naving to manage the underlying infrastructure.\\nAmazon Managed Service for Prometheus automatically scales the ingestion, storage, and querying of operational metrics as workloads scale up and down. It integrates with AWS security services to enable fast and secure access to data. Designed to be highly available, data ingested into a workspace is replicated across three Availability Zones in the same AWS Region.'\n",
      "\n",
      "=== 297 ===\n",
      "chunk.text (131 tokens):\n",
      "'AWS Organizations helps you centrally manage and govern your environment as you grow and Scale your AWS resources. Using AWS Organizations, you can programmatically create new AWS accounts and allocate resources, group accounts to organize your workTlows, apply policies to accounts or groups for governance, and simplify billing by using a single payment method for all of your accounts.\\nAmazon Managed Gratana\\nIn addition, AWS Organizations is integrated with other AWS services so you can define central configurations, security mechanisms, audit requirements, and resource sharing across accounts In your organization. AWS Organizations Is available to all AWS customers at no additional charge.'\n",
      "chunker.contextualize(chunk) (134 tokens):\n",
      "'AWS Organizations\\nAWS Organizations helps you centrally manage and govern your environment as you grow and Scale your AWS resources. Using AWS Organizations, you can programmatically create new AWS accounts and allocate resources, group accounts to organize your workTlows, apply policies to accounts or groups for governance, and simplify billing by using a single payment method for all of your accounts.\\nAmazon Managed Gratana\\nIn addition, AWS Organizations is integrated with other AWS services so you can define central configurations, security mechanisms, audit requirements, and resource sharing across accounts In your organization. AWS Organizations Is available to all AWS customers at no additional charge.'\n",
      "\n",
      "=== 298 ===\n",
      "chunk.text (106 tokens):\n",
      "'AWS OpsWorks is a configuration management service that provides managed instances of Chet and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. AWS OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments. AWS OpsWorks has three offerings, AWS OpsWorks tor Chef Automate, AWS OpsWorks for Puppet Enterprise, and AWS OpsWorks Stacks.'\n",
      "chunker.contextualize(chunk) (110 tokens):\n",
      "'AWS OpsWorks\\nAWS OpsWorks is a configuration management service that provides managed instances of Chet and Puppet. Chef and Puppet are automation platforms that allow you to use code to automate the configurations of your servers. AWS OpsWorks lets you use Chef and Puppet to automate how servers are configured, deployed, and managed across your Amazon EC2 instances or on-premises compute environments. AWS OpsWorks has three offerings, AWS OpsWorks tor Chef Automate, AWS OpsWorks for Puppet Enterprise, and AWS OpsWorks Stacks.'\n",
      "\n",
      "=== 299 ===\n",
      "chunk.text (131 tokens):\n",
      "'AWS Proton is the first fully managed delivery service for container and serverless applications. Platform engineering teams can use AWS Proton to connect and coordinate all the different tools needed for infrastructure provisioning, code deployments, monitoring, and updates.\\nMaintaining hundreds — or sometimes thousands — of microservices with constantly changing infrastructure resources and continuous integration/continuous delivery (CI/CD) configurations is a nearly impossible task for even the most capable platform teams.\\nAWS Proton solves this by giving platform teams the tools they need to manage this complexity and enforce consistent standards, while making it easy for developers to deploy their code using containers and serverltess technologies.'\n",
      "chunker.contextualize(chunk) (134 tokens):\n",
      "'AWS Proton\\nAWS Proton is the first fully managed delivery service for container and serverless applications. Platform engineering teams can use AWS Proton to connect and coordinate all the different tools needed for infrastructure provisioning, code deployments, monitoring, and updates.\\nMaintaining hundreds — or sometimes thousands — of microservices with constantly changing infrastructure resources and continuous integration/continuous delivery (CI/CD) configurations is a nearly impossible task for even the most capable platform teams.\\nAWS Proton solves this by giving platform teams the tools they need to manage this complexity and enforce consistent standards, while making it easy for developers to deploy their code using containers and serverltess technologies.'\n",
      "\n",
      "=== 300 ===\n",
      "chunk.text (85 tokens):\n",
      "'Service Catalog allows organizations to create and manage catalogs of IT services that are approved for use on AWS. These IT services can include everything from virtual machine images, servers, software, and databases to complete multi-tier application architectures. Service Catalog allows you to centrally manage commonly deployed IT services and helps you achieve consistent governance and meet your compliance requirements, while enabling users to quickly deploy only the approved IT services they need.'\n",
      "chunker.contextualize(chunk) (87 tokens):\n",
      "'Service Catalog\\nService Catalog allows organizations to create and manage catalogs of IT services that are approved for use on AWS. These IT services can include everything from virtual machine images, servers, software, and databases to complete multi-tier application architectures. Service Catalog allows you to centrally manage commonly deployed IT services and helps you achieve consistent governance and meet your compliance requirements, while enabling users to quickly deploy only the approved IT services they need.'\n",
      "\n",
      "=== 301 ===\n",
      "chunk.text (147 tokens):\n",
      "'AWS Systems Manager gives you visibility and control of your infrastructure on AWS. Systems Manager provides a unified user interface so you can view operational data from multiple AWS\\nAWS OpsWorks 100\\nservices and allows you to automate operational tasks across your AWS resources. With Systems Manager, you can group resources, such as Amazon EC2 instances, Amazon S34 buckets, or Amazon RDS instances, by application, view operational data for monitoring and troubleshooting, and take action on your groups of resources. Systems Manager simplifies resource and application management, shortens the time to detect and resolve operational problems, and makes it easy to operate and manage your infrastructure securely at scale.\\nAWS Systems Manager contains the following tools:'\n",
      "chunker.contextualize(chunk) (151 tokens):\n",
      "'AWS Systems Manager\\nAWS Systems Manager gives you visibility and control of your infrastructure on AWS. Systems Manager provides a unified user interface so you can view operational data from multiple AWS\\nAWS OpsWorks 100\\nservices and allows you to automate operational tasks across your AWS resources. With Systems Manager, you can group resources, such as Amazon EC2 instances, Amazon S34 buckets, or Amazon RDS instances, by application, view operational data for monitoring and troubleshooting, and take action on your groups of resources. Systems Manager simplifies resource and application management, shortens the time to detect and resolve operational problems, and makes it easy to operate and manage your infrastructure securely at scale.\\nAWS Systems Manager contains the following tools:'\n",
      "\n",
      "=== 302 ===\n",
      "chunk.text (383 tokens):\n",
      "'e Resource groups — Lets you create a logical group of resources associated with a particular workload such as different layers of an application stack, or production versus development environments. For example, you can group different layers of an application, such as the frontend web layer and the backend data layer. Resource groups can be created, updated, or removed programmatically through the API.\\n- Insights dashboard — Displays operational data that the AWS Systems Manager automatically aggregates for each resource group. Systems Manager eliminates the need for you to navigate across multiple AWS consoles to view your operational data. With Systems Manager you can view API call logs from AWS CloudTrail, resource configuration changes from AWS Config, software inventory, and patch compliance status by resource group. You can also easily integrate your Amazon CloudWatch dashboards, AWS Trusted Advisor notifications, and AWS Health Dashboard performance and availability alerts into your Systems Manager dashboard. Systems Manager centralizes all relevant operational data, so you can have a clear view of your infrastructure compliance and performance.\\ne Run command — Provides a simple way of automating common administrative tasks such as remotely running shell scripts or PowerShell commands, installing software updates, or making changes to the configuration of OS, software, EC2 and instances and servers in your on-premises data center.\\ne State Manager — Helps you define and maintain consistent OS configurations such as firewall settings and anti-malware definitions to comply with your policies. You can monitor the configuration of a large set of instances, specify a configuration policy for the instances, and automatically apply updates or configuration changes.\\ne Inventory — Helps you collect and query configuration and inventory information about your instances and the software installed on them. You can gather details about your instances such as installed applications, DHCP settings, agent detail, and custom items. You can run queries to track and audit your system configurations.'\n",
      "chunker.contextualize(chunk) (387 tokens):\n",
      "'AWS Systems Manager\\ne Resource groups — Lets you create a logical group of resources associated with a particular workload such as different layers of an application stack, or production versus development environments. For example, you can group different layers of an application, such as the frontend web layer and the backend data layer. Resource groups can be created, updated, or removed programmatically through the API.\\n- Insights dashboard — Displays operational data that the AWS Systems Manager automatically aggregates for each resource group. Systems Manager eliminates the need for you to navigate across multiple AWS consoles to view your operational data. With Systems Manager you can view API call logs from AWS CloudTrail, resource configuration changes from AWS Config, software inventory, and patch compliance status by resource group. You can also easily integrate your Amazon CloudWatch dashboards, AWS Trusted Advisor notifications, and AWS Health Dashboard performance and availability alerts into your Systems Manager dashboard. Systems Manager centralizes all relevant operational data, so you can have a clear view of your infrastructure compliance and performance.\\ne Run command — Provides a simple way of automating common administrative tasks such as remotely running shell scripts or PowerShell commands, installing software updates, or making changes to the configuration of OS, software, EC2 and instances and servers in your on-premises data center.\\ne State Manager — Helps you define and maintain consistent OS configurations such as firewall settings and anti-malware definitions to comply with your policies. You can monitor the configuration of a large set of instances, specify a configuration policy for the instances, and automatically apply updates or configuration changes.\\ne Inventory — Helps you collect and query configuration and inventory information about your instances and the software installed on them. You can gather details about your instances such as installed applications, DHCP settings, agent detail, and custom items. You can run queries to track and audit your system configurations.'\n",
      "\n",
      "=== 303 ===\n",
      "chunk.text (474 tokens):\n",
      "'Maintenance Window — Lets you define a recurring window of time to run administrative and maintenance tasks across your instances. This ensures that installing patches and updates, or making other configuration changes does not disrupt business-critical operations. This helps improve your application availability.\\nPatch Manager — Helps you select and deploy operating system and software patches automatically across large groups of instances. You can define a maintenance window so that patches are applied only during set times that fit your needs. These capabilities help ensure that your software Is always up to date and meets your compliance policies.\\nAutomation — Simplifies common maintenance and deployment tasks, such as updating Amazon Machine Images (AMIs). Use the Automation feature to apply patches, update drivers and agents, or Dake applications into your AMI using a streamlined, repeatable, and auditable UTOCESS.\\nParameter Store — Provides an encrypted location to store important administrative information such as passwords and database strings. The Parameter Store integrates with AWS Key Management Service (AWS KMS) to make it easy to encrypt the information you keep in the Parameter Store.\\nDistributor — Helps you securely distribute and install software packages, such as software agents. Systems Manager Distributor allows you to centrally store and systematically distribute software packages while you maintain control over versioning. You can use Distributor to create and distribute software packages and then install them using Systems Manager Run Command and State Manager. Distributor can also use AWS Identity and Access Management (IAM) policies to control who can create or update packages in your account. You can use the existing [AM policy support for Systems Manager Run Command and State Manager to define who can install DackKages on your hosts.\\nSession Manager — Provides a browser-based interactive shell and CLI for managing Windows and Linux EC2 instances, without the need to open inbound ports, manage SSH keys, or use bastion hosts. Administrators can grant and revoke access to instances through a central location by using AWS Identity and Access Management (IAM) policies. This allows you to control which users can access each instance, including the option to provide non-root access to specified users. Once access Is provided, you can audit which user accessed an instance and log each command to Amazon S43 or Amazon CloudWatcn Logs using AWS Cloud Trait.\\nAWS Systems Manager 1QO2'\n",
      "chunker.contextualize(chunk) (478 tokens):\n",
      "'AWS Systems Manager\\nMaintenance Window — Lets you define a recurring window of time to run administrative and maintenance tasks across your instances. This ensures that installing patches and updates, or making other configuration changes does not disrupt business-critical operations. This helps improve your application availability.\\nPatch Manager — Helps you select and deploy operating system and software patches automatically across large groups of instances. You can define a maintenance window so that patches are applied only during set times that fit your needs. These capabilities help ensure that your software Is always up to date and meets your compliance policies.\\nAutomation — Simplifies common maintenance and deployment tasks, such as updating Amazon Machine Images (AMIs). Use the Automation feature to apply patches, update drivers and agents, or Dake applications into your AMI using a streamlined, repeatable, and auditable UTOCESS.\\nParameter Store — Provides an encrypted location to store important administrative information such as passwords and database strings. The Parameter Store integrates with AWS Key Management Service (AWS KMS) to make it easy to encrypt the information you keep in the Parameter Store.\\nDistributor — Helps you securely distribute and install software packages, such as software agents. Systems Manager Distributor allows you to centrally store and systematically distribute software packages while you maintain control over versioning. You can use Distributor to create and distribute software packages and then install them using Systems Manager Run Command and State Manager. Distributor can also use AWS Identity and Access Management (IAM) policies to control who can create or update packages in your account. You can use the existing [AM policy support for Systems Manager Run Command and State Manager to define who can install DackKages on your hosts.\\nSession Manager — Provides a browser-based interactive shell and CLI for managing Windows and Linux EC2 instances, without the need to open inbound ports, manage SSH keys, or use bastion hosts. Administrators can grant and revoke access to instances through a central location by using AWS Identity and Access Management (IAM) policies. This allows you to control which users can access each instance, including the option to provide non-root access to specified users. Once access Is provided, you can audit which user accessed an instance and log each command to Amazon S43 or Amazon CloudWatcn Logs using AWS Cloud Trait.\\nAWS Systems Manager 1QO2'\n",
      "\n",
      "=== 304 ===\n",
      "chunk.text (310 tokens):\n",
      "'AWS Trusted Advisor is an online resource to help you reduce cost, increase performance, and improve security by optimizing your AWS environment. Trusted Advisor provides real-time guidance to help you provision your resources following AWS best practices.\\nThe AWS Well-Architected Tool (AWS WA Tool) helps you review the state of your workloads and compares them to the latest AWS architectural best practices. A workload is defined as any set of components that deliver business value, which could be an application or website. The tool is based on the AWS Well-Architected Framework, developed to help cloud architects build secure, highperforming, resilient, efficient, and sustainable application infrastructure.\\nThe Framework provides a consistent approach for customers and partners to evaluate architectures. It has been used in tens of thousands of workload reviews conducted by the AWS Solutions Architecture team and by customers, and provides guidance to help implement designs that scale with application needs over time.\\nTo use the AWS WA Tool, available in the AWS Management Console at no charge, just define your workload and answer a set of questions regarding operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability. The AWS WA Tool then provides a plan on how to architect for the cloud using established best practices.\\nAWS offers the most purpose-built media services, software, and appliances of any cloud to make creating, transforming, and delivering digital content fast and easy.\\nFor general information, see Media Services on AWS.'\n",
      "chunker.contextualize(chunk) (314 tokens):\n",
      "'AWS Trusted Advisor\\nAWS Trusted Advisor is an online resource to help you reduce cost, increase performance, and improve security by optimizing your AWS environment. Trusted Advisor provides real-time guidance to help you provision your resources following AWS best practices.\\nThe AWS Well-Architected Tool (AWS WA Tool) helps you review the state of your workloads and compares them to the latest AWS architectural best practices. A workload is defined as any set of components that deliver business value, which could be an application or website. The tool is based on the AWS Well-Architected Framework, developed to help cloud architects build secure, highperforming, resilient, efficient, and sustainable application infrastructure.\\nThe Framework provides a consistent approach for customers and partners to evaluate architectures. It has been used in tens of thousands of workload reviews conducted by the AWS Solutions Architecture team and by customers, and provides guidance to help implement designs that scale with application needs over time.\\nTo use the AWS WA Tool, available in the AWS Management Console at no charge, just define your workload and answer a set of questions regarding operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability. The AWS WA Tool then provides a plan on how to architect for the cloud using established best practices.\\nAWS offers the most purpose-built media services, software, and appliances of any cloud to make creating, transforming, and delivering digital content fast and easy.\\nFor general information, see Media Services on AWS.'\n",
      "\n",
      "=== 305 ===\n",
      "chunk.text (56 tokens):\n",
      "'e Amazon Elastic Transcoder\\ne Amazon Interactive Video Service\\ne Amazon Nimble Studio\\nAWS Trustea Advisor\\ne AWS Elemental Appliances and Software\\ne AWS Elemental MediaConnect\\nAWS Elemental MediaLive\\ne AWS Elemental MediaPackage\\ne AWS Elemental MediatTailor'\n",
      "chunker.contextualize(chunk) (57 tokens):\n",
      "'Services\\ne Amazon Elastic Transcoder\\ne Amazon Interactive Video Service\\ne Amazon Nimble Studio\\nAWS Trustea Advisor\\ne AWS Elemental Appliances and Software\\ne AWS Elemental MediaConnect\\nAWS Elemental MediaLive\\ne AWS Elemental MediaPackage\\ne AWS Elemental MediatTailor'\n",
      "\n",
      "=== 306 ===\n",
      "chunk.text (71 tokens):\n",
      "'Amazon Elastic Transcoder is media transcoding in the cloud. It is designed to be a highly scalable, easy-to-use, and cost-effective way for developers and businesses to convert (or transcode) media hiles from their source format into versions that will play back on devices such as smartphones, tablets, and PCs.'\n",
      "chunker.contextualize(chunk) (76 tokens):\n",
      "'Amazon Elastic Transcoder\\nAmazon Elastic Transcoder is media transcoding in the cloud. It is designed to be a highly scalable, easy-to-use, and cost-effective way for developers and businesses to convert (or transcode) media hiles from their source format into versions that will play back on devices such as smartphones, tablets, and PCs.'\n",
      "\n",
      "=== 307 ===\n",
      "chunk.text (124 tokens):\n",
      "'Amazon Interactive Video Service (Amazon IVS) is a managed live streaming solution that is quick and easy to set up, and ideal for creating interactive video experiences. Send your live streams to Amazon IVS using streaming software and the service does everything you need to make low-latency live video available to any viewer around the world, letting you focus on Duilding interactive experiences alongside the live video. You can easily customize and enhance the audience experience through the Amazon IVS player SDK and timed metadata APIs, allowing you to build a more valuable relationsnip with your viewers on your own websites and applications.'\n",
      "chunker.contextualize(chunk) (128 tokens):\n",
      "'Amazon Interactive Video Service\\nAmazon Interactive Video Service (Amazon IVS) is a managed live streaming solution that is quick and easy to set up, and ideal for creating interactive video experiences. Send your live streams to Amazon IVS using streaming software and the service does everything you need to make low-latency live video available to any viewer around the world, letting you focus on Duilding interactive experiences alongside the live video. You can easily customize and enhance the audience experience through the Amazon IVS player SDK and timed metadata APIs, allowing you to build a more valuable relationsnip with your viewers on your own websites and applications.'\n",
      "\n",
      "=== 308 ===\n",
      "chunk.text (69 tokens):\n",
      "'Amazon Nimble Studio empowers creative studios to produce visual effects, animation, and interactive content entirely in the cloud, from storyboard sketch to final deliverable. Rapidly onboard and collaborate with artists globally and create content Taster with access to virtual workstations, high-speed storage, and scalable rendering across the AWS global infrastructure.'\n",
      "chunker.contextualize(chunk) (73 tokens):\n",
      "'Amazon Nimble Studio\\nAmazon Nimble Studio empowers creative studios to produce visual effects, animation, and interactive content entirely in the cloud, from storyboard sketch to final deliverable. Rapidly onboard and collaborate with artists globally and create content Taster with access to virtual workstations, high-speed storage, and scalable rendering across the AWS global infrastructure.'\n",
      "\n",
      "=== 309 ===\n",
      "chunk.text (184 tokens):\n",
      "'AWS Elemental Appliances and Software solutions bring advanced video processing and delivery technologies into your data center, co-location space, or on-premises facility. You can deploy AWS\\nAmazon Elastic Transcoder\\nElemental Appliances and Software to encode, package, and deliver video assets on-premises and seamlessly connect with cloud-based video infrastructure. Designed for easy integration with AWS Cloud media solutions, AWS Elemental Appliances and Software support video workloads that need to remain on-premises to accommodate physical camera and router interfaces, managed network delivery, or network Danawidth constraints.\\nAWS Elemental Live, AWS Elemental Server, and AWS Elemental Conductor come in two variants: ready-to-deploy appliances, or AWS-licensed software that you install on your own hardware. AWS Flemental Link is a compact hardware device that sends live video to the cloud for encoding and delivery to viewers.'\n",
      "chunker.contextualize(chunk) (190 tokens):\n",
      "'AWS Elemental Appliances and Software\\nAWS Elemental Appliances and Software solutions bring advanced video processing and delivery technologies into your data center, co-location space, or on-premises facility. You can deploy AWS\\nAmazon Elastic Transcoder\\nElemental Appliances and Software to encode, package, and deliver video assets on-premises and seamlessly connect with cloud-based video infrastructure. Designed for easy integration with AWS Cloud media solutions, AWS Elemental Appliances and Software support video workloads that need to remain on-premises to accommodate physical camera and router interfaces, managed network delivery, or network Danawidth constraints.\\nAWS Elemental Live, AWS Elemental Server, and AWS Elemental Conductor come in two variants: ready-to-deploy appliances, or AWS-licensed software that you install on your own hardware. AWS Flemental Link is a compact hardware device that sends live video to the cloud for encoding and delivery to viewers.'\n",
      "\n",
      "=== 310 ===\n",
      "chunk.text (371 tokens):\n",
      "'AWS Elemental MediaConnect is a high-quality transport service for live video. Today, broadcasters and content owners rely on satellite networks or fiber connections to send their high-value content into the cloud or to transmit it to partners for distribution. Both satellite and fiber approaches are expensive, require long lead times to set up, and lack the flexibility to adapt to changing requirements. To be more nimble, some customers Nave tried to use solutions that transmit live video on top of IP infrastructure, but have struggled with reliability and security.\\nNow you can get the reliability and security of satellite and fiber combined with the flexibility, agility, and economics of IP-based networks using AWS Elemental MediaConnect. MediaConnect enables you to build mission-critical live video workflows in a fraction of the time and cost of Satellite or fiber services. You can use MediaConnect to ingest live video from a remote event site (Such as a Stadium), share video with a partner (such as a cable TV distributor), or replicate a video stream for processing (such as an over-the-top service). MediaConnect combines reliable video transport, highly secure stream sharing, and real-time network traffic and video monitoring that allow you to focus on your content, not your transport infrastructure.\\nAWS Elemental MediaConvert is a file-based video transcoding service with broadcast-grade features. It allows you to easily create video-on-demand (VOD) content for broadcast and multiscreen delivery at scale. The service combines advanced video and audio capabilities with a simple web services interface and pay-as-you-go pricing. With AWS Elemental MediaConvert, you can focus on delivering compelling media experiences without having to worry about the complexity of building and operating your own video processing infrastructure.'\n",
      "chunker.contextualize(chunk) (378 tokens):\n",
      "'AWS Elemental MediaConnect\\nAWS Elemental MediaConnect is a high-quality transport service for live video. Today, broadcasters and content owners rely on satellite networks or fiber connections to send their high-value content into the cloud or to transmit it to partners for distribution. Both satellite and fiber approaches are expensive, require long lead times to set up, and lack the flexibility to adapt to changing requirements. To be more nimble, some customers Nave tried to use solutions that transmit live video on top of IP infrastructure, but have struggled with reliability and security.\\nNow you can get the reliability and security of satellite and fiber combined with the flexibility, agility, and economics of IP-based networks using AWS Elemental MediaConnect. MediaConnect enables you to build mission-critical live video workflows in a fraction of the time and cost of Satellite or fiber services. You can use MediaConnect to ingest live video from a remote event site (Such as a Stadium), share video with a partner (such as a cable TV distributor), or replicate a video stream for processing (such as an over-the-top service). MediaConnect combines reliable video transport, highly secure stream sharing, and real-time network traffic and video monitoring that allow you to focus on your content, not your transport infrastructure.\\nAWS Elemental MediaConvert is a file-based video transcoding service with broadcast-grade features. It allows you to easily create video-on-demand (VOD) content for broadcast and multiscreen delivery at scale. The service combines advanced video and audio capabilities with a simple web services interface and pay-as-you-go pricing. With AWS Elemental MediaConvert, you can focus on delivering compelling media experiences without having to worry about the complexity of building and operating your own video processing infrastructure.'\n",
      "\n",
      "=== 311 ===\n",
      "chunk.text (165 tokens):\n",
      "'AWS Elemental MediaLive Is a broadcast-grade live video processing service. It lets you create nighquality video streams for delivery to broadcast televisions and internet-connected multiscreen devices, such as connected TVs, tablets, smart pnones, and set-top boxes. The service works by encoding your live video streams in real-time, taking a larger-sized live video source and compressing it into smaller versions for distribution to your viewers. With AWS Elemental MediaLive, you can easily set up streams for both live events and 24x7 channels with advanced broadcasting features, high availability, and pay-as-you-go pricing. AWS Elemental MediaLive lets you focus on creating compelling live video experiences for your viewers without the complexity of pbuilding and operating broadcast-grade video processing infrastructure.'\n",
      "chunker.contextualize(chunk) (172 tokens):\n",
      "'AWS Elemental MediaConnect\\nAWS Elemental MediaLive Is a broadcast-grade live video processing service. It lets you create nighquality video streams for delivery to broadcast televisions and internet-connected multiscreen devices, such as connected TVs, tablets, smart pnones, and set-top boxes. The service works by encoding your live video streams in real-time, taking a larger-sized live video source and compressing it into smaller versions for distribution to your viewers. With AWS Elemental MediaLive, you can easily set up streams for both live events and 24x7 channels with advanced broadcasting features, high availability, and pay-as-you-go pricing. AWS Elemental MediaLive lets you focus on creating compelling live video experiences for your viewers without the complexity of pbuilding and operating broadcast-grade video processing infrastructure.'\n",
      "\n",
      "=== 312 ===\n",
      "chunk.text (234 tokens):\n",
      "\"AWS Elemental MediaPackage reliably prepares and protects your video for delivery over the Internet. From a single video input, AWS Elemental MediaPackage creates video streams formatted to play on connected TVs, mobile phones, computers, tablets, and game consoles. It makes it easy to implement popular video features for viewers (Start-over, pause, rewind, and so on), such as those commonly found on DVRs. AWS Elemental MediaPackage can also protect your content using Digital Rignts Management (DRM). AWS Elemental MediaPackage scales automatically in response to load, so your viewers will always get a great experience without you Naving to accurately predict in advance the capacity you'll need.\\nAWS Elemental MediaStore is an AWS storage service optimized for media. It gives you the performance, consistency, and low latency required to deliver live streaming video content. AWS Elemental MediaStore acts as the origin store in your video workflow. Its high performance capabilities meet the needs of the most demanding media delivery workloads, combined with iong-term, cost-effective storage.\"\n",
      "chunker.contextualize(chunk) (240 tokens):\n",
      "\"AWS Elemental MediaPackage\\nAWS Elemental MediaPackage reliably prepares and protects your video for delivery over the Internet. From a single video input, AWS Elemental MediaPackage creates video streams formatted to play on connected TVs, mobile phones, computers, tablets, and game consoles. It makes it easy to implement popular video features for viewers (Start-over, pause, rewind, and so on), such as those commonly found on DVRs. AWS Elemental MediaPackage can also protect your content using Digital Rignts Management (DRM). AWS Elemental MediaPackage scales automatically in response to load, so your viewers will always get a great experience without you Naving to accurately predict in advance the capacity you'll need.\\nAWS Elemental MediaStore is an AWS storage service optimized for media. It gives you the performance, consistency, and low latency required to deliver live streaming video content. AWS Elemental MediaStore acts as the origin store in your video workflow. Its high performance capabilities meet the needs of the most demanding media delivery workloads, combined with iong-term, cost-effective storage.\"\n",
      "\n",
      "=== 313 ===\n",
      "chunk.text (215 tokens):\n",
      "'AWS Elemental MediaTailor lets video providers insert individually targeted advertising into their video streams without sacrificing broadcast-level quality-of-service. With AWS Elemental MediaTailor, viewers of your live or on-demand video each receive a stream that combines your content with ads personalized to them. But unlike other personalized ad solutions, with AWS Elemental MediaTailor your entire stream — video and ads — Is delivered with broadcast-grade video\\nAWS Elemental MediaLive\\nquality to improve the experience for your viewers. AWS Elemental MediaTailor delivers automated reporting based on both client and server-side ad delivery metrics, making it easy to accurately measure ad impressions and viewer benavior. You can easily monetize unexpected nigh-demand viewing events with no up-front costs using AWS Elemental MediaTailor. It also improves ad delivery rates, helping you make more money from every video, and it works with a wider variety of content delivery networks, ad decision servers, and client devices.\\nAlso reter to Amazon Kinesis Video Streams'\n",
      "chunker.contextualize(chunk) (221 tokens):\n",
      "'AWS Elemental MediaTailor\\nAWS Elemental MediaTailor lets video providers insert individually targeted advertising into their video streams without sacrificing broadcast-level quality-of-service. With AWS Elemental MediaTailor, viewers of your live or on-demand video each receive a stream that combines your content with ads personalized to them. But unlike other personalized ad solutions, with AWS Elemental MediaTailor your entire stream — video and ads — Is delivered with broadcast-grade video\\nAWS Elemental MediaLive\\nquality to improve the experience for your viewers. AWS Elemental MediaTailor delivers automated reporting based on both client and server-side ad delivery metrics, making it easy to accurately measure ad impressions and viewer benavior. You can easily monetize unexpected nigh-demand viewing events with no up-front costs using AWS Elemental MediaTailor. It also improves ad delivery rates, helping you make more money from every video, and it works with a wider variety of content delivery networks, ad decision servers, and client devices.\\nAlso reter to Amazon Kinesis Video Streams'\n",
      "\n",
      "=== 314 ===\n",
      "chunk.text (101 tokens):\n",
      "'AWS offers a wide range of migration tools, guidance, services, and programs to help you assess, migrate and modernize applications and data from building the business case to leveraging AWS services to deliver new experiences.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing AWS migration services and tools. For general information, see Migrate and Modernize on AWS.\\nMATE ANL) [RANSFER DATA 1U AND FRUM AWS'\n",
      "chunker.contextualize(chunk) (104 tokens):\n",
      "'Migration and transfer\\nAWS offers a wide range of migration tools, guidance, services, and programs to help you assess, migrate and modernize applications and data from building the business case to leveraging AWS services to deliver new experiences.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing AWS migration services and tools. For general information, see Migrate and Modernize on AWS.\\nMATE ANL) [RANSFER DATA 1U AND FRUM AWS'\n",
      "\n",
      "=== 315 ===\n",
      "chunk.text (54 tokens):\n",
      "'Simplifies, expeadites, Migrates data to and -Transters datasets Securely transfers Tiles and automates largqe- Trommostorthe bdetween on-premises, into and out of AWS\\notner cloud'\n",
      "chunker.contextualize(chunk) (61 tokens):\n",
      "'Streamline data and application migrations\\nSimplifies, expeadites, Migrates data to and -Transters datasets Securely transfers Tiles and automates largqe- Trommostorthe bdetween on-premises, into and out of AWS\\notner cloud'\n",
      "\n",
      "=== 316 ===\n",
      "chunk.text (47 tokens):\n",
      "'e AWS Application Discovery Service\\n¢ AWS Application Migration Service\\ne AWS Database Migration Service\\nMigration and transter 107\\ne AWS Mainframe Modernization Service\\nAWS Migration Hub\\nAWS Snow Family\\nAWS DataSync\\nAWS Transfer Family'\n",
      "chunker.contextualize(chunk) (50 tokens):\n",
      "'Services ana tools\\ne AWS Application Discovery Service\\n¢ AWS Application Migration Service\\ne AWS Database Migration Service\\nMigration and transter 107\\ne AWS Mainframe Modernization Service\\nAWS Migration Hub\\nAWS Snow Family\\nAWS DataSync\\nAWS Transfer Family'\n",
      "\n",
      "=== 317 ===\n",
      "chunk.text (179 tokens):\n",
      "'AWS Application Discovery Service helps enterprise customers plan migration projects by gathering information about their on-premises data centers.\\nPlanning data center migrations can involve thousands of workloads that are often deeply interdependent. Server utilization data and dependency mapping are important early first steps in the migration process. AWS Application Discovery Service collects and presents configuration, usage, and behavior data from your servers to help you better understand your workloads.\\nThe collected data is retained in encrypted format in an AWS Application Discovery Service data store. You can export this data as a CSV file and use it to estimate the Total Cost of Ownership (TCO) of running on AWS and to plan your migration to AWS. In addition, this data is also available in AWS Migration Hub, where you can migrate the discovered servers and track their progress as they get migrated to AWS.'\n",
      "chunker.contextualize(chunk) (184 tokens):\n",
      "'AWS Application Discovery Service\\nAWS Application Discovery Service helps enterprise customers plan migration projects by gathering information about their on-premises data centers.\\nPlanning data center migrations can involve thousands of workloads that are often deeply interdependent. Server utilization data and dependency mapping are important early first steps in the migration process. AWS Application Discovery Service collects and presents configuration, usage, and behavior data from your servers to help you better understand your workloads.\\nThe collected data is retained in encrypted format in an AWS Application Discovery Service data store. You can export this data as a CSV file and use it to estimate the Total Cost of Ownership (TCO) of running on AWS and to plan your migration to AWS. In addition, this data is also available in AWS Migration Hub, where you can migrate the discovered servers and track their progress as they get migrated to AWS.'\n",
      "\n",
      "=== 318 ===\n",
      "chunk.text (130 tokens):\n",
      "'AWS Application Migration Service (AWS MGN) allows you to quickly realize the benefits of migrating applications to the cloud without changes and with minimal downtime.\\nAWS Application Migration Service minimizes time-intensive, error-prone manual processes by automatically converting your source servers from physical, virtual, or cloud infrastructure to run natively on AWS. It further simplifies your migration by enabling you to use the same automated process for a wide range of applications.\\nAnd by launching non-disruptive tests before migrating, you can be confident that your most critical applications such as SAP, Oracle, and SQL Server will work seamlessly on AWS.'\n",
      "chunker.contextualize(chunk) (135 tokens):\n",
      "'AWS Application Migration Service\\nAWS Application Migration Service (AWS MGN) allows you to quickly realize the benefits of migrating applications to the cloud without changes and with minimal downtime.\\nAWS Application Migration Service minimizes time-intensive, error-prone manual processes by automatically converting your source servers from physical, virtual, or cloud infrastructure to run natively on AWS. It further simplifies your migration by enabling you to use the same automated process for a wide range of applications.\\nAnd by launching non-disruptive tests before migrating, you can be confident that your most critical applications such as SAP, Oracle, and SQL Server will work seamlessly on AWS.'\n",
      "\n",
      "=== 319 ===\n",
      "chunk.text (278 tokens):\n",
      "'AWS Database Migration Service (AWS DMS) helps you migrate databases to AWS easily and securely. The source database remains fully operational during the migration, minimizing\\ndowntime to applications that rely on the database. The AWS Database Migration Service can migrate your data to and from most widely used commercial and open-source databases. The service supports homogeneous migrations such as Oracle to Oracle, as well as heterogeneous migrations between different database platforms, such as Oracle to Amazon Aurora or Microsoft SQL Server to MySQL. It also allows you to stream data to Amazon Redshift from any of the Supported sources including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, SAP ASE, and SQL Server, enabling consolidation and easy analysis of data in the petabyte-scale data warehouse. AWS Database Migration Service can also be used for continuous data replication with nigh availability.\\nAWS DMS Serverless offers the flexibility to migrate data without needing to provision replication instances, manually monitoring use, and adjusting capacity. AWS DMS Serverless supports popular use cases including continuous data replication, database consolidation, and migrations, even if the source and target database engines differ. For like-to-like or compatible database engines, you can use built-in tools with automatic scaling for a seamless database migration.'\n",
      "chunker.contextualize(chunk) (283 tokens):\n",
      "'AWS Database Migration Service\\nAWS Database Migration Service (AWS DMS) helps you migrate databases to AWS easily and securely. The source database remains fully operational during the migration, minimizing\\ndowntime to applications that rely on the database. The AWS Database Migration Service can migrate your data to and from most widely used commercial and open-source databases. The service supports homogeneous migrations such as Oracle to Oracle, as well as heterogeneous migrations between different database platforms, such as Oracle to Amazon Aurora or Microsoft SQL Server to MySQL. It also allows you to stream data to Amazon Redshift from any of the Supported sources including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, SAP ASE, and SQL Server, enabling consolidation and easy analysis of data in the petabyte-scale data warehouse. AWS Database Migration Service can also be used for continuous data replication with nigh availability.\\nAWS DMS Serverless offers the flexibility to migrate data without needing to provision replication instances, manually monitoring use, and adjusting capacity. AWS DMS Serverless supports popular use cases including continuous data replication, database consolidation, and migrations, even if the source and target database engines differ. For like-to-like or compatible database engines, you can use built-in tools with automatic scaling for a seamless database migration.'\n",
      "\n",
      "=== 320 ===\n",
      "chunk.text (131 tokens):\n",
      "'AWS Maintrame Modernization Service is a unique service that allows you to migrate your onpremises mainframe workloads to a managed runtime environment on AWS. AWS Mainframe Modernization Service is a set of managed tools providing infrastructure and software Tor migrating, modernizing, and running mainframe applications.\\n« Migrate and modernize your applications to remove the hardware and statting costs of traditional maintrames.\\ne Break up and manage your complete migration with infrastructure, software, and tools to refactor and transform legacy applications.\\ne Deploy, run, and operate migrated applications in the Mainframe Modernization environment with no uptront costs.'\n",
      "chunker.contextualize(chunk) (138 tokens):\n",
      "'AWS Maintrame Modernization Service\\nAWS Maintrame Modernization Service is a unique service that allows you to migrate your onpremises mainframe workloads to a managed runtime environment on AWS. AWS Mainframe Modernization Service is a set of managed tools providing infrastructure and software Tor migrating, modernizing, and running mainframe applications.\\n« Migrate and modernize your applications to remove the hardware and statting costs of traditional maintrames.\\ne Break up and manage your complete migration with infrastructure, software, and tools to refactor and transform legacy applications.\\ne Deploy, run, and operate migrated applications in the Mainframe Modernization environment with no uptront costs.'\n",
      "\n",
      "=== 321 ===\n",
      "chunk.text (206 tokens):\n",
      "'AWS Migration Hub provides a single location to track the progress of application migrations across multiple AWS and partner solutions. Using Migration Hub allows you to choose the AWS and partner migration tools that best nit your needs, while providing visibility into the status of migrations across your portfolio of applications. Migration Hub also provides key metrics and progress Tor individual applications, regardless of wnich tools are being used to migrate them. For\\nexample, you might use AWS Database Migration Service, AWS Application Migration Service, and partner migration tools such as ATADATA ATAmotion, CloudEndure Live Migration, or RiverMeadow Server Migration Saas to migrate an application comprised of a database, virtualized web servers, and a bare metal server. Using Migration Hub, you can view the migration progress of all the resources in the application. This allows you to quickly get progress updates across all of your migrations, easily identify and troubleshoot any issues, and reduce the overall time and effort spent on your migration projects.'\n",
      "chunker.contextualize(chunk) (210 tokens):\n",
      "'AWS Migration Hub\\nAWS Migration Hub provides a single location to track the progress of application migrations across multiple AWS and partner solutions. Using Migration Hub allows you to choose the AWS and partner migration tools that best nit your needs, while providing visibility into the status of migrations across your portfolio of applications. Migration Hub also provides key metrics and progress Tor individual applications, regardless of wnich tools are being used to migrate them. For\\nexample, you might use AWS Database Migration Service, AWS Application Migration Service, and partner migration tools such as ATADATA ATAmotion, CloudEndure Live Migration, or RiverMeadow Server Migration Saas to migrate an application comprised of a database, virtualized web servers, and a bare metal server. Using Migration Hub, you can view the migration progress of all the resources in the application. This allows you to quickly get progress updates across all of your migrations, easily identify and troubleshoot any issues, and reduce the overall time and effort spent on your migration projects.'\n",
      "\n",
      "=== 322 ===\n",
      "chunk.text (364 tokens):\n",
      "\"The AWS Snow Family helps customers that need to run operations in austere, non-data center environments, and in locations where there's lack of consistent network connectivity. The Snow Family comprises AWS Snowball and AWS Snowball Edge, and offers a number of physical devices and capacity points, most with built-in computing capabilities. These services help physically transport up to exabytes of data into and out of AWS. Snow Family devices are owned and managed by AWS and integrate with AWS security, monitoring, storage management, and computing capabilities.\\nAWS Snowball is the smallest member of the AWS Snow Family of edge computing, edge storage, and data transfer devices, weighing in at 4.5 pounds (2.1 kg) with 8 terabytes of usable storage. The Snowball appliance is ruggedized, secure, and purpose-built for use outside of a traditional data center. Its small form factor makes it a perfect fit for tight spaces or where portability is a necessity and network connectivity is unreliable. You can use Snowball in backpacks on first responders, or for Internet of Things (loT), vehicular, and drone use cases. You can run compute applications at the edge, and you can ship the device with data to AWS for offline data transfer, or you can transfer data online with AWS DataSync from edge locations.\\nLike AWS Snowball Edge, AWS Snowball has multiple layers of security and encryption. You can use either of these services to run edge computing workloads, or to collect, process, and transfer data to AWS. Snowball is designed for data migration needs up to 8 terabytes per device and from Space-constrained environments where Snowball Edge devices will not fit.\"\n",
      "chunker.contextualize(chunk) (368 tokens):\n",
      "\"AWS Snow Family\\nThe AWS Snow Family helps customers that need to run operations in austere, non-data center environments, and in locations where there's lack of consistent network connectivity. The Snow Family comprises AWS Snowball and AWS Snowball Edge, and offers a number of physical devices and capacity points, most with built-in computing capabilities. These services help physically transport up to exabytes of data into and out of AWS. Snow Family devices are owned and managed by AWS and integrate with AWS security, monitoring, storage management, and computing capabilities.\\nAWS Snowball is the smallest member of the AWS Snow Family of edge computing, edge storage, and data transfer devices, weighing in at 4.5 pounds (2.1 kg) with 8 terabytes of usable storage. The Snowball appliance is ruggedized, secure, and purpose-built for use outside of a traditional data center. Its small form factor makes it a perfect fit for tight spaces or where portability is a necessity and network connectivity is unreliable. You can use Snowball in backpacks on first responders, or for Internet of Things (loT), vehicular, and drone use cases. You can run compute applications at the edge, and you can ship the device with data to AWS for offline data transfer, or you can transfer data online with AWS DataSync from edge locations.\\nLike AWS Snowball Edge, AWS Snowball has multiple layers of security and encryption. You can use either of these services to run edge computing workloads, or to collect, process, and transfer data to AWS. Snowball is designed for data migration needs up to 8 terabytes per device and from Space-constrained environments where Snowball Edge devices will not fit.\"\n",
      "\n",
      "=== 323 ===\n",
      "chunk.text (501 tokens):\n",
      "'AWS Snowball Edge is an edge computing, data migration, and edge storage device. Snowball Edge can do local processing and run edge-computing workloads in addition to transferring data\\nAWS Snow Family 110\\nbetween your local environment and the AWS Cloud. Each Snowball Edge device can transport data at speeds faster than the internet. This transport is done by shipping the data in the devices througn a regional carrier.\\nSnowball Edge devices Nave five options for device configurations:\\ne Storage-optimized for data transfer, with up to 80 TB of usable storage capacity. They are well Suited Tor local storage and large scale data transfer.\\ne Storage-optimized 210 TB, with 210 TB of usable storage capacity\\ne Storage-optimized with EC2-compatible compute functionality, with up to 80 TB of usable storage capacity, 40 vCPUs, and 80 GB of memory for compute functionality\\n¢ Compute-optimized, with the AMD EPYC Gen2 having the most compute functionality with up to 104 vCPUs, 416 GB of memory, and 28 TB of dedicated NVMe SSD for compute instances. The AMD EPYC Gen1 has up to 52 vCPUs, 208 GB of memory, 39.5 TB of usable storage capacity, and 7.68 TB of dedicated NVMe SSD for compute instances.\\nYou can use these devices for data collection, machine learning (ML) and processing, and storage in environments with intermittent connectivity (such as manufacturing, industrial, and transportation) or in extremely remote locations (such as military or maritime operations) before shipping them back to AWS.\\n- e Compute-optimized with GPU is identical to the compute-optimized AMD EPYC Gen1 option, but also includes an installed graphics processing unit (GPU). The GPU is equivalent to the one available in the PS Amazon EC2-compatible instance type. You can use these devices for advanced ML workloads and Tull motion video analysis in disconnected environments.\\nThese devices can also be rack mounted and clustered together to build larger temporary installations.\\nSnowball supports specific Amazon EC2 instance types and AWS Lambda functions, so you can develop and test in the AWS Cloud, then deploy applications on devices in remote locations to collect, pre-process, and ship the data to AWS. Common use cases include data migration, data transport, image collation, lol sensor stream capture, and ML.'\n",
      "chunker.contextualize(chunk) (506 tokens):\n",
      "'AWS Snowball Edge\\nAWS Snowball Edge is an edge computing, data migration, and edge storage device. Snowball Edge can do local processing and run edge-computing workloads in addition to transferring data\\nAWS Snow Family 110\\nbetween your local environment and the AWS Cloud. Each Snowball Edge device can transport data at speeds faster than the internet. This transport is done by shipping the data in the devices througn a regional carrier.\\nSnowball Edge devices Nave five options for device configurations:\\ne Storage-optimized for data transfer, with up to 80 TB of usable storage capacity. They are well Suited Tor local storage and large scale data transfer.\\ne Storage-optimized 210 TB, with 210 TB of usable storage capacity\\ne Storage-optimized with EC2-compatible compute functionality, with up to 80 TB of usable storage capacity, 40 vCPUs, and 80 GB of memory for compute functionality\\n¢ Compute-optimized, with the AMD EPYC Gen2 having the most compute functionality with up to 104 vCPUs, 416 GB of memory, and 28 TB of dedicated NVMe SSD for compute instances. The AMD EPYC Gen1 has up to 52 vCPUs, 208 GB of memory, 39.5 TB of usable storage capacity, and 7.68 TB of dedicated NVMe SSD for compute instances.\\nYou can use these devices for data collection, machine learning (ML) and processing, and storage in environments with intermittent connectivity (such as manufacturing, industrial, and transportation) or in extremely remote locations (such as military or maritime operations) before shipping them back to AWS.\\n- e Compute-optimized with GPU is identical to the compute-optimized AMD EPYC Gen1 option, but also includes an installed graphics processing unit (GPU). The GPU is equivalent to the one available in the PS Amazon EC2-compatible instance type. You can use these devices for advanced ML workloads and Tull motion video analysis in disconnected environments.\\nThese devices can also be rack mounted and clustered together to build larger temporary installations.\\nSnowball supports specific Amazon EC2 instance types and AWS Lambda functions, so you can develop and test in the AWS Cloud, then deploy applications on devices in remote locations to collect, pre-process, and ship the data to AWS. Common use cases include data migration, data transport, image collation, lol sensor stream capture, and ML.'\n",
      "\n",
      "=== 324 ===\n",
      "chunk.text (269 tokens):\n",
      "\"AWS DataSync is a data transfer service that makes it easy for you to automate moving data between on-premises storage and Amazon $3 or Amazon Elastic File System (Amazon EFS).\\nAWS DataSync V4\\nDataSync automatically handles many of the tasks related to data transfers that can slow down migrations or burden your IT operations, including running your own instances, nandling encryption, managing scripts, network optimization, and data integrity validation. You can use DataSync to transfer data at speeds up to 10 times faster than open-source tools. DataSync uses an on-premises software agent to connect to your existing storage or file systems using the Network File System (NFS) protocol, so you don't have write scripts or modify your applications to work with AWS APIs. You can use DataSync to copy data over AWS Direct Connect or internet links to AWS. The service enables one-time data migrations, recurring data processing workflows, and automated replication for data protection and recovery. Getting started with DataSync is easy: Deploy the DataSync agent on premises, connect it to a file system or storage array, select Amazon EFS or Amazon S34 as your AWS storage, and start moving data. You pay only for the data you copy.\"\n",
      "chunker.contextualize(chunk) (274 tokens):\n",
      "\"AWS DataSync\\nAWS DataSync is a data transfer service that makes it easy for you to automate moving data between on-premises storage and Amazon $3 or Amazon Elastic File System (Amazon EFS).\\nAWS DataSync V4\\nDataSync automatically handles many of the tasks related to data transfers that can slow down migrations or burden your IT operations, including running your own instances, nandling encryption, managing scripts, network optimization, and data integrity validation. You can use DataSync to transfer data at speeds up to 10 times faster than open-source tools. DataSync uses an on-premises software agent to connect to your existing storage or file systems using the Network File System (NFS) protocol, so you don't have write scripts or modify your applications to work with AWS APIs. You can use DataSync to copy data over AWS Direct Connect or internet links to AWS. The service enables one-time data migrations, recurring data processing workflows, and automated replication for data protection and recovery. Getting started with DataSync is easy: Deploy the DataSync agent on premises, connect it to a file system or storage array, select Amazon EFS or Amazon S34 as your AWS storage, and start moving data. You pay only for the data you copy.\"\n",
      "\n",
      "=== 325 ===\n",
      "chunk.text (169 tokens):\n",
      "'AWS Transter Family provides fully managed support for file transfers directly into and out of Amazon $4 or Amazon EFS. With support for Secure File Transter Protocol (SFTP), File Transter Protocol over SSL (FTPS), and File Transfer Protocol (FTP), the AWS Transfer Family helps you seamlessly migrate your file transfer workTtlows to AWS by integrating with existing authentication systems, and providing DNS routing with Amazon Route 53 so nothing changes for your customers and partners, or their applications. With your data in Amazon S34 or Amazon EFS, you can use it with AWS services for processing, analytics, ML, archiving, as well as home directories and developer tools. Getting started with the AWS Transfer Family is easy; there is no infrastructure to buy and set up.'\n",
      "chunker.contextualize(chunk) (173 tokens):\n",
      "'AWS Transfer Family\\nAWS Transter Family provides fully managed support for file transfers directly into and out of Amazon $4 or Amazon EFS. With support for Secure File Transter Protocol (SFTP), File Transter Protocol over SSL (FTPS), and File Transfer Protocol (FTP), the AWS Transfer Family helps you seamlessly migrate your file transfer workTtlows to AWS by integrating with existing authentication systems, and providing DNS routing with Amazon Route 53 so nothing changes for your customers and partners, or their applications. With your data in Amazon S34 or Amazon EFS, you can use it with AWS services for processing, analytics, ML, archiving, as well as home directories and developer tools. Getting started with the AWS Transfer Family is easy; there is no infrastructure to buy and set up.'\n",
      "\n",
      "=== 326 ===\n",
      "chunk.text (75 tokens):\n",
      "'AWS offers a broad set of networking and content delivery services that provide the highest level of reliability, security, and performance in the cloud.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS networking and content delivery service. For general information, see AWS Networking and Content Delivery.\\nAWS Transfer Family 112'\n",
      "chunker.contextualize(chunk) (79 tokens):\n",
      "'Networking and content delivery\\nAWS offers a broad set of networking and content delivery services that provide the highest level of reliability, security, and performance in the cloud.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS networking and content delivery service. For general information, see AWS Networking and Content Delivery.\\nAWS Transfer Family 112'\n",
      "\n",
      "=== 327 ===\n",
      "chunk.text (51 tokens):\n",
      "'e Amazon API Gateway\\ne Amazon CloudFront\\ne Amazon Route 545\\ne Amazon VPC Lattice\\ne AWS App Mesh\\ne AWS Cloud Map\\ne AWS Global Accelerator\\ne AWS Transit Gateway\\ne Elastic Load Balancing\\ne Integrated Private Wiretess on AWS'\n",
      "chunker.contextualize(chunk) (52 tokens):\n",
      "'Services\\ne Amazon API Gateway\\ne Amazon CloudFront\\ne Amazon Route 545\\ne Amazon VPC Lattice\\ne AWS App Mesh\\ne AWS Cloud Map\\ne AWS Global Accelerator\\ne AWS Transit Gateway\\ne Elastic Load Balancing\\ne Integrated Private Wiretess on AWS'\n",
      "\n",
      "=== 328 ===\n",
      "chunk.text (137 tokens):\n",
      "'Amazon API Gateway is a Tully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. With a few clicks in the AWS Management Console, you can create an API that acts as a \"front door\" for applications to access data, business logic, or functionality from your back-end services, such as workloads running on Amazon EC2, code running on AWS Lambada, or any web application. Amazon API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including trafic management, authorization and access control, monitoring, and API version management.'\n",
      "chunker.contextualize(chunk) (140 tokens):\n",
      "'Amazon API Gateway\\nAmazon API Gateway is a Tully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. With a few clicks in the AWS Management Console, you can create an API that acts as a \"front door\" for applications to access data, business logic, or functionality from your back-end services, such as workloads running on Amazon EC2, code running on AWS Lambada, or any web application. Amazon API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including trafic management, authorization and access control, monitoring, and API version management.'\n",
      "\n",
      "=== 329 ===\n",
      "chunk.text (223 tokens):\n",
      "\"Amazon CloudFront ts a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-triendly environment. CloudFront is integrated with AWS poth physical locations that are directly connected to the AWS global infrastructure, as well as other AWS services. CloudFront works seamlessly with services including AWS Shield for DDoS mitigation, Amazon S34, Elastic Load Balancing or Amazon EC2 as origins for your applications, and Lambda@Edge to run custom code closer to customers' users and to customize the user experience.\\nYou can get started with the content delivery network in minutes, using the same AWS tools that you're already familiar with: APIs, AWS Management Console, AWS CloudFormation, CLIs, and SDKs. Amazon CDN offers a simple, pay-as-you-go pricing model with no upfront fees or required long-term contracts, and support for the CDN is included in your existing Support subscription.\"\n",
      "chunker.contextualize(chunk) (226 tokens):\n",
      "\"Amazon CloudFront\\nAmazon CloudFront ts a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-triendly environment. CloudFront is integrated with AWS poth physical locations that are directly connected to the AWS global infrastructure, as well as other AWS services. CloudFront works seamlessly with services including AWS Shield for DDoS mitigation, Amazon S34, Elastic Load Balancing or Amazon EC2 as origins for your applications, and Lambda@Edge to run custom code closer to customers' users and to customize the user experience.\\nYou can get started with the content delivery network in minutes, using the same AWS tools that you're already familiar with: APIs, AWS Management Console, AWS CloudFormation, CLIs, and SDKs. Amazon CDN offers a simple, pay-as-you-go pricing model with no upfront fees or required long-term contracts, and support for the CDN is included in your existing Support subscription.\"\n",
      "\n",
      "=== 330 ===\n",
      "chunk.text (333 tokens):\n",
      "\"Amazon Route 53 ts a highly available and scalable cloud Domain Name System (DNS) web service. It is designed to give developers and businesses an extremely reliable and cost-effective way to route users to internet applications by translating Numan-readable names, sucn as www.example.com, into the numeric IP addresses, such as 192.0.2.1, that computers use to connect to each other. Amazon Route 53 is fully compliant with IPv6 as well.\\nAmazon Route 53 effectively connects user requests to infrastructure running in AWS—such as EC2 instances, elastic load balancers, or Amazon $3 bDuckets—and can also be used to route users to infrastructure outside of AWS. You can use Amazon Route 53 to configure DNS health checks to route traffic to healthy endpoints or to independently monitor the health of your application and its endpoints.\\nAmazon Route 53 traffic flow makes it easy for you to manage traffic globally through a variety of routing types, including latency-based routing, Geo DNS, and weighted round robin—all of which can be combined with DNS Failover in order to enable a variety of low-latency, fault-tolerant architectures. Using Amazon Route 53 traffic flow's simple visual editor, you can easily manage now your end users are routed to your application's endpoints—whether in a single AWS Region or distributed around the globe. Amazon Route 53 also offers Domain Name Registration— you can purchase and manage domain names such as example.com and Amazon Route 53 will automatically configure DNS settings for your domains.\"\n",
      "chunker.contextualize(chunk) (336 tokens):\n",
      "\"Amazon Route 55\\nAmazon Route 53 ts a highly available and scalable cloud Domain Name System (DNS) web service. It is designed to give developers and businesses an extremely reliable and cost-effective way to route users to internet applications by translating Numan-readable names, sucn as www.example.com, into the numeric IP addresses, such as 192.0.2.1, that computers use to connect to each other. Amazon Route 53 is fully compliant with IPv6 as well.\\nAmazon Route 53 effectively connects user requests to infrastructure running in AWS—such as EC2 instances, elastic load balancers, or Amazon $3 bDuckets—and can also be used to route users to infrastructure outside of AWS. You can use Amazon Route 53 to configure DNS health checks to route traffic to healthy endpoints or to independently monitor the health of your application and its endpoints.\\nAmazon Route 53 traffic flow makes it easy for you to manage traffic globally through a variety of routing types, including latency-based routing, Geo DNS, and weighted round robin—all of which can be combined with DNS Failover in order to enable a variety of low-latency, fault-tolerant architectures. Using Amazon Route 53 traffic flow's simple visual editor, you can easily manage now your end users are routed to your application's endpoints—whether in a single AWS Region or distributed around the globe. Amazon Route 53 also offers Domain Name Registration— you can purchase and manage domain names such as example.com and Amazon Route 53 will automatically configure DNS settings for your domains.\"\n",
      "\n",
      "=== 331 ===\n",
      "chunk.text (83 tokens):\n",
      "'AWS Verified Access provides corporate users secure access to your applications without using a virtual private network (VPN). Based on AWS Zero Trust principles, Verified Access evaluates each application request in real time to help ensure that users can only access your applications after they meet specified security requirements. You can group applications, or define unique access policies for each application, with conditions based on user identity and device posture data.'\n",
      "chunker.contextualize(chunk) (87 tokens):\n",
      "'AWS Verified Access\\nAWS Verified Access provides corporate users secure access to your applications without using a virtual private network (VPN). Based on AWS Zero Trust principles, Verified Access evaluates each application request in real time to help ensure that users can only access your applications after they meet specified security requirements. You can group applications, or define unique access policies for each application, with conditions based on user identity and device posture data.'\n",
      "\n",
      "=== 332 ===\n",
      "chunk.text (227 tokens):\n",
      "'Amazon Virtual Private Cloud (Amazon VPC) lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define. You nave complete control over your virtual networking environment, including selection of your own IP address range, creation of subnets, and configuration of route tables and network gateways. You can use both IPv4 and IPv6 in your VPC for secure and easy access to resources and applications.\\nYou can easily customize the network configuration for your VPC. For example, you can create a public-facing subnet for your web servers that has access to the Internet, and place your backend systems, such as databases or application servers, in a private-facing subnet with no Internet access. You can leverage multiple layers of security (including security groups and network access control lists) to help control access to EC2 instances in each subnet.\\nAdditionally, you can create a hardware virtual private network (VPN) connection between your corporate data center and your VPC and leverage the AWS Cloud as an extension of your corporate data center.'\n",
      "chunker.contextualize(chunk) (230 tokens):\n",
      "'Amazon VPC\\nAmazon Virtual Private Cloud (Amazon VPC) lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define. You nave complete control over your virtual networking environment, including selection of your own IP address range, creation of subnets, and configuration of route tables and network gateways. You can use both IPv4 and IPv6 in your VPC for secure and easy access to resources and applications.\\nYou can easily customize the network configuration for your VPC. For example, you can create a public-facing subnet for your web servers that has access to the Internet, and place your backend systems, such as databases or application servers, in a private-facing subnet with no Internet access. You can leverage multiple layers of security (including security groups and network access control lists) to help control access to EC2 instances in each subnet.\\nAdditionally, you can create a hardware virtual private network (VPN) connection between your corporate data center and your VPC and leverage the AWS Cloud as an extension of your corporate data center.'\n",
      "\n",
      "=== 333 ===\n",
      "chunk.text (65 tokens):\n",
      "'Amazon VPC Lattice provides fully managed support for service-to-service connectivity and communication. With VPC Lattice, you can use policies to define network tratiic management,\\nAWS Verined Access\\naccess, and monitoring to connect compute services in a simplified and secure way across instances, containers, and serverless applications.'\n",
      "chunker.contextualize(chunk) (69 tokens):\n",
      "'Amazon VPC Lattice\\nAmazon VPC Lattice provides fully managed support for service-to-service connectivity and communication. With VPC Lattice, you can use policies to define network tratiic management,\\nAWS Verined Access\\naccess, and monitoring to connect compute services in a simplified and secure way across instances, containers, and serverless applications.'\n",
      "\n",
      "=== 334 ===\n",
      "chunk.text (372 tokens):\n",
      "'AWS App Mesh makes It easy to monitor and control microservices running on AWS. App Mesn standardizes how your microservices communicate, giving you end-to-end visibility and helping to ensure high-availability for your applications.\\nModern applications are often composed of multiple microservices that each perform a specific function. This architecture helps to increase the availability and scalability of the application by allowing each component to scale independently based on demand, and automatically degrading functionality when a component fails instead of going offline. Each microservice interacts with all the other microservices through an API. As the number of microservices grows within an application, it becomes increasingly difficult to pinpoint the exact location of errors, re-route traffic after failures, and safely deploy code changes. Previously, this has required you to build monitoring and control logic directly into your code and redeploy your microservices every time there are changes.\\nAWS App Mesh makes it easy to run microservices by providing consistent visibility and network traffic controls for every microservice in an application. App Mesh removes the need to update application code to change how monitoring data is collected or traffic is routed between microservices. App Mesh configures each microservice to export monitoring data and implements consistent communications control logic across your application. This makes it easy to quickly pinpoint the exact location of errors and automatically re-route network traffic when there are failures or when code changes need to be deployed.\\nYou can use App Mesh with Amazon ECS and Amazon EKS to better run containerized microservices at scale. App Mesh uses the open source Envoy proxy, making it compatible with a wide range of AWS partner and open source tools for monitoring microservices.'\n",
      "chunker.contextualize(chunk) (376 tokens):\n",
      "'AWS App Mesh\\nAWS App Mesh makes It easy to monitor and control microservices running on AWS. App Mesn standardizes how your microservices communicate, giving you end-to-end visibility and helping to ensure high-availability for your applications.\\nModern applications are often composed of multiple microservices that each perform a specific function. This architecture helps to increase the availability and scalability of the application by allowing each component to scale independently based on demand, and automatically degrading functionality when a component fails instead of going offline. Each microservice interacts with all the other microservices through an API. As the number of microservices grows within an application, it becomes increasingly difficult to pinpoint the exact location of errors, re-route traffic after failures, and safely deploy code changes. Previously, this has required you to build monitoring and control logic directly into your code and redeploy your microservices every time there are changes.\\nAWS App Mesh makes it easy to run microservices by providing consistent visibility and network traffic controls for every microservice in an application. App Mesh removes the need to update application code to change how monitoring data is collected or traffic is routed between microservices. App Mesh configures each microservice to export monitoring data and implements consistent communications control logic across your application. This makes it easy to quickly pinpoint the exact location of errors and automatically re-route network traffic when there are failures or when code changes need to be deployed.\\nYou can use App Mesh with Amazon ECS and Amazon EKS to better run containerized microservices at scale. App Mesh uses the open source Envoy proxy, making it compatible with a wide range of AWS partner and open source tools for monitoring microservices.'\n",
      "\n",
      "=== 335 ===\n",
      "chunk.text (296 tokens):\n",
      "'AWS Cloud Map is a cloud resource discovery service. With AWS Cloud Map, you can define custom names for your application resources, and it maintains the updated location of these dynamically changing resources. This increases your application availability because your web service always discovers the most up-to-date locations of its resources.\\nModern applications are typically composed of multiple services that are accessible over an API and perform a specific function. Each service interacts with a variety of other resources such as\\nAWS App Mesh 116\\ndatabases, queues, object stores, and customer-defined microservices, and they also need to be able to find the location of all the infrastructure resources on which it depends, in order to function. You typically manually manage all these resource names and their locations within the application code. However, manual resource management becomes time consuming and error-prone as the number of dependent infrastructure resources increases or the number of microservices dynamically scale up and down based on traffic. You can also use third-party service discovery products, but this requires installing and managing additional software and infrastructure.\\nAWS Cloud Map allows you to register any application resources such as databases, queues, microservices, and other cloud resources with custom names. AWS Cloud Map then constantly checks the health of resources to make sure the location is up-to-date. The application can then query the registry for the location of the resources needed based on the application version and deployment environment.'\n",
      "chunker.contextualize(chunk) (301 tokens):\n",
      "'AWS Ctoud Map\\nAWS Cloud Map is a cloud resource discovery service. With AWS Cloud Map, you can define custom names for your application resources, and it maintains the updated location of these dynamically changing resources. This increases your application availability because your web service always discovers the most up-to-date locations of its resources.\\nModern applications are typically composed of multiple services that are accessible over an API and perform a specific function. Each service interacts with a variety of other resources such as\\nAWS App Mesh 116\\ndatabases, queues, object stores, and customer-defined microservices, and they also need to be able to find the location of all the infrastructure resources on which it depends, in order to function. You typically manually manage all these resource names and their locations within the application code. However, manual resource management becomes time consuming and error-prone as the number of dependent infrastructure resources increases or the number of microservices dynamically scale up and down based on traffic. You can also use third-party service discovery products, but this requires installing and managing additional software and infrastructure.\\nAWS Cloud Map allows you to register any application resources such as databases, queues, microservices, and other cloud resources with custom names. AWS Cloud Map then constantly checks the health of resources to make sure the location is up-to-date. The application can then query the registry for the location of the resources needed based on the application version and deployment environment.'\n",
      "\n",
      "=== 336 ===\n",
      "chunk.text (442 tokens):\n",
      "\"AWS Direct Connect makes it easy to establish a dedicated network connection from your premises to AWS. Using AWS Direct Connect, you can establish private connectivity between AWS and your data center, office, or co-location environment, which in many cases can reduce your network costs, increase bandwidth throughput, and provide a more consistent network experience than Internetbased connections.\\nAWS Direct Connect lets you establish a dedicated network connection between your network and one of the AWS Direct Connect locations. Using industry standard 802.1Q virtual LANs (VLANs), this dedicated connection can be partitioned into multiple virtual interfaces. This allows you to use the same connection to access public resources, such as objects stored in Amazon $3 using public IP address space, and private resources such as EC2 instances running within a VPC using private IP address space, while maintaining network separation between the public and private environments. Virtual interfaces can be reconfigured at any time to meet your changing needs.\\nAWS Global Accelerator is a networking service that improves the availability and performance of the applications that you offer to your global users.\\nToday, if you deliver applications to your global users over the public internet, your users might face inconsistent availability and performance as they traverse through multiple public networks to reach your application. These public networks are often congested and each hop can introduce\\nAWS Direct Connect\\navailability and performance risk. AWS Global Accelerator uses the highly available and congestionfree AWS global network to direct internet traffic from your users to your applications on AWS, making your users' experience more consistent.\\nTo improve the availability of your application, you must monitor the health of your application endpoints and route traffic only to healthy endpoints. AWS Global Accelerator improves application availability by continuously monitoring the health of your application endpoints and routing traffic to the closest healthy endpoints.\\nAWS Global Accelerator also makes it easier to manage your global applications by providing static IP addresses that act as a fixed entry point to your application hosted on AWS which eliminates the complexity of managing specific IP addresses for different AWS Regions and Availability Zones. AWS Global Accelerator is easy to set up, configure and manage.\"\n",
      "chunker.contextualize(chunk) (446 tokens):\n",
      "\"AWS Direct Connect\\nAWS Direct Connect makes it easy to establish a dedicated network connection from your premises to AWS. Using AWS Direct Connect, you can establish private connectivity between AWS and your data center, office, or co-location environment, which in many cases can reduce your network costs, increase bandwidth throughput, and provide a more consistent network experience than Internetbased connections.\\nAWS Direct Connect lets you establish a dedicated network connection between your network and one of the AWS Direct Connect locations. Using industry standard 802.1Q virtual LANs (VLANs), this dedicated connection can be partitioned into multiple virtual interfaces. This allows you to use the same connection to access public resources, such as objects stored in Amazon $3 using public IP address space, and private resources such as EC2 instances running within a VPC using private IP address space, while maintaining network separation between the public and private environments. Virtual interfaces can be reconfigured at any time to meet your changing needs.\\nAWS Global Accelerator is a networking service that improves the availability and performance of the applications that you offer to your global users.\\nToday, if you deliver applications to your global users over the public internet, your users might face inconsistent availability and performance as they traverse through multiple public networks to reach your application. These public networks are often congested and each hop can introduce\\nAWS Direct Connect\\navailability and performance risk. AWS Global Accelerator uses the highly available and congestionfree AWS global network to direct internet traffic from your users to your applications on AWS, making your users' experience more consistent.\\nTo improve the availability of your application, you must monitor the health of your application endpoints and route traffic only to healthy endpoints. AWS Global Accelerator improves application availability by continuously monitoring the health of your application endpoints and routing traffic to the closest healthy endpoints.\\nAWS Global Accelerator also makes it easier to manage your global applications by providing static IP addresses that act as a fixed entry point to your application hosted on AWS which eliminates the complexity of managing specific IP addresses for different AWS Regions and Availability Zones. AWS Global Accelerator is easy to set up, configure and manage.\"\n",
      "\n",
      "=== 337 ===\n",
      "chunk.text (79 tokens):\n",
      "'AWS PrivateLink simplifies the security of data shared with cloud-based applications by eliminating the exposure of data to the public Internet. AWS PrivateLink provides private connectivity between VPCs, AWS services, and on-premises applications, securely on the Amazon network. AWS PrivateLink makes it easy to connect services across different accounts and VPCs to significantly simplify the network architecture.'\n",
      "chunker.contextualize(chunk) (83 tokens):\n",
      "'AWS PrivateLink\\nAWS PrivateLink simplifies the security of data shared with cloud-based applications by eliminating the exposure of data to the public Internet. AWS PrivateLink provides private connectivity between VPCs, AWS services, and on-premises applications, securely on the Amazon network. AWS PrivateLink makes it easy to connect services across different accounts and VPCs to significantly simplify the network architecture.'\n",
      "\n",
      "=== 338 ===\n",
      "chunk.text (333 tokens):\n",
      "'AWS Private 5G offers an easy way to use cellular technology to augment your current network. This can help you increase reliability, extend coverage, or allow a new class of workloads, such as factory automation, autonomous robotics, and advanced augmented and virtual reality (AR/VR). You will receive all the Private 5G hardware (including SIM cards) and software you need to deploy your private cellular network and connect devices to your applications.\\nWith a Tew clicks in the AWS Management Console, deploy a private cellular network that meets your connectivity requirements. Start by specifying the connectivity requirements Tor the desired Location, the number of devices you want to connect, and the geographic area they will cover. AWS will deliver pre-integrated hardware and software components (from both AWS and our AWS Partners) that meet the enterprise connectivity requirements of your private network. AWS delivers and maintains the small cell radio units, servers, 5G core, radio access network (RAN) software, and SIM cards required to set up a private 5G network and connect devices. Once the equipment Is powered on, AWS automatically configures and deploys the cellular network. All you need to do is insert the SIM cards into your devices.\\nAWS PrivateLink\\nAWS Private 5G Is also integrated with AWS Identity and Access Management (IAM), which helps you securely access and manage AWS services and resources, including all devices connected to your Private 5G network. Private 5G manages and maintains all the software and hardware components to deliver reliable, predictable network behavior and on-demand scaling to accommodate any number of devices and sensors.'\n",
      "chunker.contextualize(chunk) (338 tokens):\n",
      "'AWS Private 5G\\nAWS Private 5G offers an easy way to use cellular technology to augment your current network. This can help you increase reliability, extend coverage, or allow a new class of workloads, such as factory automation, autonomous robotics, and advanced augmented and virtual reality (AR/VR). You will receive all the Private 5G hardware (including SIM cards) and software you need to deploy your private cellular network and connect devices to your applications.\\nWith a Tew clicks in the AWS Management Console, deploy a private cellular network that meets your connectivity requirements. Start by specifying the connectivity requirements Tor the desired Location, the number of devices you want to connect, and the geographic area they will cover. AWS will deliver pre-integrated hardware and software components (from both AWS and our AWS Partners) that meet the enterprise connectivity requirements of your private network. AWS delivers and maintains the small cell radio units, servers, 5G core, radio access network (RAN) software, and SIM cards required to set up a private 5G network and connect devices. Once the equipment Is powered on, AWS automatically configures and deploys the cellular network. All you need to do is insert the SIM cards into your devices.\\nAWS PrivateLink\\nAWS Private 5G Is also integrated with AWS Identity and Access Management (IAM), which helps you securely access and manage AWS services and resources, including all devices connected to your Private 5G network. Private 5G manages and maintains all the software and hardware components to deliver reliable, predictable network behavior and on-demand scaling to accommodate any number of devices and sensors.'\n",
      "\n",
      "=== 339 ===\n",
      "chunk.text (444 tokens):\n",
      "'AWS Transit Gateway is a service that enables customers to connect their Amazon Virtual Private Clouds (VPCs) and their on-premises networks to a single gateway. As you grow the number of workloads running on AWS, you need to be able to scale your networks across multiple accounts and Amazon VPCs to keep up with the growth. Today, you can connect pairs of Amazon VPCs using peering. However, managing point-to-point connectivity across many Amazon VPCs, without the ability to centrally manage the connectivity policies, can be operationally costly and cumbersome. For on-premises connectivity, you need to attach your AWS VPN to each individual Amazon VPC. This solution can be time consuming to build and hard to manage when the number of VPCs grows into the hunareas.\\nWith AWS Transit Gateway, you only have to create and manage a single connection from the central gateway in to each Amazon VPC, on-premises data center, or remote office across your network. Transit Gateway acts as a hub that controls how traffic is routed among all the connected networks which act like spokes. This hub and spoke model significantly simplifies management and reduces operational costs because each network only has to connect to the Transit Gateway and not to every other network. Any new VPC is simply connected to the Transit Gateway and Is then automatically available to every other network that is connected to the Transit Gateway. This ease of connectivity makes it easy to scale your network as you grow.\\nAWS Virtual Private Network (AWS VPN) solutions establish secure connections between your on-premises networks, remote offices, client devices, and the AWS global network. AWS VPN Is comprised of two services: AWS Site-to-Site VPN and AWS Client VPN. Each service provides a highly-available, managed, and elastic cloud VPN solution to protect your network traffic.\\nAWS Site-to-Site VPN creates encrypted tunnels between your network and your Amazon Virtual Private Clouds or AWS Transit Gateways. For managing remote access, AWS Client VPN connects your users to AWS or on-premises resources using a VPN software client.'\n",
      "chunker.contextualize(chunk) (448 tokens):\n",
      "'AWS Transit Gateway\\nAWS Transit Gateway is a service that enables customers to connect their Amazon Virtual Private Clouds (VPCs) and their on-premises networks to a single gateway. As you grow the number of workloads running on AWS, you need to be able to scale your networks across multiple accounts and Amazon VPCs to keep up with the growth. Today, you can connect pairs of Amazon VPCs using peering. However, managing point-to-point connectivity across many Amazon VPCs, without the ability to centrally manage the connectivity policies, can be operationally costly and cumbersome. For on-premises connectivity, you need to attach your AWS VPN to each individual Amazon VPC. This solution can be time consuming to build and hard to manage when the number of VPCs grows into the hunareas.\\nWith AWS Transit Gateway, you only have to create and manage a single connection from the central gateway in to each Amazon VPC, on-premises data center, or remote office across your network. Transit Gateway acts as a hub that controls how traffic is routed among all the connected networks which act like spokes. This hub and spoke model significantly simplifies management and reduces operational costs because each network only has to connect to the Transit Gateway and not to every other network. Any new VPC is simply connected to the Transit Gateway and Is then automatically available to every other network that is connected to the Transit Gateway. This ease of connectivity makes it easy to scale your network as you grow.\\nAWS Virtual Private Network (AWS VPN) solutions establish secure connections between your on-premises networks, remote offices, client devices, and the AWS global network. AWS VPN Is comprised of two services: AWS Site-to-Site VPN and AWS Client VPN. Each service provides a highly-available, managed, and elastic cloud VPN solution to protect your network traffic.\\nAWS Site-to-Site VPN creates encrypted tunnels between your network and your Amazon Virtual Private Clouds or AWS Transit Gateways. For managing remote access, AWS Client VPN connects your users to AWS or on-premises resources using a VPN software client.'\n",
      "\n",
      "=== 340 ===\n",
      "chunk.text (377 tokens):\n",
      "'Elastic Load Balancing (ELB) automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, and IP adaresses. It can handle the varying load of your application traffic in a single Availability Zone or across multiple Availability Zones. Elastic Load Balancing offers four types of load balancers that all feature the high availability, automatic scaling, and robust security necessary to make your applications fault tolerant.\\ne Application Load Balancer is best suited for load balancing of HTTP and HTTPS traffic and provides advanced request routing targeted at the delivery of modern application architectures, including microservices and containers. Operating at the individual request level (Layer seven), Application Load Balancer routes traffic to targets within Amazon Virtual Private Cloud (Amazon VPC) based on the content of the request.\\ne Network Load Balancer is best suited for load balancing of TCP trathic where extreme performance is required. Operating at the connection level (Layer four), Network Load Balancer routes traffic to targets within Amazon Virtual Private Cloud (Amazon VPC) and is capable of handling millions of requests per second while maintaining ultra-low latencies. Network Load Balancer is also optimized to handle sudden and volatile traffic patterns.\\ne Gateway Load Balancer makes it easy to deploy, scale, and run third-party virtual networking appliances. Providing load balancing and auto scaling for fleets of third-party appliances, Gateway Load Balancer is transparent to the source and destination of traffic. This capability makes it well suited Tor working with third-party appliances for security, network analytics, and otner use cases.\\ne Classic Load Balancer provides basic load balancing across multiple Amazon EC2 instances and operates at both the request level and connection level. Classic Load Balancer is intended Tor applications that were built within the EC2-Classic network. EC2-Classic was retired on August 15, 2022.'\n",
      "chunker.contextualize(chunk) (380 tokens):\n",
      "'Elastic Load Balancing\\nElastic Load Balancing (ELB) automatically distributes incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, and IP adaresses. It can handle the varying load of your application traffic in a single Availability Zone or across multiple Availability Zones. Elastic Load Balancing offers four types of load balancers that all feature the high availability, automatic scaling, and robust security necessary to make your applications fault tolerant.\\ne Application Load Balancer is best suited for load balancing of HTTP and HTTPS traffic and provides advanced request routing targeted at the delivery of modern application architectures, including microservices and containers. Operating at the individual request level (Layer seven), Application Load Balancer routes traffic to targets within Amazon Virtual Private Cloud (Amazon VPC) based on the content of the request.\\ne Network Load Balancer is best suited for load balancing of TCP trathic where extreme performance is required. Operating at the connection level (Layer four), Network Load Balancer routes traffic to targets within Amazon Virtual Private Cloud (Amazon VPC) and is capable of handling millions of requests per second while maintaining ultra-low latencies. Network Load Balancer is also optimized to handle sudden and volatile traffic patterns.\\ne Gateway Load Balancer makes it easy to deploy, scale, and run third-party virtual networking appliances. Providing load balancing and auto scaling for fleets of third-party appliances, Gateway Load Balancer is transparent to the source and destination of traffic. This capability makes it well suited Tor working with third-party appliances for security, network analytics, and otner use cases.\\ne Classic Load Balancer provides basic load balancing across multiple Amazon EC2 instances and operates at both the request level and connection level. Classic Load Balancer is intended Tor applications that were built within the EC2-Classic network. EC2-Classic was retired on August 15, 2022.'\n",
      "\n",
      "=== 341 ===\n",
      "chunk.text (211 tokens):\n",
      "\"The Integrated Private Wireless on AWS program is designed to provide enterprises with managed and validated private wireless offerings trom leading Communications Service Providers (CSPs). The offerings integrate CSPs' private 5G and 4G LTE wireless networks with AWS services across AWS Regions, AWS Local Zones, AWS Outposts, and AWS Snow Family. AWS Telco Solutions Architects tecnnically validate the offerings for their sound architecture, and adherence to AWS best practices. Telecom companies deliver, operate, and support the offerings.\\nElastic Load Balancing 120\\nThe program also uses the rich expertise of validated global AWS Independent Software Vendor (ISV) partners to accelerate the time-to-value for private wireless deployment. Integrated Private Wireless on AWS removes the tong planning cycles and complex integrations usually required to set up and scale a private wireless network. You can now deploy a secure, reliable, and low-latency private wireless network to power AI/ML and loT workloads at the edge and at scale.\"\n",
      "chunker.contextualize(chunk) (217 tokens):\n",
      "\"integrated Private Wireless on AWS\\nThe Integrated Private Wireless on AWS program is designed to provide enterprises with managed and validated private wireless offerings trom leading Communications Service Providers (CSPs). The offerings integrate CSPs' private 5G and 4G LTE wireless networks with AWS services across AWS Regions, AWS Local Zones, AWS Outposts, and AWS Snow Family. AWS Telco Solutions Architects tecnnically validate the offerings for their sound architecture, and adherence to AWS best practices. Telecom companies deliver, operate, and support the offerings.\\nElastic Load Balancing 120\\nThe program also uses the rich expertise of validated global AWS Independent Software Vendor (ISV) partners to accelerate the time-to-value for private wireless deployment. Integrated Private Wireless on AWS removes the tong planning cycles and complex integrations usually required to set up and scale a private wireless network. You can now deploy a secure, reliable, and low-latency private wireless network to power AI/ML and loT workloads at the edge and at scale.\"\n",
      "\n",
      "=== 342 ===\n",
      "chunk.text (269 tokens):\n",
      "'Amazon Braket is a fully managed quantum computing service that helps researchers and developers get started with the technology to accelerate research and discovery. Amazon Braket provides a development environment for you to explore and build quantum algorithms, test them on quantum circuit simulators, and run them on different quantum hardware technologies.\\nQuantum computing has the potential to solve computational problems that are beyond the reach of classical computers by harnessing the laws of quantum mechanics to process information in new ways. This approach to computing could transform areas such as chemical engineering, material science, drug discovery, financial portfolio optimization, and machine learning. But defining those problems and programming quantum computers to solve them requires new skills, which are difficult to acquire without easy access to quantum computing haraware.\\nAmazon Braket overcomes these challenges so you can explore quantum computing. With Amazon Braket, you can design and build your own quantum algorithms from scratch or choose from a set of pre-built algorithms. Once you Nave built your algorithm, Amazon Braket provides a choice of simulators to test, troubleshoot and run your algorithms. When you are ready, you can run your algorithm on your choice of different quantum computers, and gate-based computers from Rigetti and lonQ. With Amazon Braket, you can now evaluate the potential of quantum computing for your organization, and build expertise.\\nQuantum technologies 127'\n",
      "chunker.contextualize(chunk) (272 tokens):\n",
      "'Amazon Braket\\nAmazon Braket is a fully managed quantum computing service that helps researchers and developers get started with the technology to accelerate research and discovery. Amazon Braket provides a development environment for you to explore and build quantum algorithms, test them on quantum circuit simulators, and run them on different quantum hardware technologies.\\nQuantum computing has the potential to solve computational problems that are beyond the reach of classical computers by harnessing the laws of quantum mechanics to process information in new ways. This approach to computing could transform areas such as chemical engineering, material science, drug discovery, financial portfolio optimization, and machine learning. But defining those problems and programming quantum computers to solve them requires new skills, which are difficult to acquire without easy access to quantum computing haraware.\\nAmazon Braket overcomes these challenges so you can explore quantum computing. With Amazon Braket, you can design and build your own quantum algorithms from scratch or choose from a set of pre-built algorithms. Once you Nave built your algorithm, Amazon Braket provides a choice of simulators to test, troubleshoot and run your algorithms. When you are ready, you can run your algorithm on your choice of different quantum computers, and gate-based computers from Rigetti and lonQ. With Amazon Braket, you can now evaluate the potential of quantum computing for your organization, and build expertise.\\nQuantum technologies 127'\n",
      "\n",
      "=== 343 ===\n",
      "chunk.text (435 tokens):\n",
      "'AWS RoboMaker Is a service that makes it easy to develop, test, and deploy intelligent robotics applications at scale. AWS RoboMaker extends the most widely used open-source robotics software framework, Robot Operating System (ROS), with connectivity to cloud services. This includes AWS machine learning services, monitoring services, and analytics services that enable a robot to stream data, navigate, communicate, comprehend, and learn. AWS RoboMaker provides a robotics development environment for application development, a robotics simulation service to accelerate application testing, and a robotics fleet management service tor remote application deployment, update, and management.\\nRobots are machines that sense, compute, and take action. Robots need instructions to accomplish tasks, and these instructions come in the form of applications that developers code to determine how the robot will behave. Receiving and processing sensor data, controlling actuators for movement, and performing a specific task are all Tunctions that are typically automated by these intelligent robotics applications. Intelligent robots are being increasingly used in warehouses to distribute inventory, in homes to carry out tedious housework, and in retail stores to provide customer service. Robotics applications use machine learning in order to perform more complex tasks like recognizing an object or face, having a conversation with a person, Tollowing a spoken commana, or navigating autonomously.\\nUntil now, developing, testing, and deploying intelligent robotics applications was difficult ana time consuming. Building intelligent robotics functionality using machine learning is complex and requires specialized skills. Setting up a development environment can take each developer days and building a realistic simulation system to test an application can take months due to the underlying infrastructure needed. Once an application has been developed and tested, a developer needs to build a deployment system to deploy the application into the robot and later update the application while the robot is in use.\\nAWS RoboMaker provides you with the tools to make building intelligent robotics applications more accessible, a fully managed simulation service for quick and easy testing, anda deployment service for lifecycle management. AWS RoboMaker removes the heavy lifting\\nRobdoTtIcCS\\nfrom each step of robotics development so you can focus on creating innovative robotics applications.'\n",
      "chunker.contextualize(chunk) (436 tokens):\n",
      "'Robotics\\nAWS RoboMaker Is a service that makes it easy to develop, test, and deploy intelligent robotics applications at scale. AWS RoboMaker extends the most widely used open-source robotics software framework, Robot Operating System (ROS), with connectivity to cloud services. This includes AWS machine learning services, monitoring services, and analytics services that enable a robot to stream data, navigate, communicate, comprehend, and learn. AWS RoboMaker provides a robotics development environment for application development, a robotics simulation service to accelerate application testing, and a robotics fleet management service tor remote application deployment, update, and management.\\nRobots are machines that sense, compute, and take action. Robots need instructions to accomplish tasks, and these instructions come in the form of applications that developers code to determine how the robot will behave. Receiving and processing sensor data, controlling actuators for movement, and performing a specific task are all Tunctions that are typically automated by these intelligent robotics applications. Intelligent robots are being increasingly used in warehouses to distribute inventory, in homes to carry out tedious housework, and in retail stores to provide customer service. Robotics applications use machine learning in order to perform more complex tasks like recognizing an object or face, having a conversation with a person, Tollowing a spoken commana, or navigating autonomously.\\nUntil now, developing, testing, and deploying intelligent robotics applications was difficult ana time consuming. Building intelligent robotics functionality using machine learning is complex and requires specialized skills. Setting up a development environment can take each developer days and building a realistic simulation system to test an application can take months due to the underlying infrastructure needed. Once an application has been developed and tested, a developer needs to build a deployment system to deploy the application into the robot and later update the application while the robot is in use.\\nAWS RoboMaker provides you with the tools to make building intelligent robotics applications more accessible, a fully managed simulation service for quick and easy testing, anda deployment service for lifecycle management. AWS RoboMaker removes the heavy lifting\\nRobdoTtIcCS\\nfrom each step of robotics development so you can focus on creating innovative robotics applications.'\n",
      "\n",
      "=== 344 ===\n",
      "chunk.text (437 tokens):\n",
      "'AWS Ground Station ts a fully managed service that lets you control satellite communications, downlink and process satellite data, and scale your satellite operations quickly, easily and cost-effectively without having to worry about building or managing your own ground station infrastructure. Satellites are used for a wide variety of use cases, including weather forecasting, Surface imaging, communications, and video broadcasts. Ground stations are at the core of global satellite networks, which are facilities that provide communications between the ground and the satellites by using antennas to receive data and control systems to send radio signals to command and control the satellite. Today, you must either build your own ground stations and antennas, or obtain long-term leases with ground station providers, often in multiple countries to provide enough opportunities to contact the satellites as they orbit the globe. Once all this data is downloaded, you need servers, storage, and networking in close proximity to the antennas to process, store, and transport the data from the satellites.\\nAWS Ground Station eliminates these problems by delivering a global ground station as a service. We provide direct access to AWS services and the AWS Global Infrastructure including our low-latency global fiber network right where your data is downloaded into our AWS Ground Station. This enables you to easily control satellite communications, quickly ingest and process your satellite data, and rapidly integrate that data with your applications and other services running in the AWS Cloud. For example, you can use Amazon S34 to store the downloaded data, Amazon Kinesis Data Streams for managing data ingestion from satellites, SageMaker Al Tor pbuilding custom machine learning applications that apply to your data sets, and Amazon EC2 to command and download data trom satellites. AWS Ground Station can help you save up to 80% on the cost of your ground station operations by allowing you to pay only for the actual antenna time used, and relying on our global footprint of ground stations to download data when and wnere you need it, instead of building and operating your own global ground station infrastructure. There are no long-term commitments, and you gain the ability to rapidly scale your satellite communications on-demand when your business needs it.\\nSatellite'\n",
      "chunker.contextualize(chunk) (443 tokens):\n",
      "'AWS Grouna Station\\nAWS Ground Station ts a fully managed service that lets you control satellite communications, downlink and process satellite data, and scale your satellite operations quickly, easily and cost-effectively without having to worry about building or managing your own ground station infrastructure. Satellites are used for a wide variety of use cases, including weather forecasting, Surface imaging, communications, and video broadcasts. Ground stations are at the core of global satellite networks, which are facilities that provide communications between the ground and the satellites by using antennas to receive data and control systems to send radio signals to command and control the satellite. Today, you must either build your own ground stations and antennas, or obtain long-term leases with ground station providers, often in multiple countries to provide enough opportunities to contact the satellites as they orbit the globe. Once all this data is downloaded, you need servers, storage, and networking in close proximity to the antennas to process, store, and transport the data from the satellites.\\nAWS Ground Station eliminates these problems by delivering a global ground station as a service. We provide direct access to AWS services and the AWS Global Infrastructure including our low-latency global fiber network right where your data is downloaded into our AWS Ground Station. This enables you to easily control satellite communications, quickly ingest and process your satellite data, and rapidly integrate that data with your applications and other services running in the AWS Cloud. For example, you can use Amazon S34 to store the downloaded data, Amazon Kinesis Data Streams for managing data ingestion from satellites, SageMaker Al Tor pbuilding custom machine learning applications that apply to your data sets, and Amazon EC2 to command and download data trom satellites. AWS Ground Station can help you save up to 80% on the cost of your ground station operations by allowing you to pay only for the actual antenna time used, and relying on our global footprint of ground stations to download data when and wnere you need it, instead of building and operating your own global ground station infrastructure. There are no long-term commitments, and you gain the ability to rapidly scale your satellite communications on-demand when your business needs it.\\nSatellite'\n",
      "\n",
      "=== 345 ===\n",
      "chunk.text (220 tokens):\n",
      "\"AWS is architected to be the most secure global cloud infrastructure on which to build, migrate, and manage applications and workloads.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing AWS security, identity, and governance services. For general information, see Security, Identity, and Compliance on AWS.\\nAVW>S Firewall\\n\\nAWS Shield\\nVanager\\nGovernance ana compliance\\nAWS Network Firewall AWS WAF\\na. 1 1 iby AWS uzatic\\nidentity Center rn t AWS Config AWS CloudTrail 1 ' 'S Organizations\\nmH 1 “67 1 ni Md\\n' ' - ' AWS Control Tower\\nAmazon Cognito ' 4 BA ic Amazon Inspector AWS Security Hub\\n\\n= ) a\\n\\nko\\nAWS Private\\nCertificate Authority\\ntriel\\n\\nAWS Artifact\\n| ~Amagznan Detective Amazon GuardUu\\nAmazon Detective = ““mazon Suardbuly\\n\\nfm\\n\\nprotection\\nAWS KMS AWS Certificate § AWS secrets n =~ SES H , AWS Audit Manager\\nManager ‘Manager\"\n",
      "chunker.contextualize(chunk) (226 tokens):\n",
      "\"Security, identity, and compliance\\nAWS is architected to be the most secure global cloud infrastructure on which to build, migrate, and manage applications and workloads.\\nEach service is described after the diagram. To help you decide which service best meets your needs, see Choosing AWS security, identity, and governance services. For general information, see Security, Identity, and Compliance on AWS.\\nAVW>S Firewall\\n\\nAWS Shield\\nVanager\\nGovernance ana compliance\\nAWS Network Firewall AWS WAF\\na. 1 1 iby AWS uzatic\\nidentity Center rn t AWS Config AWS CloudTrail 1 ' 'S Organizations\\nmH 1 “67 1 ni Md\\n' ' - ' AWS Control Tower\\nAmazon Cognito ' 4 BA ic Amazon Inspector AWS Security Hub\\n\\n= ) a\\n\\nko\\nAWS Private\\nCertificate Authority\\ntriel\\n\\nAWS Artifact\\n| ~Amagznan Detective Amazon GuardUu\\nAmazon Detective = ““mazon Suardbuly\\n\\nfm\\n\\nprotection\\nAWS KMS AWS Certificate § AWS secrets n =~ SES H , AWS Audit Manager\\nManager ‘Manager\"\n",
      "\n",
      "=== 346 ===\n",
      "chunk.text (96 tokens):\n",
      "'e Amazon Cognito\\ne Amazon Detective\\n¢ Amazon GuardDuty\\n¢ Amazon Inspector\\nAmazon Macie\\ne Amazon Security Lake\\ne Amazon Verified Permissions\\ne AWS Artifact\\n¢ AWS Audit Manager\\ne AWS Certificate Manager\\ne AWS Directory Service\\n¢ AWS Firewall Manager\\n¢ AWS Identity and Access Management\\ne AWS Key Management Service\\ne AWS Resource Access Manager\\ne AWS Secrets Manager\\ne AWS Security Hub\\ne AWS IAM Identity Center\\ne AWS WAF Captcha'\n",
      "chunker.contextualize(chunk) (97 tokens):\n",
      "'Services\\ne Amazon Cognito\\ne Amazon Detective\\n¢ Amazon GuardDuty\\n¢ Amazon Inspector\\nAmazon Macie\\ne Amazon Security Lake\\ne Amazon Verified Permissions\\ne AWS Artifact\\n¢ AWS Audit Manager\\ne AWS Certificate Manager\\ne AWS Directory Service\\n¢ AWS Firewall Manager\\n¢ AWS Identity and Access Management\\ne AWS Key Management Service\\ne AWS Resource Access Manager\\ne AWS Secrets Manager\\ne AWS Security Hub\\ne AWS IAM Identity Center\\ne AWS WAF Captcha'\n",
      "\n",
      "=== 347 ===\n",
      "chunk.text (182 tokens):\n",
      "\"Amazon Cognito lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily. With Amazon Cognito, you can scale to millions of users and supports sign-in with social identity providers such as Apple, Facebook, Twitter, or Amazon, with SAML 2.0 identity solutions, or by using your own identity system.\\nIn addition, Amazon Cognito enables you to save data locally on users' devices, allowing your applications to work even when the devices are offline. You can then synchronize data across users' devices so that their app experience remains consistent regardless of the device they use.\\nWith Amazon Cognito, you can focus on creating great app experiences instead of worrying about pbuilding, securing, and scaling a solution to handle user management, authentication, and sync Across AeVICeS.\\nAmazon Cognito 25\"\n",
      "chunker.contextualize(chunk) (186 tokens):\n",
      "\"Amazon Cognito\\nAmazon Cognito lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily. With Amazon Cognito, you can scale to millions of users and supports sign-in with social identity providers such as Apple, Facebook, Twitter, or Amazon, with SAML 2.0 identity solutions, or by using your own identity system.\\nIn addition, Amazon Cognito enables you to save data locally on users' devices, allowing your applications to work even when the devices are offline. You can then synchronize data across users' devices so that their app experience remains consistent regardless of the device they use.\\nWith Amazon Cognito, you can focus on creating great app experiences instead of worrying about pbuilding, securing, and scaling a solution to handle user management, authentication, and sync Across AeVICeS.\\nAmazon Cognito 25\"\n",
      "\n",
      "=== 348 ===\n",
      "chunk.text (437 tokens):\n",
      "'Amazon Detective makes It easy to analyze, investigate, and quickly identify the root cause of potential security issues or suspicious activities. Amazon Detective automatically collects (og data from your AWS resources and uses machine learning, statistical analysis, and graph theory to build a linked set of data that enables you to easily conduct faster and more efficient security investigations. Amazon Detective further simplifies account management for security operations and investigations across all existing and future accounts In an organization using AWS Organizations for up to 1,200 AWS accounts.\\nAWS security services such as Amazon GuardDuty, Amazon Macie, and AWS Security Hub, as well as partner security products, can be used to identify potential security issues, or findings. These services are really helpful in alerting you when and where there is possible unauthorized access or suspicious benavior in your AWS deployment. However, sometimes there are security findings that you would like to perform deeper investigations of the events that led to the findings to remediate the root cause. Determining the root cause of security findings can be a complex process for security analysts that often involves collecting and combining logs from many data sources, using extract, transform, and load (ETL) tools, and custom scripting to organize the data.\\nAmazon Detective simplifies this process by enabling your security teams to easily investigate and quickly get to the root cause of a finding. Detective can analyze trillions of events from multiple data sources such as Amazon Virtual Private Cloud (VPC) Flow Logs, AWS CloudTrail, and Amazon GuardDuty. Detective uses these events to automatically create a unified, interactive view of your resources, users, and the interactions between them over time. With this unified view, you can visualize all the details and context in one place to identify the underlying reasons for the findings, dritl down into relevant historical activities, and quickly determine the root cause.\\nYou can get started with Amazon Detective in just a few clicks in the AWS Management Console. There is no software to deploy, or data sources to enable and maintain. You can try Detective at no additional charge with a 30-day Tree trial that is available to new accounts.'\n",
      "chunker.contextualize(chunk) (439 tokens):\n",
      "'Amazon Detective\\nAmazon Detective makes It easy to analyze, investigate, and quickly identify the root cause of potential security issues or suspicious activities. Amazon Detective automatically collects (og data from your AWS resources and uses machine learning, statistical analysis, and graph theory to build a linked set of data that enables you to easily conduct faster and more efficient security investigations. Amazon Detective further simplifies account management for security operations and investigations across all existing and future accounts In an organization using AWS Organizations for up to 1,200 AWS accounts.\\nAWS security services such as Amazon GuardDuty, Amazon Macie, and AWS Security Hub, as well as partner security products, can be used to identify potential security issues, or findings. These services are really helpful in alerting you when and where there is possible unauthorized access or suspicious benavior in your AWS deployment. However, sometimes there are security findings that you would like to perform deeper investigations of the events that led to the findings to remediate the root cause. Determining the root cause of security findings can be a complex process for security analysts that often involves collecting and combining logs from many data sources, using extract, transform, and load (ETL) tools, and custom scripting to organize the data.\\nAmazon Detective simplifies this process by enabling your security teams to easily investigate and quickly get to the root cause of a finding. Detective can analyze trillions of events from multiple data sources such as Amazon Virtual Private Cloud (VPC) Flow Logs, AWS CloudTrail, and Amazon GuardDuty. Detective uses these events to automatically create a unified, interactive view of your resources, users, and the interactions between them over time. With this unified view, you can visualize all the details and context in one place to identify the underlying reasons for the findings, dritl down into relevant historical activities, and quickly determine the root cause.\\nYou can get started with Amazon Detective in just a few clicks in the AWS Management Console. There is no software to deploy, or data sources to enable and maintain. You can try Detective at no additional charge with a 30-day Tree trial that is available to new accounts.'\n",
      "\n",
      "=== 349 ===\n",
      "chunk.text (347 tokens):\n",
      "'Amazon GuardDuty is a threat detection service that continuously monitors for malicious activity and anomalous behavior to protect your AWS accounts, workloads, Kubernetes clusters, and data stored in Amazon Simple Storage Service (Amazon S34). The GuardDuty service monitors for activity such as unusual API calls, unauthorized deployments, and exfiltrated credentials that indicate a possible account reconnaissance or compromise.\\nAmazon Detective\\nEnabled with a few clicks in the AWS Management Console and easily administrated organizationwide with its support of AWS Organizations, Amazon GuardDuty can immediately begin analyzing billions of events across your AWS accounts for signs of unauthorized use. GuardDuty identifies suspected attackers through integrated threat intelligence feeds and machine learning anomaly detection to detect anomalies in account and workload activity. When potential unauthorized use is detected, the service delivers a detailed finding to the GuardDuty console, Amazon CloudWatch Events, and AWS Security Hub. This makes findings actionable and easy to integrate into existing event management and workflow systems. Further investigation to determine the root cause of a finding is easily accomplished by using Amazon Detective directly from the GuardDuty console.\\nAmazon GuardDuty is cost effective and easy to operate. It does not require you to deploy and maintain software or security infrastructure, meaning it can be enabled quickly with no risk of negatively impacting existing application and container workloads. There are no uptront costs with GuardDuty, no software to deploy, and no threat intelligence feeds to enable. Furthermore, GuardDuty optimizes costs by applying smart filters and analyzing only a subset of logs relevant to threat detection, and new Amazon GuardDuty accounts are free for 30 days.'\n",
      "chunker.contextualize(chunk) (351 tokens):\n",
      "'Amazon GuardDuty\\nAmazon GuardDuty is a threat detection service that continuously monitors for malicious activity and anomalous behavior to protect your AWS accounts, workloads, Kubernetes clusters, and data stored in Amazon Simple Storage Service (Amazon S34). The GuardDuty service monitors for activity such as unusual API calls, unauthorized deployments, and exfiltrated credentials that indicate a possible account reconnaissance or compromise.\\nAmazon Detective\\nEnabled with a few clicks in the AWS Management Console and easily administrated organizationwide with its support of AWS Organizations, Amazon GuardDuty can immediately begin analyzing billions of events across your AWS accounts for signs of unauthorized use. GuardDuty identifies suspected attackers through integrated threat intelligence feeds and machine learning anomaly detection to detect anomalies in account and workload activity. When potential unauthorized use is detected, the service delivers a detailed finding to the GuardDuty console, Amazon CloudWatch Events, and AWS Security Hub. This makes findings actionable and easy to integrate into existing event management and workflow systems. Further investigation to determine the root cause of a finding is easily accomplished by using Amazon Detective directly from the GuardDuty console.\\nAmazon GuardDuty is cost effective and easy to operate. It does not require you to deploy and maintain software or security infrastructure, meaning it can be enabled quickly with no risk of negatively impacting existing application and container workloads. There are no uptront costs with GuardDuty, no software to deploy, and no threat intelligence feeds to enable. Furthermore, GuardDuty optimizes costs by applying smart filters and analyzing only a subset of logs relevant to threat detection, and new Amazon GuardDuty accounts are free for 30 days.'\n",
      "\n",
      "=== 350 ===\n",
      "chunk.text (352 tokens):\n",
      "'Amazon Inspector is a new automated vulnerability management service that continually scans AWS workloads for software vulnerabilities and unintended network exposure. With a Tew clicks in the AWS Management Console and AWS Organizations, Amazon Inspector can be used across all accounts in your organization. Once started, Amazon Inspector automatically discovers running Amazon Elastic Compute Cloud (Amazon EC2) instances and container images residing in Amazon Elastic Container Registry (Amazon ECR), at any scale, and immediately starts assessing them for Known vulnerabilities.\\nAmazon Inspector has many improvements over Amazon Inspector Classic. For example, the new Amazon Inspector calculates a highly contextualized risk score Tor each finding by correlating common vulnerabilities and exposures (CVE) information with factors such as network access and exploitability. This score is used to prioritize the most critical vulnerabilities to improve remediation response efficiency. Additionally, Amazon Inspector now uses the widely deployed AWS Systems Manager Agent (SSM Agent) to eliminate the need for you to deploy and maintain a standalone agent to run Amazon EC2 instance assessments. For container workloads, Amazon Inspector is now integrated with Amazon Elastic Container Registry (Amazon ECR) to support intelligent, costeTicient, and continual vulnerability assessments of container images. All findings are aggregated in the Amazon Inspector console, routed to AWS Security Hub, and pushed through Amazon EventBridge to automate workTlows such as ticketing.\\nAmazon Inspector V2/\\nAll accounts new to Amazon Inspector are eligible for a 15-day Tree trial to evaluate the service and estimate its cost. During the trial, all eligible Amazon EC2 instances and container images pushed to Amazon ECR are continually scanned at no cost.'\n",
      "chunker.contextualize(chunk) (354 tokens):\n",
      "'Amazon Inspector\\nAmazon Inspector is a new automated vulnerability management service that continually scans AWS workloads for software vulnerabilities and unintended network exposure. With a Tew clicks in the AWS Management Console and AWS Organizations, Amazon Inspector can be used across all accounts in your organization. Once started, Amazon Inspector automatically discovers running Amazon Elastic Compute Cloud (Amazon EC2) instances and container images residing in Amazon Elastic Container Registry (Amazon ECR), at any scale, and immediately starts assessing them for Known vulnerabilities.\\nAmazon Inspector has many improvements over Amazon Inspector Classic. For example, the new Amazon Inspector calculates a highly contextualized risk score Tor each finding by correlating common vulnerabilities and exposures (CVE) information with factors such as network access and exploitability. This score is used to prioritize the most critical vulnerabilities to improve remediation response efficiency. Additionally, Amazon Inspector now uses the widely deployed AWS Systems Manager Agent (SSM Agent) to eliminate the need for you to deploy and maintain a standalone agent to run Amazon EC2 instance assessments. For container workloads, Amazon Inspector is now integrated with Amazon Elastic Container Registry (Amazon ECR) to support intelligent, costeTicient, and continual vulnerability assessments of container images. All findings are aggregated in the Amazon Inspector console, routed to AWS Security Hub, and pushed through Amazon EventBridge to automate workTlows such as ticketing.\\nAmazon Inspector V2/\\nAll accounts new to Amazon Inspector are eligible for a 15-day Tree trial to evaluate the service and estimate its cost. During the trial, all eligible Amazon EC2 instances and container images pushed to Amazon ECR are continually scanned at no cost.'\n",
      "\n",
      "=== 351 ===\n",
      "chunk.text (375 tokens):\n",
      "'Amazon Macie is a Tully managed data security and data privacy service that uses inventory evaluations, machine learning, and pattern matching to discover sensitive data and accessibility in your Amazon S3 environment. Macie supports scalable on-demand and automated sensitive data discovery jobs that automatically tracks changes to the bucket and only evaluates new or modified objects over time. Using Macie, you can detect a large and growing list of sensitive data types for many countries and Regions, including multiple types of financial data, personal health information (PHI), and personally identifiable information (PII), as well as custom types. Macie also continually evaluates your Amazon S3 environment to provide an S43 resource summary and security evaluation across all of your accounts. You can search, filter, and sort $4 buckets by metadata variables, sucn as bucket names, tags, and security controls like encryption status or public accessibility. For any unencrypted buckets, publicly accessible buckets, or buckets snared with AWS accounts outside those you Nave defined in AWS Organizations, you can be alerted to act.\\nIn the multi-account configuration, a single Macie administrator account can manage all member accounts, including the creation and administration of sensitive data discovery jobs across accounts with AWS Organizations. Security and sensitive data discovery findings are aggregated in the Macie administrator account and sent to Amazon CloudWatch Events and AWS Security Hub. Now using one account, you can integrate with event management, workflow, and ticketing systems or use Macie findings with AWS Step Functions to automate remediation actions. You can quickly get started with Macie using the 30-day trial available to new accounts for S3 bucket inventory and bucket-level evaluation at no charge. Sensitive data discovery is not included in the 30-day trial for Ducket evaluation.'\n",
      "chunker.contextualize(chunk) (378 tokens):\n",
      "'Amazon Macie\\nAmazon Macie is a Tully managed data security and data privacy service that uses inventory evaluations, machine learning, and pattern matching to discover sensitive data and accessibility in your Amazon S3 environment. Macie supports scalable on-demand and automated sensitive data discovery jobs that automatically tracks changes to the bucket and only evaluates new or modified objects over time. Using Macie, you can detect a large and growing list of sensitive data types for many countries and Regions, including multiple types of financial data, personal health information (PHI), and personally identifiable information (PII), as well as custom types. Macie also continually evaluates your Amazon S3 environment to provide an S43 resource summary and security evaluation across all of your accounts. You can search, filter, and sort $4 buckets by metadata variables, sucn as bucket names, tags, and security controls like encryption status or public accessibility. For any unencrypted buckets, publicly accessible buckets, or buckets snared with AWS accounts outside those you Nave defined in AWS Organizations, you can be alerted to act.\\nIn the multi-account configuration, a single Macie administrator account can manage all member accounts, including the creation and administration of sensitive data discovery jobs across accounts with AWS Organizations. Security and sensitive data discovery findings are aggregated in the Macie administrator account and sent to Amazon CloudWatch Events and AWS Security Hub. Now using one account, you can integrate with event management, workflow, and ticketing systems or use Macie findings with AWS Step Functions to automate remediation actions. You can quickly get started with Macie using the 30-day trial available to new accounts for S3 bucket inventory and bucket-level evaluation at no charge. Sensitive data discovery is not included in the 30-day trial for Ducket evaluation.'\n",
      "\n",
      "=== 352 ===\n",
      "chunk.text (255 tokens):\n",
      "\"Amazon Security Lake centralizes security data from AWS environments, SaaS providers, on premises, and cloud sources, into a purpose-built data lake that's stored in your AWS account. Security Lake automates the collection and management of security data across accounts and AWS Regions so that you can use your preferred analytics tools while retaining control and ownership over your security data. With Security Lake, you can also improve the protection of your workloads, applications, and data.\\nAmazon Macie\\nSecurity Lake automates the collection of security-related log and event data from integrated AWS services and third-party services. It also helps you manage the lifecycle of data with customizable retention settings. Tne data lake is backed by Amazon S34 buckets, and you retain ownership over your data. Security Lake converts ingested data into Apache Parquet format and a standard opensource schema called the Open Cybersecurity Schema Framework (OCSF). With OCSF support, Security Lake normalizes and combines security data from AWS and a broad range of enterprise security data sources.\\nOther AWS services and third-party services can subscribe to the data that's stored in Security Lake for incident response and security data analytics.\"\n",
      "chunker.contextualize(chunk) (258 tokens):\n",
      "\"Amazon Security Lake\\nAmazon Security Lake centralizes security data from AWS environments, SaaS providers, on premises, and cloud sources, into a purpose-built data lake that's stored in your AWS account. Security Lake automates the collection and management of security data across accounts and AWS Regions so that you can use your preferred analytics tools while retaining control and ownership over your security data. With Security Lake, you can also improve the protection of your workloads, applications, and data.\\nAmazon Macie\\nSecurity Lake automates the collection of security-related log and event data from integrated AWS services and third-party services. It also helps you manage the lifecycle of data with customizable retention settings. Tne data lake is backed by Amazon S34 buckets, and you retain ownership over your data. Security Lake converts ingested data into Apache Parquet format and a standard opensource schema called the Open Cybersecurity Schema Framework (OCSF). With OCSF support, Security Lake normalizes and combines security data from AWS and a broad range of enterprise security data sources.\\nOther AWS services and third-party services can subscribe to the data that's stored in Security Lake for incident response and security data analytics.\"\n",
      "\n",
      "=== 353 ===\n",
      "chunk.text (130 tokens):\n",
      "\"Amazon Verified Permissions ts a scalable, fine-grained permissions management and authorization service for custom applications you've built. Verified Permissions enables your developers to build secure applications faster by externalizing authorization and centralizing policy management and administration.\\nVerified Permissions uses Cedar, an open-source policy language and SDK, to define fine-grained permissions for application users. Your authorization model is defined using principal types, resource types, and valid actions, to control wno can take wnat actions on which resources in a given application context. Policy changes are audited so that you can see wno made the changes and when.\"\n",
      "chunker.contextualize(chunk) (134 tokens):\n",
      "\"Amazon Verified Permissions\\nAmazon Verified Permissions ts a scalable, fine-grained permissions management and authorization service for custom applications you've built. Verified Permissions enables your developers to build secure applications faster by externalizing authorization and centralizing policy management and administration.\\nVerified Permissions uses Cedar, an open-source policy language and SDK, to define fine-grained permissions for application users. Your authorization model is defined using principal types, resource types, and valid actions, to control wno can take wnat actions on which resources in a given application context. Policy changes are audited so that you can see wno made the changes and when.\"\n",
      "\n",
      "=== 354 ===\n",
      "chunk.text (122 tokens):\n",
      "'AWS Artifact is your go-to, central resource for compliance-related information that matters to you. It provides on-demand access to AWS security and compliance reports and select online agreements. Reports available in AWS Artifact include our Service Organization Control (SOC) reports, Payment Card Industry (PCI) reports, and certifications from accreditation bodies across geographies and compliance verticals that validate the implementation and operating effectiveness of AWS security controls. Agreements available in AWS Artifact include the Business Associate Addendum (BAA) and the Nondisclosure Agreement (NDA).'\n",
      "chunker.contextualize(chunk) (125 tokens):\n",
      "'AWS Artifact\\nAWS Artifact is your go-to, central resource for compliance-related information that matters to you. It provides on-demand access to AWS security and compliance reports and select online agreements. Reports available in AWS Artifact include our Service Organization Control (SOC) reports, Payment Card Industry (PCI) reports, and certifications from accreditation bodies across geographies and compliance verticals that validate the implementation and operating effectiveness of AWS security controls. Agreements available in AWS Artifact include the Business Associate Addendum (BAA) and the Nondisclosure Agreement (NDA).'\n",
      "\n",
      "=== 355 ===\n",
      "chunk.text (298 tokens):\n",
      "'AWS Audit Manager helps you continuously audit your AWS usage to simplify how you assess risk and compliance with regulations and industry standards. Audit Manager automates evidence\\nAmazon Verined Permissions\\ncollection to reduce the \"all hands on deck\" manual effort that often happens for audits and enable you to scale your audit capability in the cloud as your business grows. With Audit Manager, it is easy to assess if your policies, procedures, and activities — also known as controls — are operating effectively. When it Is time for an audit, AWS Audit Manager helps you manage stakeholder reviews of your controls and enables you to build audit-ready reports with much less manual effort.\\nThe AWS Audit Manager prebuilt frameworks help translate evidence from cloud services into auditor-friendly reports by mapping your AWS resources to the requirements in industry standards or regulations, such as CIS AWS Foundations Benchmark, the General Data Protection Regulation (GDPR), and the Payment Card Industry Data Security Standard (PCI DSS). You can also fully customize a framework and its controls for your unique business requirements. Based on the framework you select, Audit Manager launches an assessment that continuously collects and organizes relevant evidence from your AWS accounts and resources, such as resource configuration Snapshots, user activity, and compliance check results.\\nYou can get started quickly in the AWS Management Console. Just select a prebuilt framework to launch an assessment and begin automatically collecting and organizing evidence.'\n",
      "chunker.contextualize(chunk) (302 tokens):\n",
      "'AWS Audit Manager\\nAWS Audit Manager helps you continuously audit your AWS usage to simplify how you assess risk and compliance with regulations and industry standards. Audit Manager automates evidence\\nAmazon Verined Permissions\\ncollection to reduce the \"all hands on deck\" manual effort that often happens for audits and enable you to scale your audit capability in the cloud as your business grows. With Audit Manager, it is easy to assess if your policies, procedures, and activities — also known as controls — are operating effectively. When it Is time for an audit, AWS Audit Manager helps you manage stakeholder reviews of your controls and enables you to build audit-ready reports with much less manual effort.\\nThe AWS Audit Manager prebuilt frameworks help translate evidence from cloud services into auditor-friendly reports by mapping your AWS resources to the requirements in industry standards or regulations, such as CIS AWS Foundations Benchmark, the General Data Protection Regulation (GDPR), and the Payment Card Industry Data Security Standard (PCI DSS). You can also fully customize a framework and its controls for your unique business requirements. Based on the framework you select, Audit Manager launches an assessment that continuously collects and organizes relevant evidence from your AWS accounts and resources, such as resource configuration Snapshots, user activity, and compliance check results.\\nYou can get started quickly in the AWS Management Console. Just select a prebuilt framework to launch an assessment and begin automatically collecting and organizing evidence.'\n",
      "\n",
      "=== 356 ===\n",
      "chunk.text (485 tokens):\n",
      "\"AWS Certificate Manager is a service that lets you easily provision, manage, and deploy Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS services and your internal connected resources. SSL/TLS certificates are used to secure network communications and establish the identity of websites over the Internet as well as resources on private networks. AWS Certificate Manager removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates.\\nWith AWS Certificate Manager, you can quickly request a certificate, deploy it on ACM-integrated AWS resources, such as Elastic Load Balancing, Amazon CloudFront distributions, and APIs on API Gateway, and let AWS Certificate Manager handle certificate renewals. It also enables you to create private certificates for your internal resources and manage the certificate lifecycle centrally. Public and private certificates provisioned through AWS Certificate Manager for use with ACM-integrated services are Tree. You pay only for the AWS resources you create to run your application.\\nWith AWS Private Certincate Authority, you pay monthly for the operation of the private certificate authority (CA) and for the private certificates you issue. you Nave a highly available private CA service without the uptront investment and ongoing maintenance costs of operating your own private CA.\\nAWS Certificate Manager 130\\nThe AWS CloudHS™M is a cloud-based hardware security module (HSM) that enables you to easily generate and use your own encryption keys on the AWS Cloud. With AWS CloudHSM, you can manage your own encryption Keys using dedicated FIPS 140-2 Level 3 validated HSMs. AWS CloudHSM offers you the flexibility to integrate with your applications using industry-standard APIs, such as PKCS#11, Java Cryptography Extensions (JCE), and Microsoft CryptoNG (CNG) 'ipraries.\\nAWS CloudHSM is standards-compliant and enables you to export all of your keys to most other commercially-available HSMs, subject to your configurations. It is a Tully managed service that automates time-consuming administrative tasks Tor you, such as hardware provisioning, software patching, high-availability, and backups. AWS CloudHSM also enables you to scale quickly by adding and removing HSM capacity on-demand, with no up-Tront costs.\"\n",
      "chunker.contextualize(chunk) (489 tokens):\n",
      "\"AWS Certificate Manager\\nAWS Certificate Manager is a service that lets you easily provision, manage, and deploy Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS services and your internal connected resources. SSL/TLS certificates are used to secure network communications and establish the identity of websites over the Internet as well as resources on private networks. AWS Certificate Manager removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates.\\nWith AWS Certificate Manager, you can quickly request a certificate, deploy it on ACM-integrated AWS resources, such as Elastic Load Balancing, Amazon CloudFront distributions, and APIs on API Gateway, and let AWS Certificate Manager handle certificate renewals. It also enables you to create private certificates for your internal resources and manage the certificate lifecycle centrally. Public and private certificates provisioned through AWS Certificate Manager for use with ACM-integrated services are Tree. You pay only for the AWS resources you create to run your application.\\nWith AWS Private Certincate Authority, you pay monthly for the operation of the private certificate authority (CA) and for the private certificates you issue. you Nave a highly available private CA service without the uptront investment and ongoing maintenance costs of operating your own private CA.\\nAWS Certificate Manager 130\\nThe AWS CloudHS™M is a cloud-based hardware security module (HSM) that enables you to easily generate and use your own encryption keys on the AWS Cloud. With AWS CloudHSM, you can manage your own encryption Keys using dedicated FIPS 140-2 Level 3 validated HSMs. AWS CloudHSM offers you the flexibility to integrate with your applications using industry-standard APIs, such as PKCS#11, Java Cryptography Extensions (JCE), and Microsoft CryptoNG (CNG) 'ipraries.\\nAWS CloudHSM is standards-compliant and enables you to export all of your keys to most other commercially-available HSMs, subject to your configurations. It is a Tully managed service that automates time-consuming administrative tasks Tor you, such as hardware provisioning, software patching, high-availability, and backups. AWS CloudHSM also enables you to scale quickly by adding and removing HSM capacity on-demand, with no up-Tront costs.\"\n",
      "\n",
      "=== 357 ===\n",
      "chunk.text (155 tokens):\n",
      "'AWS Directory Service for Microsoft Active Directory, also Known as AWS Managed Microsoft AD, enables your directory-aware workloads and AWS resources to use managed Active Directory in the AWS Cloud. AWS Managed Microsoft AD Is built on actual Microsoft Active Directory and does not require you to synchronize or replicate data from your existing Active Directory to the cloud. You can use standard Active Directory administration tools and take advantage of built-in Active Directory features such as Group Policy and single sign-on (SSO). With AWS Managed Microsoft AD, you can easily join Amazon EC2 and Amazon RDS for SQL Server instances to a domain, and use AWS Enterprise IT applications such as Amazon WorkSpaces with Active Directory users and QrOups.'\n",
      "chunker.contextualize(chunk) (159 tokens):\n",
      "'AWS Directory Service\\nAWS Directory Service for Microsoft Active Directory, also Known as AWS Managed Microsoft AD, enables your directory-aware workloads and AWS resources to use managed Active Directory in the AWS Cloud. AWS Managed Microsoft AD Is built on actual Microsoft Active Directory and does not require you to synchronize or replicate data from your existing Active Directory to the cloud. You can use standard Active Directory administration tools and take advantage of built-in Active Directory features such as Group Policy and single sign-on (SSO). With AWS Managed Microsoft AD, you can easily join Amazon EC2 and Amazon RDS for SQL Server instances to a domain, and use AWS Enterprise IT applications such as Amazon WorkSpaces with Active Directory users and QrOups.'\n",
      "\n",
      "=== 358 ===\n",
      "chunk.text (99 tokens):\n",
      "'AWS Firewall Manager is a security management service which allows you to centrally configure and manage firewall rules across your accounts and applications in AWS Organizations. As new applications are created, Firewall Manager makes it easy to bring new applications and resources into compliance by enforcing a common set of security rules. Now you have a single service to build firewall rules, create security policies, and enforce them in a consistent, hierarchical manner across your entire infrastructure, from a central administrator account.'\n",
      "chunker.contextualize(chunk) (104 tokens):\n",
      "'AWS Firewall Manager\\nAWS Firewall Manager is a security management service which allows you to centrally configure and manage firewall rules across your accounts and applications in AWS Organizations. As new applications are created, Firewall Manager makes it easy to bring new applications and resources into compliance by enforcing a common set of security rules. Now you have a single service to build firewall rules, create security policies, and enforce them in a consistent, hierarchical manner across your entire infrastructure, from a central administrator account.'\n",
      "\n",
      "=== 359 ===\n",
      "chunk.text (434 tokens):\n",
      "\"AWS Identity and Access Management (IAM) enables you to securely control access to AWS services and resources for your AWS users, groups, and roles. Using IAM, you can create and manage finegrained access controls with permissions, specify who can access which services and resources, and under which conditions. IAM allows you to do the following:\\ne You manage AWS permissions for your workforce users and workloads in AWS IAM Identity Center (IAM Identity Center). IAM Identity Center allows you to manage user access across multiple AWS accounts. With just a few clicks, you can enable a highly available service, easily manage multi-account access and the permissions to all of your accounts in AWS Organizations centrally. IAM Identity Center includes built-in SAML integrations to many business applications, such as Salesforce, Box, and Microsoft Office 365. Further, you can create Security Assertion Markup Language (SAML) 2.0 integrations and extend single sign-on access to any of your SAMLenabled applications. Your users simply sign in to a user portal with credentials they configure or using their existing corporate credentials to access all their assigned accounts and applications from one place.\\ne Manage single-account IAM permissions: You can specify access to AWS resources using permissions. Your IAM entities (users, groups, and roles) by default start with no permissions. These identities can be granted permissions by attaching an IAM policy that specifies the type of access, the actions that can be performed, and the resources on which actions can be performed. You can also specify conditions that must be set for access to be allowed or denied.\\ne Manage single-account IAM roles: IAM roles allows you to delegate access to users or services that normally don't Nave access to your organization's AWS resources. IAM users or AWS services can assume a role to obtain a temporary security credential that be used to make AWS API calls. You don't have to share long-term credentials or define permissions for each identity.\"\n",
      "chunker.contextualize(chunk) (440 tokens):\n",
      "\"AWS Identity and Access Management\\nAWS Identity and Access Management (IAM) enables you to securely control access to AWS services and resources for your AWS users, groups, and roles. Using IAM, you can create and manage finegrained access controls with permissions, specify who can access which services and resources, and under which conditions. IAM allows you to do the following:\\ne You manage AWS permissions for your workforce users and workloads in AWS IAM Identity Center (IAM Identity Center). IAM Identity Center allows you to manage user access across multiple AWS accounts. With just a few clicks, you can enable a highly available service, easily manage multi-account access and the permissions to all of your accounts in AWS Organizations centrally. IAM Identity Center includes built-in SAML integrations to many business applications, such as Salesforce, Box, and Microsoft Office 365. Further, you can create Security Assertion Markup Language (SAML) 2.0 integrations and extend single sign-on access to any of your SAMLenabled applications. Your users simply sign in to a user portal with credentials they configure or using their existing corporate credentials to access all their assigned accounts and applications from one place.\\ne Manage single-account IAM permissions: You can specify access to AWS resources using permissions. Your IAM entities (users, groups, and roles) by default start with no permissions. These identities can be granted permissions by attaching an IAM policy that specifies the type of access, the actions that can be performed, and the resources on which actions can be performed. You can also specify conditions that must be set for access to be allowed or denied.\\ne Manage single-account IAM roles: IAM roles allows you to delegate access to users or services that normally don't Nave access to your organization's AWS resources. IAM users or AWS services can assume a role to obtain a temporary security credential that be used to make AWS API calls. You don't have to share long-term credentials or define permissions for each identity.\"\n",
      "\n",
      "=== 360 ===\n",
      "chunk.text (495 tokens):\n",
      "\"AWS Key Management Service (AWS KMS) makes it easy for you to create and manage cryptographic keys and control their use across a wide range of AWS services and in your applications. AWS KMS uses hardware security modules (HSM) to protect and validate your AWS KMS Keys under the FIPS 140-2 Cryptographic Module Validation Program. AWS KMS is integrated with AWS CloudtTrail to provide you with logs of all key usage to help meet your regulatory and compliance needs.\\nAWS Network Firewall is a managed service that makes it easy to deploy essential network protections for all of your Amazon Virtual Private Clouds (VPCs). The service can be setup with just a Tew clicks and scales automatically with your network traffic, so you don't have to worry about deploying and managing any infrastructure. The AWS Network Firewall flexible rules engine lets you define firewall rules that give you fine-grained control over network traffic, such as blocking outbound Server Message Block (SMB) requests to prevent the spread of malicious activity. You can also import rules you've already written in common open source rule formats as well as enable integrations with managed intelligence feeds sourced by AWS Partners. AWS Network Firewall works together with AWS Firewall Manager so you can build policies based on AWS Network Firewall rules and then centrally apply those policies across your VPCs and accounts.\\nAWS Network Firewall includes features that provide protections from common network threats. The AWS Network Firewall stateful firewall can incorporate context from traffic flows, such as tracking connections and protocol identification, to enforce policies such as preventing your VPCs from accessing domains using an unauthorized protocol. The AWS Network Firewall intrusion prevention system (IPS) provides active traffic flow inspection so you can identify and block vulnerability exploits using signature-based detection. AWS Network Firewall also offers web hiltering that can stop trafic to Known bad URLs and monitor fully qualined domain names.\\nIt's easy to get started with AWS Network Firewall by visiting the Amazon VPC Console to create or import your firewall rules, group them into policies, and apply them to the VPCs you want to protect. AWS Network Firewall pricing is based on the number of firewalls deployed and the amount of traffic inspected. There are no upfront commitments and you pay only for what you use.\"\n",
      "chunker.contextualize(chunk) (500 tokens):\n",
      "\"AWS Key Management Service\\nAWS Key Management Service (AWS KMS) makes it easy for you to create and manage cryptographic keys and control their use across a wide range of AWS services and in your applications. AWS KMS uses hardware security modules (HSM) to protect and validate your AWS KMS Keys under the FIPS 140-2 Cryptographic Module Validation Program. AWS KMS is integrated with AWS CloudtTrail to provide you with logs of all key usage to help meet your regulatory and compliance needs.\\nAWS Network Firewall is a managed service that makes it easy to deploy essential network protections for all of your Amazon Virtual Private Clouds (VPCs). The service can be setup with just a Tew clicks and scales automatically with your network traffic, so you don't have to worry about deploying and managing any infrastructure. The AWS Network Firewall flexible rules engine lets you define firewall rules that give you fine-grained control over network traffic, such as blocking outbound Server Message Block (SMB) requests to prevent the spread of malicious activity. You can also import rules you've already written in common open source rule formats as well as enable integrations with managed intelligence feeds sourced by AWS Partners. AWS Network Firewall works together with AWS Firewall Manager so you can build policies based on AWS Network Firewall rules and then centrally apply those policies across your VPCs and accounts.\\nAWS Network Firewall includes features that provide protections from common network threats. The AWS Network Firewall stateful firewall can incorporate context from traffic flows, such as tracking connections and protocol identification, to enforce policies such as preventing your VPCs from accessing domains using an unauthorized protocol. The AWS Network Firewall intrusion prevention system (IPS) provides active traffic flow inspection so you can identify and block vulnerability exploits using signature-based detection. AWS Network Firewall also offers web hiltering that can stop trafic to Known bad URLs and monitor fully qualined domain names.\\nIt's easy to get started with AWS Network Firewall by visiting the Amazon VPC Console to create or import your firewall rules, group them into policies, and apply them to the VPCs you want to protect. AWS Network Firewall pricing is based on the number of firewalls deployed and the amount of traffic inspected. There are no upfront commitments and you pay only for what you use.\"\n",
      "\n",
      "=== 361 ===\n",
      "chunk.text (230 tokens):\n",
      "\"AWS Resource Access Manager (AWS RAM) helps you securely share your resources across AWS accounts, within your organization or organizational units (OUs) in AWS Organizations, and with IAM roles and IAM users Tor supported resource types. You can use AWS RAM to snare transit gateways, subnets, AWS License Manager license configurations, Amazon Route 53 Resolver rules, and more resource types.\\nMany organizations use multiple accounts to create administrative or billing isolation, and to limit the impact of errors. With AWS RAM, you don't need to create duplicate resources in multiple AWS accounts. This reduces the operational overhead of managing resources in every account that you own. Instead, in your multi-account environment, you can create a resource once, and use\\nAWS Network Firewall\\nAWS RAM to snare that resource across accounts by creating a resource snare. When you create a resource share, you select the resources to snare, choose an AWS RAM managed permission per resource type, and specify whom you want to have access to the resources. AWS RAM is available to you at no additional charge.\"\n",
      "chunker.contextualize(chunk) (235 tokens):\n",
      "\"AWS Resource Access Manager\\nAWS Resource Access Manager (AWS RAM) helps you securely share your resources across AWS accounts, within your organization or organizational units (OUs) in AWS Organizations, and with IAM roles and IAM users Tor supported resource types. You can use AWS RAM to snare transit gateways, subnets, AWS License Manager license configurations, Amazon Route 53 Resolver rules, and more resource types.\\nMany organizations use multiple accounts to create administrative or billing isolation, and to limit the impact of errors. With AWS RAM, you don't need to create duplicate resources in multiple AWS accounts. This reduces the operational overhead of managing resources in every account that you own. Instead, in your multi-account environment, you can create a resource once, and use\\nAWS Network Firewall\\nAWS RAM to snare that resource across accounts by creating a resource snare. When you create a resource share, you select the resources to snare, choose an AWS RAM managed permission per resource type, and specify whom you want to have access to the resources. AWS RAM is available to you at no additional charge.\"\n",
      "\n",
      "=== 362 ===\n",
      "chunk.text (164 tokens):\n",
      "'AWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources. The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call toSecrets Manager APIs, eliminating the need to hardcode sensitive information in plain text. Secrets Manager offers secret rotation with built-in integration for Amazon RDS, Amazon Redsnift, and Amazon DocumentDB. The service is also extensible to other types of secrets, including API Keys and OAuth tokens. In addition, Secrets Manager enables you to control access to secrets using fine-grained permissions and audit secret rotation centrally for resources in the AWS Cloud, thirdparty services, and on-premises.'\n",
      "chunker.contextualize(chunk) (168 tokens):\n",
      "'AWS Secrets Manager\\nAWS Secrets Manager helps you protect secrets needed to access your applications, services, and IT resources. The service enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call toSecrets Manager APIs, eliminating the need to hardcode sensitive information in plain text. Secrets Manager offers secret rotation with built-in integration for Amazon RDS, Amazon Redsnift, and Amazon DocumentDB. The service is also extensible to other types of secrets, including API Keys and OAuth tokens. In addition, Secrets Manager enables you to control access to secrets using fine-grained permissions and audit secret rotation centrally for resources in the AWS Cloud, thirdparty services, and on-premises.'\n",
      "\n",
      "=== 363 ===\n",
      "chunk.text (493 tokens):\n",
      "'AWS Security Hub ts a cloud security posture management service that performs automated, continuous security best practice checks against your AWS resources. Security Hub aggregates your security alerts (i.e. findings) from various AWS services and partner products in a standardized format so that you can more easily take action on them. To maintain a complete view of your security posture in AWS, you need to integrate multiple tools and services including threat detections from Amazon GuardDuty, vulnerabilities from Amazon Inspector, sensitive data classifications from Amazon Macie, resource configuration issues from AWS Config, and AWS Partner Network products. Security Hub simplifies how you understand and improve your security posture with automated security best practice checks powered by AWS Config rules and automated integrations with dozens of AWS services and partner products.\\nSecurity Hub enables you to understand your overall security posture via a consolidated security score across all of your AWS accounts, automatically assesses the security of your AWS accounts resources via the AWS Foundational Security Best Practices (FSBP) standard and other compliance frameworks. It also aggregates all of your security findings from dozens of AWS security services and APN products in a single place and format via the AWS Security Finding Format (ASFF), ana reduces your Mean Time To Remediation (MT TR) with automated response and remediation Support. Security Hub nas out-of-the-box integrations with ticketing, chat, Security Information and Event Management (SIEM), Security Orchestration Automation and Response (SOAR), threat\\nAWS Secrets Manager 154\\ninvestigation, Governance Risk and Compliance (GRC), and incident management tools to provide your users with a complete security operations workflow.\\nGetting started with Security Hub requires just a few clicks from the AWS Management Console to begin aggregating findings and conducting security checks using our 50-day Tree trial. You can integrate Security Hub with AWS Organizations to automatically enable the service in all accounts In your organization.\\nAWS Shield is a managed Distributed Denial of Service (DDoS) protection service that safeguards web applications running on AWS. AWS Shield provides you with always-on detection and automatic inline mitigations that minimize application downtime and latency, so there is no need to engage Support to benefit from DDoS protection. There are two tiers of AWS Shield: Standard and Aavancead.'\n",
      "chunker.contextualize(chunk) (497 tokens):\n",
      "'AWS Security Hub\\nAWS Security Hub ts a cloud security posture management service that performs automated, continuous security best practice checks against your AWS resources. Security Hub aggregates your security alerts (i.e. findings) from various AWS services and partner products in a standardized format so that you can more easily take action on them. To maintain a complete view of your security posture in AWS, you need to integrate multiple tools and services including threat detections from Amazon GuardDuty, vulnerabilities from Amazon Inspector, sensitive data classifications from Amazon Macie, resource configuration issues from AWS Config, and AWS Partner Network products. Security Hub simplifies how you understand and improve your security posture with automated security best practice checks powered by AWS Config rules and automated integrations with dozens of AWS services and partner products.\\nSecurity Hub enables you to understand your overall security posture via a consolidated security score across all of your AWS accounts, automatically assesses the security of your AWS accounts resources via the AWS Foundational Security Best Practices (FSBP) standard and other compliance frameworks. It also aggregates all of your security findings from dozens of AWS security services and APN products in a single place and format via the AWS Security Finding Format (ASFF), ana reduces your Mean Time To Remediation (MT TR) with automated response and remediation Support. Security Hub nas out-of-the-box integrations with ticketing, chat, Security Information and Event Management (SIEM), Security Orchestration Automation and Response (SOAR), threat\\nAWS Secrets Manager 154\\ninvestigation, Governance Risk and Compliance (GRC), and incident management tools to provide your users with a complete security operations workflow.\\nGetting started with Security Hub requires just a few clicks from the AWS Management Console to begin aggregating findings and conducting security checks using our 50-day Tree trial. You can integrate Security Hub with AWS Organizations to automatically enable the service in all accounts In your organization.\\nAWS Shield is a managed Distributed Denial of Service (DDoS) protection service that safeguards web applications running on AWS. AWS Shield provides you with always-on detection and automatic inline mitigations that minimize application downtime and latency, so there is no need to engage Support to benefit from DDoS protection. There are two tiers of AWS Shield: Standard and Aavancead.'\n",
      "\n",
      "=== 364 ===\n",
      "chunk.text (400 tokens):\n",
      "'All AWS customers benefit from the automatic protections of AWS Shield Standard, at no additional charge. AWS Shield Standard defends against most common, frequently occurring network and transport layer DDOS attacks that target your website or applications. When you use AWS Shiela Standard with Amazon CloudFront and Amazon Route 54, you receive comprenensive availability protection against all known infrastructure (Layer 5 and 4) attacks.\\nFor higher levels of protection against attacks targeting your applications running on Amazon Elastic Compute Cloud (Amazon EC2), Elastic Load Balancing (ELB), Amazon CloudFront, and Amazon Route 53 resources, you can subscribe to AWS Shield Advanced. In addition to the network and transport layer protections that come with Standard, AWS Shield Advanced provides additional detection and mitigation against large and sophisticated DDOS attacks, near real-time visibility into attacks, and integration with AWS WAF, a web application firewall. AWS Shield Advanced also gives you 24x7 access to the AWS DDoS Response Team (DRT) and protection against DDoS related spikes in your Amazon Elastic Compute Cloud (Amazon EC2), Elastic Load Balancing (ELB), Amazon CloudFront, and Amazon Route 54 charges.\\nAWS Shield Advanced is available globally on all Amazon CloudFront and Amazon Route 535 edge Locations. You can protect your web applications hosted anywhere in the world by deploying Amazon CloudFront in front of your application. Your origin servers can be Amazon $3, Amazon Elastic Compute Cloud (Amazon EC2), Elastic Load Balancing (ELB), or a custom server outside of AWS. You can also enable AWS Shield Advanced directly on an Elastic IP or Elastic Load Balancing (ELB) in the following AWS Regions: Northern Virginia, Ohio, Oregon, Northern California,\\nAWS Shiela\\nMontreal, Sao Paulo, Ireland, Frankfurt, London, Paris, Stockholm, Singapore, Tokyo, Sydney, Seoul, Mumbai, Milan, and Cape Town.'\n",
      "chunker.contextualize(chunk) (404 tokens):\n",
      "'AWS Security Hub\\nAll AWS customers benefit from the automatic protections of AWS Shield Standard, at no additional charge. AWS Shield Standard defends against most common, frequently occurring network and transport layer DDOS attacks that target your website or applications. When you use AWS Shiela Standard with Amazon CloudFront and Amazon Route 54, you receive comprenensive availability protection against all known infrastructure (Layer 5 and 4) attacks.\\nFor higher levels of protection against attacks targeting your applications running on Amazon Elastic Compute Cloud (Amazon EC2), Elastic Load Balancing (ELB), Amazon CloudFront, and Amazon Route 53 resources, you can subscribe to AWS Shield Advanced. In addition to the network and transport layer protections that come with Standard, AWS Shield Advanced provides additional detection and mitigation against large and sophisticated DDOS attacks, near real-time visibility into attacks, and integration with AWS WAF, a web application firewall. AWS Shield Advanced also gives you 24x7 access to the AWS DDoS Response Team (DRT) and protection against DDoS related spikes in your Amazon Elastic Compute Cloud (Amazon EC2), Elastic Load Balancing (ELB), Amazon CloudFront, and Amazon Route 54 charges.\\nAWS Shield Advanced is available globally on all Amazon CloudFront and Amazon Route 535 edge Locations. You can protect your web applications hosted anywhere in the world by deploying Amazon CloudFront in front of your application. Your origin servers can be Amazon $3, Amazon Elastic Compute Cloud (Amazon EC2), Elastic Load Balancing (ELB), or a custom server outside of AWS. You can also enable AWS Shield Advanced directly on an Elastic IP or Elastic Load Balancing (ELB) in the following AWS Regions: Northern Virginia, Ohio, Oregon, Northern California,\\nAWS Shiela\\nMontreal, Sao Paulo, Ireland, Frankfurt, London, Paris, Stockholm, Singapore, Tokyo, Sydney, Seoul, Mumbai, Milan, and Cape Town.'\n",
      "\n",
      "=== 365 ===\n",
      "chunk.text (407 tokens):\n",
      "'AWS IAM Identity Center (SSQ) is a cloud SSO service that makes it easy to centrally manage SSO access to multiple AWS accounts and business applications. With just a Tew clicks, you can enable a highly available SSO service without the upfront investment and on-going maintenance costs of operating your own SSO infrastructure. With IAM Identity Center, you can easily manage SSO access and user permissions to all of your accounts in AWS Organizations centrally. IAM Identity Center also includes built-in SAML integrations to many business applications, such as Salesforce, Box, and Microsoft Office 365. Further, by using the IAM Identity Center application configuration wizard, you can create Security Assertion Markup Language (SAML) 2.0 integrations and extend SSO access to any of your SAML-enabled applications. Your users simply sign in to a user portal with credentials they configure in IAM Identity Center or using their existing corporate credentials to access all their assigned accounts and applications from one place.\\nAWS WAF ts a web application firewall that helps protect your web applications or APIs against common web exploits and bots that may affect availability, compromise security, or consume excessive resources. AWS WAF gives you control over how traffic reaches your applications by enabling you to create security rules that control bot traffic and block common attack patterns, such as SQL injection or cross-site scripting. You can also customize rules that filter out specific traffic patterns. You can get started quickly using Managed Rules for AWS WAF, a pre-configured set of rules managed by AWS or AWS Marketplace sellers to address issues like the OWASP Top 10 security risks and automated bots that consume excess resources, skew metrics, or can Cause downtime. These rules are regularly updated as new issues emerge. AWS WAF includes a Tullfeatured API that you can use to automate the creation, deployment, and maintenance of security rules.'\n",
      "chunker.contextualize(chunk) (413 tokens):\n",
      "'AWS IAM Identity Center\\nAWS IAM Identity Center (SSQ) is a cloud SSO service that makes it easy to centrally manage SSO access to multiple AWS accounts and business applications. With just a Tew clicks, you can enable a highly available SSO service without the upfront investment and on-going maintenance costs of operating your own SSO infrastructure. With IAM Identity Center, you can easily manage SSO access and user permissions to all of your accounts in AWS Organizations centrally. IAM Identity Center also includes built-in SAML integrations to many business applications, such as Salesforce, Box, and Microsoft Office 365. Further, by using the IAM Identity Center application configuration wizard, you can create Security Assertion Markup Language (SAML) 2.0 integrations and extend SSO access to any of your SAML-enabled applications. Your users simply sign in to a user portal with credentials they configure in IAM Identity Center or using their existing corporate credentials to access all their assigned accounts and applications from one place.\\nAWS WAF ts a web application firewall that helps protect your web applications or APIs against common web exploits and bots that may affect availability, compromise security, or consume excessive resources. AWS WAF gives you control over how traffic reaches your applications by enabling you to create security rules that control bot traffic and block common attack patterns, such as SQL injection or cross-site scripting. You can also customize rules that filter out specific traffic patterns. You can get started quickly using Managed Rules for AWS WAF, a pre-configured set of rules managed by AWS or AWS Marketplace sellers to address issues like the OWASP Top 10 security risks and automated bots that consume excess resources, skew metrics, or can Cause downtime. These rules are regularly updated as new issues emerge. AWS WAF includes a Tullfeatured API that you can use to automate the creation, deployment, and maintenance of security rules.'\n",
      "\n",
      "=== 366 ===\n",
      "chunk.text (167 tokens):\n",
      "'AWS WAF Captcha helps block unwanted bot traffic by requiring users to successfully complete challenges before their web request are allowed to reach AWS WAF protected resources. You can contigure AWS WAF rules to require WAF Captcha challenges to be solved for specific resources that are frequently targeted by bots such as login, search, and form submissions. You can also require WAF Captcha challenges for suspicious requests based on the rate, attributes, or labels\\nAWS IAM Identity Center 136\\ngenerated from AWS Managed Rules, such as AWS WAF Bot Control or the Amazon IP Reputation list. WAF Captcha challenges are simple for humans while remaining effective against bots. WAF Captcna includes an audio version and is designed to meet Web Content Accessability Guidelines (WCAG) accessibility requirements.'\n",
      "chunker.contextualize(chunk) (173 tokens):\n",
      "'AWS WAF Captcha\\nAWS WAF Captcha helps block unwanted bot traffic by requiring users to successfully complete challenges before their web request are allowed to reach AWS WAF protected resources. You can contigure AWS WAF rules to require WAF Captcha challenges to be solved for specific resources that are frequently targeted by bots such as login, search, and form submissions. You can also require WAF Captcha challenges for suspicious requests based on the rate, attributes, or labels\\nAWS IAM Identity Center 136\\ngenerated from AWS Managed Rules, such as AWS WAF Bot Control or the Amazon IP Reputation list. WAF Captcha challenges are simple for humans while remaining effective against bots. WAF Captcna includes an audio version and is designed to meet Web Content Accessability Guidelines (WCAG) accessibility requirements.'\n",
      "\n",
      "=== 367 ===\n",
      "chunk.text (63 tokens):\n",
      "'AWS provides a broad portfolio of storage services with deep functionality for storing, accessing, protecting, and analyzing your data.\\nEacn service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS storage service. For general information, see Cloud Storage on A'\n",
      "chunker.contextualize(chunk) (64 tokens):\n",
      "'Storage\\nAWS provides a broad portfolio of storage services with deep functionality for storing, accessing, protecting, and analyzing your data.\\nEacn service is described after the diagram. To help you decide which service best meets your needs, see Choosing an AWS storage service. For general information, see Cloud Storage on A'\n",
      "\n",
      "=== 368 ===\n",
      "chunk.text (66 tokens):\n",
      "'Storage T5/\\ne AWS Elastic Disaster Recovery\\ne Amazon Elastic File System\\ne Amazon File Cache\\ne Amazon FSx for Lustre\\ne Amazon FSx for NetApp ONTAP\\ne Amazon FSx for OpenZFS\\ne Amazon FSx for Windows File Server\\ne Amazon Simple Storage Service\\ne AWS Storage Gateway'\n",
      "chunker.contextualize(chunk) (67 tokens):\n",
      "'Services\\nStorage T5/\\ne AWS Elastic Disaster Recovery\\ne Amazon Elastic File System\\ne Amazon File Cache\\ne Amazon FSx for Lustre\\ne Amazon FSx for NetApp ONTAP\\ne Amazon FSx for OpenZFS\\ne Amazon FSx for Windows File Server\\ne Amazon Simple Storage Service\\ne AWS Storage Gateway'\n",
      "\n",
      "=== 369 ===\n",
      "chunk.text (187 tokens):\n",
      "\"AWS Backup enables you to centralize and automate data protection across AWS services. AWS Backup offers a cost-effective, fully managed, policy-based service that further simplifies data protection at scale. AWS Backup also helps you support your regulatory compliance or business policies for data protection. Together with AWS Organizations, AWS Backup enables you to centrally deploy data protection policies to configure, manage, and govern your backup activity across your organization's AWS accounts and resources, including Amazon Elastic Compute Cloud (Amazon EC2) instances, Amazon Elastic Block Store (Amazon EBS) volumes, Amazon Relational Database Service (Amazon RDS) databases (including Amazon Aurora clusters), Amazon DynamoDB tables, Amazon Elastic File System (Amazon EFS) file systems, Amazon FSx for Lustre file systems, Amazon FSx for Windows File Server file systems, and AWS Storage Gateway volumes.\"\n",
      "chunker.contextualize(chunk) (190 tokens):\n",
      "\"AWS Backup\\nAWS Backup enables you to centralize and automate data protection across AWS services. AWS Backup offers a cost-effective, fully managed, policy-based service that further simplifies data protection at scale. AWS Backup also helps you support your regulatory compliance or business policies for data protection. Together with AWS Organizations, AWS Backup enables you to centrally deploy data protection policies to configure, manage, and govern your backup activity across your organization's AWS accounts and resources, including Amazon Elastic Compute Cloud (Amazon EC2) instances, Amazon Elastic Block Store (Amazon EBS) volumes, Amazon Relational Database Service (Amazon RDS) databases (including Amazon Aurora clusters), Amazon DynamoDB tables, Amazon Elastic File System (Amazon EFS) file systems, Amazon FSx for Lustre file systems, Amazon FSx for Windows File Server file systems, and AWS Storage Gateway volumes.\"\n",
      "\n",
      "=== 370 ===\n",
      "chunk.text (104 tokens):\n",
      "'Amazon Elastic Block Store (Amazon EBS) provides persistent block storage volumes for use with Amazon EC2 instances in the AWS Cloud. Each Amazon EBS volume Is automatically replicated within its Availability Zone to protect you from component failure, offering high availability and durability. Amazon EBS volumes offer the consistent and low-latency performance needed to run your workloads. With Amazon EBS, you can scale your usage up or down within minutes—all while paying a low price for only what you provision.'\n",
      "chunker.contextualize(chunk) (108 tokens):\n",
      "'Amazon Elastic Block Store\\nAmazon Elastic Block Store (Amazon EBS) provides persistent block storage volumes for use with Amazon EC2 instances in the AWS Cloud. Each Amazon EBS volume Is automatically replicated within its Availability Zone to protect you from component failure, offering high availability and durability. Amazon EBS volumes offer the consistent and low-latency performance needed to run your workloads. With Amazon EBS, you can scale your usage up or down within minutes—all while paying a low price for only what you provision.'\n",
      "\n",
      "=== 371 ===\n",
      "chunk.text (187 tokens):\n",
      "'AWS Elastic Disaster Recovery (Elastic Disaster Recovery) minimizes downtime and data loss with fast, reliable recovery of on-premises and cloud-based applications using atfordable storage,\\nAWS Backup 138\\nminimal compute, and point-in-time recovery. You can configure replication and launch settings, monitor data replication, and launch instances for drills or recovery.\\nSet up Elastic Disaster Recovery on your source servers to initiate secure data replication. Your data is replicated to a staging area subnet in your AWS account, in the AWS Region that you select. You can perform non-disruptive tests to confirm that implementation is complete. During normal operation, maintain readiness by monitoring replication and periodically performing non-disruptive recovery and failback drills.\\nif you must replicate to the AWS China Regions or perform replication and recovery into AWS Outposts, use CloudEndure Disaster Recovery available in the AWS Marketplace.'\n",
      "chunker.contextualize(chunk) (192 tokens):\n",
      "'AWS Elastic Disaster Recovery\\nAWS Elastic Disaster Recovery (Elastic Disaster Recovery) minimizes downtime and data loss with fast, reliable recovery of on-premises and cloud-based applications using atfordable storage,\\nAWS Backup 138\\nminimal compute, and point-in-time recovery. You can configure replication and launch settings, monitor data replication, and launch instances for drills or recovery.\\nSet up Elastic Disaster Recovery on your source servers to initiate secure data replication. Your data is replicated to a staging area subnet in your AWS account, in the AWS Region that you select. You can perform non-disruptive tests to confirm that implementation is complete. During normal operation, maintain readiness by monitoring replication and periodically performing non-disruptive recovery and failback drills.\\nif you must replicate to the AWS China Regions or perform replication and recovery into AWS Outposts, use CloudEndure Disaster Recovery available in the AWS Marketplace.'\n",
      "\n",
      "=== 372 ===\n",
      "chunk.text (429 tokens):\n",
      "\"Amazon Elastic File System (Amazon EFS) provides a simple, scalable, elastic file system for Linuxbased workloads for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and snrinking automatically as you add and remove files, so your applications have the storage they need — when they need it. It is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies. Amazon EFS its a fully managed service that requires no changes to your existing applications and tools, providing access through a standard file system interface for seamless integration. Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. You can access your file systems across Availability Zones and AWS Regions and share files between thousands of Amazon EC2 instances and on-premises servers via AWS Direct Connect or AWS VPN.\\nAmazon EFS is well suited to support a broad spectrum of use cases from highly parallelized, scale-out workloads that require the highest possible throughput to single-threaded, latencysensitive workloads. Use cases such as lift-and-shift enterprise applications, big data analytics, web serving and content management, application development and testing, media and entertainment worktlows, database backups, and container storage.\\nFor long-lived data that is accessed only a Tew times a year or less, consider Amazon EFS Archive, a cost-effective way to retain even your coldest data so that it's always available to power new business insights. Amazon EFS Archive supports the same intelligent tiering experience as existing EFS storage classes. This means that you can combine the sub-millisecond SSD latencies of Amazon EFS Standard for your active Trequently-accessed data with the lower costs of Amazon EFS IA and Amazon EFS Archive for your colder data.\\nAmazon Elastic Fite System 139\"\n",
      "chunker.contextualize(chunk) (433 tokens):\n",
      "\"Amazon Elastic File System\\nAmazon Elastic File System (Amazon EFS) provides a simple, scalable, elastic file system for Linuxbased workloads for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and snrinking automatically as you add and remove files, so your applications have the storage they need — when they need it. It is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies. Amazon EFS its a fully managed service that requires no changes to your existing applications and tools, providing access through a standard file system interface for seamless integration. Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. You can access your file systems across Availability Zones and AWS Regions and share files between thousands of Amazon EC2 instances and on-premises servers via AWS Direct Connect or AWS VPN.\\nAmazon EFS is well suited to support a broad spectrum of use cases from highly parallelized, scale-out workloads that require the highest possible throughput to single-threaded, latencysensitive workloads. Use cases such as lift-and-shift enterprise applications, big data analytics, web serving and content management, application development and testing, media and entertainment worktlows, database backups, and container storage.\\nFor long-lived data that is accessed only a Tew times a year or less, consider Amazon EFS Archive, a cost-effective way to retain even your coldest data so that it's always available to power new business insights. Amazon EFS Archive supports the same intelligent tiering experience as existing EFS storage classes. This means that you can combine the sub-millisecond SSD latencies of Amazon EFS Standard for your active Trequently-accessed data with the lower costs of Amazon EFS IA and Amazon EFS Archive for your colder data.\\nAmazon Elastic Fite System 139\"\n",
      "\n",
      "=== 373 ===\n",
      "chunk.text (188 tokens):\n",
      "'Amazon File Cache is a fully managed high-speed cache on AWS that makes it easier to process file data, regardless of where the data is stored. Amazon File Cache serves as temporary, highperformance storage for data In on-premises file systems, or in file systems or object stores on AWS. The service allows you to make dispersed datasets available to file-based applications on AWS with a unified view and high speeds. You can link the cache to multiple NFS—including onpremises and in-cloud—or Amazon Simple Storage Service (Amazon S3) buckets, providing a unified view of and fast access to your data spanning on-premises and multiple AWS Regions. The cache provides read and write data access to compute workloads on AWS with sub-millisecona latencies, up to hundreds of GB/s of throughput, and up to millions of IOPS.'\n",
      "chunker.contextualize(chunk) (191 tokens):\n",
      "'Amazon File Cache\\nAmazon File Cache is a fully managed high-speed cache on AWS that makes it easier to process file data, regardless of where the data is stored. Amazon File Cache serves as temporary, highperformance storage for data In on-premises file systems, or in file systems or object stores on AWS. The service allows you to make dispersed datasets available to file-based applications on AWS with a unified view and high speeds. You can link the cache to multiple NFS—including onpremises and in-cloud—or Amazon Simple Storage Service (Amazon S3) buckets, providing a unified view of and fast access to your data spanning on-premises and multiple AWS Regions. The cache provides read and write data access to compute workloads on AWS with sub-millisecona latencies, up to hundreds of GB/s of throughput, and up to millions of IOPS.'\n",
      "\n",
      "=== 374 ===\n",
      "chunk.text (352 tokens):\n",
      "'Amazon FSx for Lustre is a fully managed file system that is optimized for compute-intensive workloads, such as high performance computing, machine learning, and media data processing workflows. Many of these applications require the high-performance and low latencies of scaleout, parallel file systems. Operating these file systems typically requires specialized expertise and administrative overhead, requiring you to provision storage servers and tune complex performance parameters. With Amazon FSx, you can launch and run a Lustre file system that can process massive data sets at up to hundreds of gigabytes per second of throughput, millions of IOPS, and suD-milliseconad latencies.\\nAmazon FSx for Lustre is seamlessly integrated with Amazon S3, making it easy to link your longterm data sets with your high performance file systems to run compute-intensive workloads. You can automatically copy data from S3 to Amazon FSx for Lustre, run your workloads, and then write results back to $3. Amazon FSx for Lustre also enables you to burst your compute-intensive workloads from on-premises to AWS by allowing you to access your FSx file system over Amazon Direct Connect or VPN. Amazon FSx for Lustre helps you cost-optimize your storage for computeintensive workloads: It provides cheap and performant non-replicated storage for processing data, with your long-term data stored durably in Amazon S43 or other low-cost data stores. With Amazon FSx, you pay for only the resources you use. There are no minimum commitments, upfront hardware or software costs, or additional fees.'\n",
      "chunker.contextualize(chunk) (359 tokens):\n",
      "'Amazon FS x for Lustre\\nAmazon FSx for Lustre is a fully managed file system that is optimized for compute-intensive workloads, such as high performance computing, machine learning, and media data processing workflows. Many of these applications require the high-performance and low latencies of scaleout, parallel file systems. Operating these file systems typically requires specialized expertise and administrative overhead, requiring you to provision storage servers and tune complex performance parameters. With Amazon FSx, you can launch and run a Lustre file system that can process massive data sets at up to hundreds of gigabytes per second of throughput, millions of IOPS, and suD-milliseconad latencies.\\nAmazon FSx for Lustre is seamlessly integrated with Amazon S3, making it easy to link your longterm data sets with your high performance file systems to run compute-intensive workloads. You can automatically copy data from S3 to Amazon FSx for Lustre, run your workloads, and then write results back to $3. Amazon FSx for Lustre also enables you to burst your compute-intensive workloads from on-premises to AWS by allowing you to access your FSx file system over Amazon Direct Connect or VPN. Amazon FSx for Lustre helps you cost-optimize your storage for computeintensive workloads: It provides cheap and performant non-replicated storage for processing data, with your long-term data stored durably in Amazon S43 or other low-cost data stores. With Amazon FSx, you pay for only the resources you use. There are no minimum commitments, upfront hardware or software costs, or additional fees.'\n",
      "\n",
      "=== 375 ===\n",
      "chunk.text (229 tokens):\n",
      "'Amazon FSx tor NetApp ONTAP ofters the first complete, Tully managed NetApp file system available in the cloud making it easy Tor you to migrate or extend existing applications to AWS\\nAmazon File Cacne\\nwithout changing code or how you manage your data . Built on NetApp ONTAP, Amazon FSx for NetApp ONTAP provides the familiar features, performance, capabilities, and APIs of NetApp file systems with the agility, scalability, and simplicity of a fully managed AWS service.\\nAmazon FSx for NetApp ONTAP offers high-performance file storage that is broadly accessible from Linux, Windows, and macOS compute instances via the industry-standard NFS, SMB, and iSCSI protocols. With Amazon FSx for NetApp ONTAP, you get low-cost, fully elastic storage capacity with support for compression and deduplication to help you further reduce storage costs. Amazon FSx for NetApp ONTAP file systems can be deployed and managed using the AWS Management Console or NetApp Cloud Manager for seamless set up and administration.'\n",
      "chunker.contextualize(chunk) (239 tokens):\n",
      "'Amazon FSx for NetApp ONTAP\\nAmazon FSx tor NetApp ONTAP ofters the first complete, Tully managed NetApp file system available in the cloud making it easy Tor you to migrate or extend existing applications to AWS\\nAmazon File Cacne\\nwithout changing code or how you manage your data . Built on NetApp ONTAP, Amazon FSx for NetApp ONTAP provides the familiar features, performance, capabilities, and APIs of NetApp file systems with the agility, scalability, and simplicity of a fully managed AWS service.\\nAmazon FSx for NetApp ONTAP offers high-performance file storage that is broadly accessible from Linux, Windows, and macOS compute instances via the industry-standard NFS, SMB, and iSCSI protocols. With Amazon FSx for NetApp ONTAP, you get low-cost, fully elastic storage capacity with support for compression and deduplication to help you further reduce storage costs. Amazon FSx for NetApp ONTAP file systems can be deployed and managed using the AWS Management Console or NetApp Cloud Manager for seamless set up and administration.'\n",
      "\n",
      "=== 376 ===\n",
      "chunk.text (127 tokens):\n",
      "'Amazon FSx for OpenZFS is a fully managed file storage service that lets you launch, run, and scale Tully managed file systems built on the open-source OpenZFS file system. Amazon FSx for OpenZFS makes it easy to migrate your on-premises file servers—without changing your applications or how you manage data—and build new high-performance, data-driven applications in the cloud.\\nAmazon FSx for OpenZFS offers the familiar features, performance, and capabilities of OpenZFS hile systems with the agility, scalability, and simplicity of a Tully managed AWS service.'\n",
      "chunker.contextualize(chunk) (135 tokens):\n",
      "'Amazon FSx for OpenZFS\\nAmazon FSx for OpenZFS is a fully managed file storage service that lets you launch, run, and scale Tully managed file systems built on the open-source OpenZFS file system. Amazon FSx for OpenZFS makes it easy to migrate your on-premises file servers—without changing your applications or how you manage data—and build new high-performance, data-driven applications in the cloud.\\nAmazon FSx for OpenZFS offers the familiar features, performance, and capabilities of OpenZFS hile systems with the agility, scalability, and simplicity of a Tully managed AWS service.'\n",
      "\n",
      "=== 377 ===\n",
      "chunk.text (265 tokens):\n",
      "'Amazon FSx for Windows File Server provides a Tully managed native Microsoft Windows fle system so you can easily move your Windows-based applications that require file storage to AWS. Built on Windows Server, Amazon FSx provides snared file storage with the compatibility and features that your Windows-based applications rely on, including Tull support for the SMB protocol and Windows NTFS, Active Directory (AD) integration, and Distributed File System (DFS). Amazon FSx uses SSD storage to provide the fast performance your Windows applications and users expect, with high levels of throughput and IOPS, and consistent sub-miltlisecond latencies. This compatibility and performance is particularly important when moving workloads that require Windows snared Tile storage, such as CRM, ERP, and .NET applications, as well as home directories.\\nWith Amazon FSx, you can launch highly durable and available Windows file systems that can be accessed trom up to thousands of compute instances using the industry-standard SMB protocol. Amazon FSx eliminates the typical administrative overnead of managing Windows file servers. You pay Tor only the resources used, with no uptront costs, minimum commitments, or additional Tees.\\nAmazon FSx for OpenZFS 141'\n",
      "chunker.contextualize(chunk) (273 tokens):\n",
      "'Amazon FSx for Windows File Server\\nAmazon FSx for Windows File Server provides a Tully managed native Microsoft Windows fle system so you can easily move your Windows-based applications that require file storage to AWS. Built on Windows Server, Amazon FSx provides snared file storage with the compatibility and features that your Windows-based applications rely on, including Tull support for the SMB protocol and Windows NTFS, Active Directory (AD) integration, and Distributed File System (DFS). Amazon FSx uses SSD storage to provide the fast performance your Windows applications and users expect, with high levels of throughput and IOPS, and consistent sub-miltlisecond latencies. This compatibility and performance is particularly important when moving workloads that require Windows snared Tile storage, such as CRM, ERP, and .NET applications, as well as home directories.\\nWith Amazon FSx, you can launch highly durable and available Windows file systems that can be accessed trom up to thousands of compute instances using the industry-standard SMB protocol. Amazon FSx eliminates the typical administrative overnead of managing Windows file servers. You pay Tor only the resources used, with no uptront costs, minimum commitments, or additional Tees.\\nAmazon FSx for OpenZFS 141'\n",
      "\n",
      "=== 378 ===\n",
      "chunk.text (505 tokens):\n",
      "\"Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industryleading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, lol devices, and big data analytics. Amazon S4 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S34 is designed for 99.999999999% (11 9s) of durability, and stores data for millions of applications for companies all around the world.\\nAmazon S3 storage classes are a range of storage classes that you can choose from based on the data access, resiliency, and cost requirements of your workloads. S43 storage classes are purposebuilt to provide the lowest cost storage for different access patterns. S3 storage classes are ideal for virtually any use case, including those with demanding performance needs, data residency requirements, unknown or changing access patterns, or archival storage.\\nThe S43 storage classes include:\\ne S3 Intelligent-Tiering for automatic cost savings for data with unknown or changing access patterns\\ne S3 Standard for frequently accessed data\\n- S3 Express One Zone for your most frequently accessed data\\ne S3 Standard-Infrequent Access (S3 Standard-IA) and S3 One Zone-Infrequent Access (S3 One Zone-IA) for less frequently accessed data\\ne §3 Glacier Instant Retrieval for archive data that needs immediate access\\ne S3 Glacier Flexible Retrieval (formerly S35 Glacier) for rarely accessed long-term data that does not require immediate access\\ne Amazon S3 Glacier Deep Archive (S3 Glacier Deep Archive) for long-term archive and digital preservation with retrieval in hours at the lowest cost storage in the cloud\\nIf you nave data residency requirements that can't be met by an existing AWS Region, you can use the $3 Outposts storage class to store your S43 data on premises. Amazon S34 also offers capabilities to manage your data throughout its lifecycle. Once an S34 Lifecycle policy is set, your data will automatically transfer to a different storage class without any changes to your application. For more information, refer to the Amazon S4 storage classes overview into grapnic.\"\n",
      "chunker.contextualize(chunk) (509 tokens):\n",
      "\"Amazon Simple Storage Service\\nAmazon Simple Storage Service (Amazon S3) is an object storage service that offers industryleading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, lol devices, and big data analytics. Amazon S4 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S34 is designed for 99.999999999% (11 9s) of durability, and stores data for millions of applications for companies all around the world.\\nAmazon S3 storage classes are a range of storage classes that you can choose from based on the data access, resiliency, and cost requirements of your workloads. S43 storage classes are purposebuilt to provide the lowest cost storage for different access patterns. S3 storage classes are ideal for virtually any use case, including those with demanding performance needs, data residency requirements, unknown or changing access patterns, or archival storage.\\nThe S43 storage classes include:\\ne S3 Intelligent-Tiering for automatic cost savings for data with unknown or changing access patterns\\ne S3 Standard for frequently accessed data\\n- S3 Express One Zone for your most frequently accessed data\\ne S3 Standard-Infrequent Access (S3 Standard-IA) and S3 One Zone-Infrequent Access (S3 One Zone-IA) for less frequently accessed data\\ne §3 Glacier Instant Retrieval for archive data that needs immediate access\\ne S3 Glacier Flexible Retrieval (formerly S35 Glacier) for rarely accessed long-term data that does not require immediate access\\ne Amazon S3 Glacier Deep Archive (S3 Glacier Deep Archive) for long-term archive and digital preservation with retrieval in hours at the lowest cost storage in the cloud\\nIf you nave data residency requirements that can't be met by an existing AWS Region, you can use the $3 Outposts storage class to store your S43 data on premises. Amazon S34 also offers capabilities to manage your data throughout its lifecycle. Once an S34 Lifecycle policy is set, your data will automatically transfer to a different storage class without any changes to your application. For more information, refer to the Amazon S4 storage classes overview into grapnic.\"\n",
      "\n",
      "=== 379 ===\n",
      "chunk.text (68 tokens):\n",
      "'You can use S3 Object Lock to help prevent $3 objects from being deleted or overwritten for a fixed amount of time, or indefinitely. Object Lock can help you to meet regulatory requirements that require WORM (write-once-read-many) storage, or to simply add another layer of protection against object changes or deletion.'\n",
      "chunker.contextualize(chunk) (72 tokens):\n",
      "'Amazon Simple Storage Service\\nYou can use S3 Object Lock to help prevent $3 objects from being deleted or overwritten for a fixed amount of time, or indefinitely. Object Lock can help you to meet regulatory requirements that require WORM (write-once-read-many) storage, or to simply add another layer of protection against object changes or deletion.'\n",
      "\n",
      "=== 380 ===\n",
      "chunk.text (187 tokens):\n",
      "'The AWS Storage Gateway is a hybrid storage service that allows your on-premises applications to seamlessly use AWS cloud storage. You can use the service for backup and archiving, disaster recovery, cloud data processing, storage tiering, and migration. Your applications connect to the service through a virtual machine or hardware gateway appliance using standard storage protocols, sucn as NFS, SMB and iSCSI. The gateway connects to AWS storage services, such as Amazon S3, $3 Glacier, and Amazon EBS, and Amazon FSx for Windows File Server, providing storage for files, volumes, and virtual tapes in AWS. The service includes a highly-optimized data transfer mechanism, with bandwidth management, automated network resilience, and efficient data transfer, along with a local cache for low-latency on-premises access to your most active data.\\nAWS Storage Gateway 145'\n",
      "chunker.contextualize(chunk) (191 tokens):\n",
      "'AWS Storage Gateway\\nThe AWS Storage Gateway is a hybrid storage service that allows your on-premises applications to seamlessly use AWS cloud storage. You can use the service for backup and archiving, disaster recovery, cloud data processing, storage tiering, and migration. Your applications connect to the service through a virtual machine or hardware gateway appliance using standard storage protocols, sucn as NFS, SMB and iSCSI. The gateway connects to AWS storage services, such as Amazon S3, $3 Glacier, and Amazon EBS, and Amazon FSx for Windows File Server, providing storage for files, volumes, and virtual tapes in AWS. The service includes a highly-optimized data transfer mechanism, with bandwidth management, automated network resilience, and efficient data transfer, along with a local cache for low-latency on-premises access to your most active data.\\nAWS Storage Gateway 145'\n",
      "\n",
      "=== 381 ===\n",
      "chunk.text (93 tokens):\n",
      "'Reinvent how you work with IT by signing up for the AWS Free Tier, which allows you to gain nands-on experience with a broad selection of AWS products and services. Within the AWS Free Tier, you can test workloads and run applications to learn more and build the right solution for your organization. You can also contact AWS Sales and Business Development.\\nBy signing up tor AWS, you have access to Amazon cloud computing services.'\n",
      "chunker.contextualize(chunk) (95 tokens):\n",
      "'Next steps\\nReinvent how you work with IT by signing up for the AWS Free Tier, which allows you to gain nands-on experience with a broad selection of AWS products and services. Within the AWS Free Tier, you can test workloads and run applications to learn more and build the right solution for your organization. You can also contact AWS Sales and Business Development.\\nBy signing up tor AWS, you have access to Amazon cloud computing services.'\n",
      "\n",
      "=== 382 ===\n",
      "chunk.text (102 tokens):\n",
      "'The sign-up process requires a credit card, which will not be charged until you start using services. There are no long-term commitments and you can stop using AWS at any time.\\nTo help familiarize yourself with AWS, check out AWS Skill Builder to explore free, on-demand courses developed by the experts at AWS.\\nLearn about the breadth and depth of AWS on our general AWS Channel and AWS Online Tech\\nGet hands-on experience from our self-paced labs.'\n",
      "chunker.contextualize(chunk) (103 tokens):\n",
      "'Note\\nThe sign-up process requires a credit card, which will not be charged until you start using services. There are no long-term commitments and you can stop using AWS at any time.\\nTo help familiarize yourself with AWS, check out AWS Skill Builder to explore free, on-demand courses developed by the experts at AWS.\\nLearn about the breadth and depth of AWS on our general AWS Channel and AWS Online Tech\\nGet hands-on experience from our self-paced labs.'\n",
      "\n",
      "=== 383 ===\n",
      "chunk.text (177 tokens):\n",
      "'Fxplore the AWS Well-Architected Framework, which helps you understand the pros and cons of the decisions you make when building systems on AWS. Using the six pillars of the AWS WellArchitected Framework, you can learn architectural best practices for designing and operating reliable, secure, efficient, cost-effective, and sustainable systems in the cloud.\\nYou can use the AWS Well-Architected Tool, available at no charge in the AWS Management Console, to review your workloads against these best practices by answering a set of questions for eacn pillar. In addition to the Framework and the AWS WA Tool, specialized guidance is provided for various types of applications.\\n- e In the Servertess Application Lens, we focus on best practices for architecting your serverless applications on AWS.\\nAre you Well-Architected? 144'\n",
      "chunker.contextualize(chunk) (184 tokens):\n",
      "'Are you Well-Architected?\\nFxplore the AWS Well-Architected Framework, which helps you understand the pros and cons of the decisions you make when building systems on AWS. Using the six pillars of the AWS WellArchitected Framework, you can learn architectural best practices for designing and operating reliable, secure, efficient, cost-effective, and sustainable systems in the cloud.\\nYou can use the AWS Well-Architected Tool, available at no charge in the AWS Management Console, to review your workloads against these best practices by answering a set of questions for eacn pillar. In addition to the Framework and the AWS WA Tool, specialized guidance is provided for various types of applications.\\n- e In the Servertess Application Lens, we focus on best practices for architecting your serverless applications on AWS.\\nAre you Well-Architected? 144'\n",
      "\n",
      "=== 384 ===\n",
      "chunk.text (462 tokens):\n",
      "'e In the Container Build Lens, we provide cloud-agnostic best practices for building and managing containers and container images. In addition, implementation guidance and examples are provided specific to the AWS Cloud.\\ne In the Machine Learning Lens, we focus on how to design, deploy, and architect your machine Learning workloads in the AWS Cloud.\\ne In the Data Analytics Lens, we describe a collection of customer-proven best practices for designing well-architected analytics workloads.\\ne In the Hybrid Networking Lens, we focus on how to design, deploy, and architect hybrid networking Tor workloads in the AWS Cloud.\\ne In the lol Lens and loT Lens Checklist, we focus on best practices for architecting your loT applications on AWS.\\ne In the SAP Lens, we describe a collection of customer-proven design principles and best practices for ensuring SAP workloads on AWS are well-architected.\\ne In the Games Industry Lens, we focus on designing, architecting, and deploying your games workloads on AWS.\\ne In the Streaming Media Lens, we focus on the best practices for architecting and improving your streaming media workloads on AWS.\\ne In the Healthcare Industry Lens, we focus on how to design, deploy, and manage your healthcare workloads.\\ne In the Financial Services Industry Lens, we focus on best practices for architecting your Financial Services Industry workloads on AWS.\\ne In the HPC Lens, we focus on best practices for architecting your High Performance Computing (HPC) workloads on AWS.\\ne In the SaaS Lens, we focus on best practices for architecting your software as a service (SaaS) workloads on AWS.\\ne In the Government Lens, we focus on best practices for designing and delivering government services on AWS.\\ne In the Connected Mobility Lens, we focus on best practices for integrating technology into transportation systems and enhancing the overall mobility experience.\\ne In the Migration Lens, we provide best practices for how to migrate to the AWS Cloud.\\nFor more expert guidance and best practices for your cloud architecture—reference architecture deployments, diagrams, and whitepapers—refer to the AWS Architecture Center.\\nAre you Well-Architected? 145'\n",
      "chunker.contextualize(chunk) (469 tokens):\n",
      "'Are you Well-Architected?\\ne In the Container Build Lens, we provide cloud-agnostic best practices for building and managing containers and container images. In addition, implementation guidance and examples are provided specific to the AWS Cloud.\\ne In the Machine Learning Lens, we focus on how to design, deploy, and architect your machine Learning workloads in the AWS Cloud.\\ne In the Data Analytics Lens, we describe a collection of customer-proven best practices for designing well-architected analytics workloads.\\ne In the Hybrid Networking Lens, we focus on how to design, deploy, and architect hybrid networking Tor workloads in the AWS Cloud.\\ne In the lol Lens and loT Lens Checklist, we focus on best practices for architecting your loT applications on AWS.\\ne In the SAP Lens, we describe a collection of customer-proven design principles and best practices for ensuring SAP workloads on AWS are well-architected.\\ne In the Games Industry Lens, we focus on designing, architecting, and deploying your games workloads on AWS.\\ne In the Streaming Media Lens, we focus on the best practices for architecting and improving your streaming media workloads on AWS.\\ne In the Healthcare Industry Lens, we focus on how to design, deploy, and manage your healthcare workloads.\\ne In the Financial Services Industry Lens, we focus on best practices for architecting your Financial Services Industry workloads on AWS.\\ne In the HPC Lens, we focus on best practices for architecting your High Performance Computing (HPC) workloads on AWS.\\ne In the SaaS Lens, we focus on best practices for architecting your software as a service (SaaS) workloads on AWS.\\ne In the Government Lens, we focus on best practices for designing and delivering government services on AWS.\\ne In the Connected Mobility Lens, we focus on best practices for integrating technology into transportation systems and enhancing the overall mobility experience.\\ne In the Migration Lens, we provide best practices for how to migrate to the AWS Cloud.\\nFor more expert guidance and best practices for your cloud architecture—reference architecture deployments, diagrams, and whitepapers—refer to the AWS Architecture Center.\\nAre you Well-Architected? 145'\n",
      "\n",
      "=== 385 ===\n",
      "chunk.text (150 tokens):\n",
      "\"AWS provides building blocks that you can assemble quickly to support virtually any workload. With AWS, you'll find a complete set of highly available services that are designed to work together to build sophisticated scalable applications.\\nYou have access to highly durable storage, low-cost compute, high-performance databases, management tools, and more. All this is available without up-front cost, and you pay for only what you use. These services help organizations move faster, lower IT costs, and scale. AWS is trusted by the largest enterprises and the hottest start-ups to power a wide variety of workloads, including web and mobile applications, game development, data processing and warehousing, storage, archive, and many others.\"\n",
      "chunker.contextualize(chunk) (151 tokens):\n",
      "\"Conclusion\\nAWS provides building blocks that you can assemble quickly to support virtually any workload. With AWS, you'll find a complete set of highly available services that are designed to work together to build sophisticated scalable applications.\\nYou have access to highly durable storage, low-cost compute, high-performance databases, management tools, and more. All this is available without up-front cost, and you pay for only what you use. These services help organizations move faster, lower IT costs, and scale. AWS is trusted by the largest enterprises and the hottest start-ups to power a wide variety of workloads, including web and mobile applications, game development, data processing and warehousing, storage, archive, and many others.\"\n",
      "\n",
      "=== 386 ===\n",
      "chunk.text (33 tokens):\n",
      "'e AWS Decision Guides\\ne AWS Architecture Center\\ne This ls My Architecture videos\\ne AWS Documentation\\n¢ AWS Blog\\ne AWS Whitepapers & Guides'\n",
      "chunker.contextualize(chunk) (34 tokens):\n",
      "'Resources\\ne AWS Decision Guides\\ne AWS Architecture Center\\ne This ls My Architecture videos\\ne AWS Documentation\\n¢ AWS Blog\\ne AWS Whitepapers & Guides'\n",
      "\n",
      "=== 387 ===\n",
      "chunk.text (478 tokens):\n",
      "'To be notified about updates to this whitepaper, subscribe to the RSS feed.\\nChange, 1 = Description. Change, 2 = Date. Whitepaper updated, 1 = Added links to decision guides where appropriate.. Whitepaper updated, 2 = August 27, 2024. Whitepaper updated, 1 = Amazon Q added. Amazon  CodeWhisperer is now  Amazon Q Developer.  Amazon WorkDocs notice  added.. Whitepaper updated, 2 = May 3, 2024. Whitepaper updated, 1 = AWS B2B Data Interchan  ge, AWS re:Post Private,  Amazon ElastiCache Serverles  s, Amazon Neptune Analytics  , Amazon RDS for Db2,  Amazon PartyRock, Amazon  SageMaker AI HyperPod, and  Amazon WorkSpaces Thin  Client added.. Whitepaper updated, 2 = March 1, 2024. Whitepaper updated, 1 = AWS Snowball Edge informati  on updated.. Whitepaper updated, 2 = February 22, 2024. Whitepaper updated, 1 = AWS Elastic Disaster Recovery  added, other minor updates.. Whitepaper updated, 2 = February 15, 2024. Whitepaper updated, 1 = Amazon Managed Grafana  and Amazon Managed Service  for Prometheus added.. Whitepaper updated, 2 = February 5, 2024\\nWhitepaper updated, 1 = New Connected Mobility Lens  and Migration Lens added to  the Well-Architected section.. Whitepaper updated, 2 = February 2, 2024. Whitepaper updated, 1 = Amazon Lumberyard is no  longer offered. Use Open  3D Engine (O3DE), the  Apache-licensed successor to  Lumberyard.. Whitepaper updated, 2 = December 1, 2023. Whitepaper updated, 1 = New services added: Amazon  CodeCatalyst, AWS Verified  Access, Amazon Aurora  I/O-Optimized, Amazon  SageMaker AI geospatial  capabilities, Amazon Security  Lake, AWS DMS Serverless,  AWS Glue for Ray, AWS Glue  Data Quality, Amazon Verified  Permissions, AWS AppFabric  , AWS Bedrock, vector engine  for Amazon OpenSearch  Serverless, AWS HealthScr  ibe, AWS Entity Resolutio  n, and Amazon VPC Lattice.  Removed Amazon Sumerian.  Numerous editorial changes. Whitepaper updated, 2 = September 28, 2023'\n",
      "chunker.contextualize(chunk) (480 tokens):\n",
      "'Document history\\nTo be notified about updates to this whitepaper, subscribe to the RSS feed.\\nChange, 1 = Description. Change, 2 = Date. Whitepaper updated, 1 = Added links to decision guides where appropriate.. Whitepaper updated, 2 = August 27, 2024. Whitepaper updated, 1 = Amazon Q added. Amazon  CodeWhisperer is now  Amazon Q Developer.  Amazon WorkDocs notice  added.. Whitepaper updated, 2 = May 3, 2024. Whitepaper updated, 1 = AWS B2B Data Interchan  ge, AWS re:Post Private,  Amazon ElastiCache Serverles  s, Amazon Neptune Analytics  , Amazon RDS for Db2,  Amazon PartyRock, Amazon  SageMaker AI HyperPod, and  Amazon WorkSpaces Thin  Client added.. Whitepaper updated, 2 = March 1, 2024. Whitepaper updated, 1 = AWS Snowball Edge informati  on updated.. Whitepaper updated, 2 = February 22, 2024. Whitepaper updated, 1 = AWS Elastic Disaster Recovery  added, other minor updates.. Whitepaper updated, 2 = February 15, 2024. Whitepaper updated, 1 = Amazon Managed Grafana  and Amazon Managed Service  for Prometheus added.. Whitepaper updated, 2 = February 5, 2024\\nWhitepaper updated, 1 = New Connected Mobility Lens  and Migration Lens added to  the Well-Architected section.. Whitepaper updated, 2 = February 2, 2024. Whitepaper updated, 1 = Amazon Lumberyard is no  longer offered. Use Open  3D Engine (O3DE), the  Apache-licensed successor to  Lumberyard.. Whitepaper updated, 2 = December 1, 2023. Whitepaper updated, 1 = New services added: Amazon  CodeCatalyst, AWS Verified  Access, Amazon Aurora  I/O-Optimized, Amazon  SageMaker AI geospatial  capabilities, Amazon Security  Lake, AWS DMS Serverless,  AWS Glue for Ray, AWS Glue  Data Quality, Amazon Verified  Permissions, AWS AppFabric  , AWS Bedrock, vector engine  for Amazon OpenSearch  Serverless, AWS HealthScr  ibe, AWS Entity Resolutio  n, and Amazon VPC Lattice.  Removed Amazon Sumerian.  Numerous editorial changes. Whitepaper updated, 2 = September 28, 2023'\n",
      "\n",
      "=== 388 ===\n",
      "chunk.text (236 tokens):\n",
      "'Whitepaper updated, 1 = New services added: Amazon  CodeWhisperer, Amazon  DataZone, Amazon Linux  2023, AWS Infrastructure  Composer, AWS Clean  Rooms, AWS Modular Data  Center. New subservices  added: Amazon OpenSearc  h Serverless, Geospacial ML  with Amazon Sagemaker,  Amazon EC2 C7g Instances,  Amazon EC2 Inf2 Instances,  Amazon EC2 M7g instances  , Amazon EC2 R7g Instances  , Amazon EC2 Trn1 Instances  . New program added:  Integrated Private Wireless on  AWS.. Whitepaper updated, 2 = April 15, 2023. Whitepaper updated, 1 = New services added:  Amazon File Cache, AWS IoT  ExpressLink, AWS Mainframe  Modernization Service. New  subservices added: Amazon  Connect Cases, Amazon  Redshift Serverless, Amazon  WorkSpaces Core, AWS WAF  Captcha.. Whitepaper updated, 2 = December 30, 2022. Whitepaper updated, 1 = New Container Build Lens  and Healthcare Industry Lens  added to the Well-Architected. Whitepaper updated, 2 = December 23, 2022'\n",
      "chunker.contextualize(chunk) (238 tokens):\n",
      "'Document history\\nWhitepaper updated, 1 = New services added: Amazon  CodeWhisperer, Amazon  DataZone, Amazon Linux  2023, AWS Infrastructure  Composer, AWS Clean  Rooms, AWS Modular Data  Center. New subservices  added: Amazon OpenSearc  h Serverless, Geospacial ML  with Amazon Sagemaker,  Amazon EC2 C7g Instances,  Amazon EC2 Inf2 Instances,  Amazon EC2 M7g instances  , Amazon EC2 R7g Instances  , Amazon EC2 Trn1 Instances  . New program added:  Integrated Private Wireless on  AWS.. Whitepaper updated, 2 = April 15, 2023. Whitepaper updated, 1 = New services added:  Amazon File Cache, AWS IoT  ExpressLink, AWS Mainframe  Modernization Service. New  subservices added: Amazon  Connect Cases, Amazon  Redshift Serverless, Amazon  WorkSpaces Core, AWS WAF  Captcha.. Whitepaper updated, 2 = December 30, 2022. Whitepaper updated, 1 = New Container Build Lens  and Healthcare Industry Lens  added to the Well-Architected. Whitepaper updated, 2 = December 23, 2022'\n",
      "\n",
      "=== 389 ===\n",
      "chunk.text (384 tokens):\n",
      "'Whitepaper updated, 1 = New service AWS Billing  Conductor added, Global  Infrastructure section  updated, category icons  added, and minor corrections. Whitepaper updated, 2 = June 3, 2022. Whitepaper updated, 1 = Added note that EC2-Classic  is being retired on August 15,  2022. Whitepaper updated, 2 = February 17, 2022. Whitepaper updated, 1 = Added new services and  compute services comparison  table.. Whitepaper updated, 2 = January 12, 2022. Whitepaper updated, 1 = Amazon Elasticsearch Service  renamed Amazon OpenSearc  h Service.. Whitepaper updated, 2 = September 8, 2021. Whitepaper updated, 1 = Added new services and  updated information  throughout.. Whitepaper updated, 2 = August 5, 2021. Minor update, 1 = Minor text updates to  improve accuracy and fix  links.. Minor update, 2 = April 12, 2021. Minor update, 1 = Minor text updates to  improve accuracy.. Minor update, 2 = November 20, 2020. Minor update, 1 = Fixed incorrect link.. Minor update, 2 = November 19, 2020. Minor update, 1 = Fixed incorrect link.. Minor update, 2 = August 11, 2020. Minor update, 1 = Fixed incorrect link.. Minor update, 2 = July 17, 2020. Minor updates, 1 = Minor text updates to. Minor updates, 2 = January 1, 2020\\nMinor updates, 1 = Minor text updates to  improve accuracy.. Minor updates, 2 = October 1, 2019. Whitepaper updated, 1 = Added new services and  updated information  throughout.. Whitepaper updated, 2 = December 1, 2018. Whitepaper updated, 1 = Added new services and  updated information  throughout.. Whitepaper updated, 2 = April 1, 2017. Initial publication, 1 = Overview of Amazon Web  Services published.. Initial publication, 2 = January 1, 2014'\n",
      "chunker.contextualize(chunk) (386 tokens):\n",
      "'Document history\\nWhitepaper updated, 1 = New service AWS Billing  Conductor added, Global  Infrastructure section  updated, category icons  added, and minor corrections. Whitepaper updated, 2 = June 3, 2022. Whitepaper updated, 1 = Added note that EC2-Classic  is being retired on August 15,  2022. Whitepaper updated, 2 = February 17, 2022. Whitepaper updated, 1 = Added new services and  compute services comparison  table.. Whitepaper updated, 2 = January 12, 2022. Whitepaper updated, 1 = Amazon Elasticsearch Service  renamed Amazon OpenSearc  h Service.. Whitepaper updated, 2 = September 8, 2021. Whitepaper updated, 1 = Added new services and  updated information  throughout.. Whitepaper updated, 2 = August 5, 2021. Minor update, 1 = Minor text updates to  improve accuracy and fix  links.. Minor update, 2 = April 12, 2021. Minor update, 1 = Minor text updates to  improve accuracy.. Minor update, 2 = November 20, 2020. Minor update, 1 = Fixed incorrect link.. Minor update, 2 = November 19, 2020. Minor update, 1 = Fixed incorrect link.. Minor update, 2 = August 11, 2020. Minor update, 1 = Fixed incorrect link.. Minor update, 2 = July 17, 2020. Minor updates, 1 = Minor text updates to. Minor updates, 2 = January 1, 2020\\nMinor updates, 1 = Minor text updates to  improve accuracy.. Minor updates, 2 = October 1, 2019. Whitepaper updated, 1 = Added new services and  updated information  throughout.. Whitepaper updated, 2 = December 1, 2018. Whitepaper updated, 1 = Added new services and  updated information  throughout.. Whitepaper updated, 2 = April 1, 2017. Initial publication, 1 = Overview of Amazon Web  Services published.. Initial publication, 2 = January 1, 2014'\n",
      "\n",
      "=== 390 ===\n",
      "chunk.text (25 tokens):\n",
      "'To subscribe to RSS updates, you must have an RSS plug-in enabled for the browser you are USING.'\n",
      "chunker.contextualize(chunk) (26 tokens):\n",
      "'Note\\nTo subscribe to RSS updates, you must have an RSS plug-in enabled for the browser you are USING.'\n",
      "\n",
      "=== 391 ===\n",
      "chunk.text (21 tokens):\n",
      "'For the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.'\n",
      "chunker.contextualize(chunk) (25 tokens):\n",
      "'AWS Glossary\\nFor the latest AWS terminology, see the AWS glossary in the AWS Glossary Reference.'\n",
      "\n",
      "The document has been divided into 392 chunks.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARDDOCBOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
